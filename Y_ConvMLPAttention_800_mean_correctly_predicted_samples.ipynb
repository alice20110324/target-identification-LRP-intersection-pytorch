{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48253913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='TRUE'\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042aef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class ConvMLP1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bn0=nn.BatchNorm1d(3300)\n",
    "        self.fc1 = nn.Linear(3300, 1100)\n",
    "        self.bn1= nn.BatchNorm1d(1100)\n",
    "        self.fc2 = nn.Linear(1, 100)\n",
    "        self.bn2=nn.BatchNorm1d(100)\n",
    "        self.fc3=nn.Linear(100,9)\n",
    "        self.bn3=nn.BatchNorm1d(9)\n",
    "        \n",
    "        self.drop=nn.Dropout(0.5)\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(1, 8, 3, padding=1)\n",
    "        #self.pool1 = nn.MaxPool1d(3,stride=3)\n",
    "        self.bn4=nn.BatchNorm1d(3300)\n",
    "        self.conv2 = nn.Conv1d(8, 16, 1,padding=1)\n",
    "        self.bn5=nn.BatchNorm1d(3300)\n",
    "        self.pool2 = nn.MaxPool1d(3,stride=3)\n",
    "        self.conv3=nn.Conv1d(16,1,1,stride=1)\n",
    "        self.pool3=nn.MaxPool1d(3,stride=3)\n",
    "        self.bn6=nn.BatchNorm1d(1100)\n",
    "        #self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        #self.fc2 = nn.Linear(120, 84)\n",
    "        #self.fc3 = nn.Linear(84, 10)\n",
    "        self.bn7=nn.BatchNorm1d(1100)\n",
    "    def forward(self, x):\n",
    "        x=self.bn0(x)\n",
    "        #print('x:',x.shape)\n",
    "        x1= F.relu(self.drop(self.bn1(self.fc1(x))))\n",
    "        #print('x1:',x1.shape)\n",
    "        x0=torch.unsqueeze(x,1)\n",
    "        x2=F.relu(self.conv1(x0))\n",
    "        #x2=x2+x0\n",
    "        #print('x2:',x2.shape)\n",
    "        x2=F.relu(self.conv2(x2))\n",
    "        #x2=x2+x0\n",
    "        #print('x2:',x2.shape)\n",
    "        x2=F.relu(self.conv3(x2))\n",
    "        #print('x2:',x2.shape)\n",
    "        #x2=x0+x2####skip connection\n",
    "        x2=torch.squeeze(x2,1)\n",
    "        x2=self.bn5(x2)\n",
    "        x2=self.pool3(x2)\n",
    "        #print('x2:',x2.shape)\n",
    "        x2=self.bn6(x2)\n",
    "        #x3=torch.add(x1,x2)\n",
    "        #x3=torch.concat([x1,x2],dim=1)\n",
    "        x3=torch.add(x1+x2)\n",
    "        x4=self.bn7(x3)\n",
    "        x4 = F.relu(self.drop(self.bn2(self.fc2(x3))))\n",
    "        return F.softmax(self.bn3(self.fc3(x4)), dim=1) \n",
    "modely=ConvMLP1()\n",
    "modely.cuda()\n",
    "print(modely)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
