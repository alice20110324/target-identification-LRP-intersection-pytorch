{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1e79833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import Trainer\n",
    "#from network import NFM\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "from Utils.criteo_loader import getTestData, getTrainData\n",
    "\n",
    "nfm_config = \\\n",
    "{\n",
    "    'n_class':9,\n",
    "    'linear_hidden1':1000,\n",
    "    #'linear_hidden':100,#线性模型输出层（隐层个数）\n",
    "    'embed_input_dim':1001,#embed输入维度\n",
    "    'embed_dim': 10, # 用于控制稀疏特征经过Embedding层后的稠密特征大小，embed输出维度\n",
    "    #'dnn_hidden_units': [100,11],#MLP隐层和输出层\n",
    "    'linear1_drop':0.5,\n",
    "    'dnn_hidden_units':[9],#MLP隐层\n",
    "    'dnn_layer_units':[100,9],\n",
    "    'num_sparse_features_cols':10477,#the number of the gene columns\n",
    "    'num_dense_features': 0,#dense features number\n",
    "    'bi_dropout': 0.3,#Bi-Interaction 的dropout\n",
    "    'num_epoch': 500,#训练epoch次数\n",
    "    'batch_size': 24,#batch_size\n",
    "    'lr': 1e-3,\n",
    "    'l2_regularization': 1e-4,\n",
    "    'device_id': 0,\n",
    "    'use_cuda': False,\n",
    "    'epoch':1000,\n",
    "    \n",
    "    #'train_file': '../Data/criteo/processed_data/train_set.csv',\n",
    "    #'fea_file': '../Data/criteo/processed_data/fea_col.npy',\n",
    "    #'validate_file': '../Data/criteo/processed_data/val_set.csv',\n",
    "    #'test_file': '../Data/criteo/processed_data/test_set.csv',\n",
    "    #'model_name': '../TrainedModels/NFM.model'\n",
    "    #'train_file':'data/xiaoqiu_gene_5000/train/final_5000_encode_100x.csv',\n",
    "    'train_data':'dataset/qiuguan/encode/encode_1000/train/train_encode_data_1000_new.csv',\n",
    "    'train_label':'dataset/qiuguan/non_code/train/train_label.csv',\n",
    "    #'test_data':'dataset/qiuguan/non_code/test/test_encode_data.csv',\n",
    "    'test_data':'dataset/qiuguan/encode/encode_1000/test/test_encode_data_1000_new.csv',\n",
    "    'test_label':'dataset/qiuguan/non_code/test/test_labels.csv'\n",
    "    #'title':'dataset/xiaoguan/RF/RF_for_train/train_class_9/test/test_data.csv',\n",
    "    \n",
    "    #'all':''\n",
    "    #'title':'data/xiaoqiu_gene_5000/train/gene_5000_gene_name.csv',\n",
    "    #'all':'data/xiaoqiu_gene_5000/train/gene_5000_label_name.csv'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36805b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiInteractionPooling(nn.Module):\n",
    "    \"\"\"Bi-Interaction Layer used in Neural FM,compress the\n",
    "      pairwise element-wise product of features into one single vector.\n",
    "      Input shape\n",
    "        - A 3D tensor with shape:``(batch_size,field_size,embedding_size)``.\n",
    "      Output shape\n",
    "    http://127.0.0.1:3000/notebooks/NFM-pyorch-master/NFM-pyorch-master/%E6%9C%AA%E5%91%BD%E5%90%8D5.ipynb?kernel_name=python3#    - 3D tensor with shape: ``(batch_size,1,embedding_size)``.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(BiInteractionPooling, self).__init__()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        concated_embeds_value = inputs\n",
    "        square_of_sum = torch.pow(\n",
    "            torch.sum(concated_embeds_value, dim=1, keepdim=True), 2)\n",
    "        sum_of_square = torch.sum(\n",
    "            concated_embeds_value * concated_embeds_value, dim=1, keepdim=True)\n",
    "        cross_term = 0.5 * (square_of_sum - sum_of_square)\n",
    "        return cross_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf2e073a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embding_process(config,sparse_inputs):\n",
    "    \n",
    "    \n",
    "    embedding_layers=nn.Embedding(config['embed_input_dim'],config['embed_dim'])\n",
    "        \n",
    "    # B-Interaction 层\n",
    "    bi_pooling = BiInteractionPooling()\n",
    "    bi_dropout = config['bi_dropout']\n",
    "    if bi_dropout > 0:\n",
    "        dropout = nn.Dropout(bi_dropout)\n",
    "            \n",
    "    num_sparse_feature=config['num_sparse_features_cols']\n",
    "    \n",
    "    sparse_embeds = [embedding_layers(sparse_inputs[:, i]) for i in range(sparse_inputs.shape[1])]\n",
    "    sparse_embeds = torch.cat(sparse_embeds, axis=-1)\n",
    "    BN_bi = nn.BatchNorm1d(config['embed_dim'])\n",
    "    # 送入B-Interaction层\n",
    "    fm_input = sparse_embeds.view(-1, num_sparse_feature, config['embed_dim'])#整理成n行m列\n",
    "    # print(fm_input)\n",
    "    # print(fm_input.shape)\n",
    "\n",
    "    bi_out = bi_pooling(fm_input)\n",
    "    if bi_dropout:\n",
    "        bi_out = dropout(bi_out)\n",
    "\n",
    "    bi_out = bi_out.view(-1, config['embed_dim'])\n",
    "    bi_out=BN_bi(bi_out)\n",
    "    \n",
    "    return bi_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2768b319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.backends.cudnn as cudnn\n",
    "#3from tensorboardX import SummaryWriter\n",
    "\n",
    "#import network\n",
    "import config\n",
    "import evaluate\n",
    "import data_utils\n",
    "import Trainer\n",
    "\n",
    "def one_hot_smoothing(labels, classes, label_smoothing=0.2):\n",
    "    n = len(labels)\n",
    "    eoff = label_smoothing / classes\n",
    "    output = np.ones((n, classes), dtype=np.float32) * eoff\n",
    "    for row, label in enumerate(labels):\n",
    "        output[row, label] = 1 - label_smoothing + eoff\n",
    "        #print(\"row:\",row,\"label:\",label)\n",
    "    return output\n",
    "\n",
    "def one_hot(labels, classes):\n",
    "    n = len(labels)\n",
    "    #eoff = label_smoothing / classes\n",
    "    output = np.ones((n, classes), dtype=np.float32)\n",
    "    for row, label in enumerate(labels):\n",
    "        output[row, label] = 1\n",
    "        #print(\"row:\",row,\"label:\",label)\n",
    "    return output\n",
    "\n",
    "class FMData(data.Dataset):\n",
    "    \"\"\" Construct the FM pytorch dataset. \"\"\"\n",
    "    #def __init__(self, file,label_file, feature_map,n_class=16):\n",
    "    def __init__(self, file,label_file, n_class):\n",
    "        super(FMData, self).__init__()\n",
    "        self.label =torch.Tensor([])\n",
    "        self.features = torch.Tensor([])\n",
    "        self.bi_features=torch.Tensor([])\n",
    "        \n",
    "        \n",
    "        fd=pd.read_csv(file,sep=',')\n",
    "        \n",
    "        n_fd=np.array(fd)\n",
    "        \n",
    "        \n",
    "        self.features=np.array(n_fd)\n",
    "        self.bi_features=torch.from_numpy(self.features)\n",
    "        self.bi_features=embding_process(nfm_config,self.bi_features)\n",
    "        \n",
    "        self.features=torch.from_numpy(self.features)\n",
    "        nrow,ncol=n_fd.shape\n",
    "        \n",
    "\n",
    "        \n",
    "        label_fd=pd.read_csv(label_file,sep=',')\n",
    "        #print(features)\n",
    "        #print(label_fd)\n",
    "        label=np.array(label_fd)\n",
    "        #label=label[:,1:]\n",
    "        label=one_hot_smoothing(label,n_class)\n",
    "        self.label=label\n",
    "        self.label=torch.from_numpy(self.label)\n",
    "        \n",
    "        #print(self.features)\n",
    "        #print(self.bi_features)\n",
    "        #print(self.label)\n",
    "        #print(\"label:\",label)\n",
    "        #print(\"features:\",self.features)\n",
    "        #print(label)\n",
    "        # convert labels\n",
    "        \"\"\"if config.loss_type == 'square_loss':\n",
    "            self.label.append(np.float32(items[0]))\n",
    "        else: # log_loss\n",
    "            label = 1 if float(items[0]) > 0 else 0\n",
    "            self.label.append(label)\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        assert all(len(item) == len(self.features[0]\n",
    "            ) for item in self.features), 'features are of different length'\n",
    "        \"\"\"\n",
    "        #print(len(self.features))\n",
    "        #print(len(self.feature_values))\n",
    "        #print(len(self.label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.label[idx]\n",
    "        features = self.features[idx]\n",
    "        bi_features=self.bi_features[idx]\n",
    "        #feature_values = self.feature_values[idx]\n",
    "        #return features, feature_values, label\n",
    "        return features, bi_features, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f9118b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#准备训练集\n",
    "\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.backends.cudnn as cudnn\n",
    "#3from tensorboardX import SummaryWriter\n",
    "\n",
    "#import network\n",
    "import config\n",
    "import evaluate\n",
    "import data_utils\n",
    "import Trainer\n",
    "#from utils import \n",
    "#准备训练集\n",
    "#from new_dataset_processed import FMData\n",
    "#from dataset_process import FMData\n",
    "def prepare_dataset(m_data,m_label,batch_size,n_class):\n",
    "    m_dataset=FMData(m_data,m_label,n_class)\n",
    "    m_dataloader=data.DataLoader(m_dataset, drop_last=True,batch_size=batch_size,shuffle=True)\n",
    "    \n",
    "    return m_dataset,m_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58f07d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from new_nfm_network import NFM\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.backends.cudnn as cudnn\n",
    "#3from tensorboardX import SummaryWriter\n",
    "import sys \n",
    "#import network\n",
    "import config\n",
    "import evaluate\n",
    "import data_utils\n",
    "import Trainer\n",
    "import torchmetrics\n",
    "def   train_data(model,train_loader,test_loader,batch_size,model_path):\n",
    "    #train_accuracy=torchmetrics.Accuracy()\n",
    "    #test_accuracy=torchmetrics.Accuracy()\n",
    "    BATCH_SIZE=batch_size\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=nfm_config['lr'], weight_decay=nfm_config['l2_regularization'])\n",
    "    total = 0\n",
    "    \n",
    "    #loss_func = torch.nn.BCELoss()\n",
    "    loss_func=torch.nn.CrossEntropyLoss()\n",
    "    #loss_func=nn.MultiLabelSoftMarginLoss()\n",
    "    #loss_func=torch.nn.LogSoftmax()\n",
    "    num=2000\n",
    "    #model=nn.Softmax(nn.Linear(10149,16)).to(device)\n",
    "    # 从DataLoader中获取小批量的id以及数据\n",
    "    \n",
    "    batch_size=0\n",
    "    for epoch_id in range(1000):\n",
    "        correct=0\n",
    "        total=0\n",
    "        total_test_acc=0\n",
    "        total_train_accuracy=0\n",
    "        for batch_idx, (x, bi_x,labels) in enumerate(train_loader):\n",
    "            x = Variable(x)\n",
    "            bi_x=Variable(bi_x)\n",
    "            labels = Variable(labels)\n",
    "            \n",
    "            \n",
    "            #x = torch.tensor(x, dtype=torch.float)\n",
    "            #x=x.clone().detach().requires_grad_(True)\n",
    "            x=torch.tensor(x,dtype=torch.float)\n",
    "            bi_x=torch.tensor(bi_x,dtype=torch.long)\n",
    "            labels=torch.tensor(labels,dtype=torch.float)\n",
    "            x, bi_x,labels = x.cuda(),bi_x.cuda(), labels.cuda()\n",
    "            labels_int=labels=torch.max(labels,1)[1]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_predict = model(x,bi_x)\n",
    "            #print(\"y_predict:\",y_predict)\n",
    "            #loss = loss_func(y_predict.view(-1), labels)\n",
    "            loss = loss_func(y_predict, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss = loss.item()\n",
    "            #loss, predicted = self._train_single_batch(x, labels)\n",
    "\n",
    "            total += loss\n",
    "            #yhat = torch.max(yhat.data,1)[1]\n",
    "            #yhat=yhat.detach().cpu().numpy()\n",
    "            #print(\"predicted:\",predicted)\n",
    "            #predicted = torch.max(y_predict.data,1)[1]\n",
    "             #predicted = torch.max(y_predict.data,1)[1]\n",
    "            batch_train_acc=torchmetrics.functional.accuracy(y_predict,labels_int)\n",
    "            #print('batch_train_acc:',batch_train_acc)\n",
    "            total_train_accuracy+=batch_train_acc\n",
    "        #total_train_accuracy=torchmetrics.functional.compute_details()\n",
    "        total_train_accuracy/=(batch_idx+1)\n",
    "        print('total_train_accuracy:',total_train_accuracy)\n",
    "        #print('total_train_accuracy:',total_train_accuracy)\n",
    "        for i , (inputs ,bi_inputs, targets) in enumerate(test_loader):   \n",
    "            print(\"test\")\n",
    "            # evaluate the model on the test set   \n",
    "            #print(\\ inputs:\\  inputs)   \n",
    "            #print(\\ targets:\\  targets)   \n",
    "            inputs = Variable(inputs)   \n",
    "            bi_inputs=Variable(bi_inputs)\n",
    "            targets = Variable(targets)     \n",
    "            #x = torch.tensor(x  dtype=torch.float)   \n",
    "            #x=x.clone().detach().requires_grad_(True)   \n",
    "            inputs=torch.tensor(inputs ,dtype=torch.float)  \n",
    "            bi_inputs=torch.tensor(bi_inputs,dtype=torch.float)\n",
    "            targets=torch.tensor(targets ,dtype=torch.float)   \n",
    "            inputs ,bi_inputs, targets = inputs.cuda(),bi_inputs.cuda(), targets.cuda()   \n",
    "            yhat = model(inputs,bi_inputs)  \n",
    "            \n",
    "            targets=torch.max(targets,1)[1]\n",
    "            #print(\"labels:\",labels)\n",
    "            #labels=labels[1]\n",
    "            #targets=targets.detach().cpu().numpy()\n",
    "            \n",
    "            \n",
    "            \n",
    "            batch_test_acc=torchmetrics.functional.accuracy(yhat,targets)\n",
    "            #print(\"batch_test_acc:\",batch_test_acc)\n",
    "            total_test_acc+=batch_test_acc\n",
    "            #total_test_accuracy=torchmetrics.functional.compute_details()\n",
    "            batch_size=i\n",
    "        print('total_test_accuracy:',total_test_acc/(batch_size+1))\n",
    "        \n",
    "                    \n",
    "                    \n",
    "            \n",
    "            #model.evaluate()\n",
    "            #model.eval()\n",
    "            #train_result = evaluate.metrics(model, train_loader)\n",
    "            #valid_result = evaluate.metrics(model, valid_loader)\n",
    "            #est_result = evaluate.metrics(model, test_loader)\n",
    "            #acturals,predictions,acc_test=evaluate_model(test_loader,model)\n",
    "            #print(\"acc_test:  %d  \" %(acc_test))\n",
    "            #print(\"Train_RMSE: {:.3f}, Valid_RMSE: {:.3f}, Test_RMSE: {:.3f}\".format(\n",
    "            #train_result, valid_result, test_result))\n",
    "            # print('[Training Epoch: {}] Batch: {}, Loss: {}'.format(epoch_id, batch_id, loss))\n",
    "        print(\"Training Epoch: %d, total loss: %f\" % (epoch_id, total))\n",
    "        #print(\"auc:\",roc_auc_score)\n",
    "    #功能：保存训练完的网络的各层参数（即weights和bias)\n",
    "    #path='dataset/xiaoguan/RF/RF_for_train/train_class_9/model/gene_4000_NFM.pkl'\n",
    "        if epoch_id %100==0:\n",
    "            num=num+1\n",
    "            path=os.path.join(model_path,'NMF'+str(num)+'.pkl')\n",
    "            torch.save(model.state_dict(),path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17d06b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from basemodel import BaseModel\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "class NFM(BaseModel):\n",
    "    def __init__(self, config, dense_features_cols=[]):#=[]为新增\n",
    "    #def __init__(self, config, dense_features_cols, sparse_features_cols):\n",
    "        super(NFM, self).__init__(config)\n",
    "        # 稠密和稀疏特征的数量\n",
    "        #self.num_dense_feature = dense_features_cols.__len__()\n",
    "        self.num_dense_feature = 0#修改\n",
    "        self.num_sparse_feature = config['num_sparse_features_cols']\n",
    "        #self.num_sparse_feature = 0##修改\n",
    "        self.__config=config\n",
    "        \n",
    "        \n",
    "        self.BN_num=nn.BatchNorm1d(self.num_sparse_feature)\n",
    "        self.linear1=nn.Linear(config['num_sparse_features_cols'],config['linear_hidden1'])\n",
    "        self.bn1=nn.BatchNorm1d(config['linear_hidden1'])\n",
    "        self.drop1=nn.Dropout(0.5)\n",
    "        self.relu1=nn.ReLU()\n",
    "        \n",
    "        self.linear2=nn.Linear(config['linear_hidden1']+config['embed_dim'],config['dnn_hidden_units'][0])\n",
    "        self.bn2=nn.BatchNorm1d(config['dnn_hidden_units'][0])\n",
    "        self.drop2=nn.Dropout(0.5)\n",
    "        self.relu2=nn.ReLU()\n",
    "        '''\n",
    "        self.linear3=nn.Linear(config['dnn_hidden_units'][0]+config['embed_dim'],config['dnn_hidden_units'][1])\n",
    "        self.bn3=nn.BatchNorm1d(config['dnn_hidden_units'][1])\n",
    "        #self.drop3=nn.Dropout(0.3)\n",
    "        self.relu3=nn.ReLU()\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        #self.embedding_layers=nn.Embedding(config['embed_input_dim'],config['embed_dim'])\n",
    "        \n",
    "        \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        #self.dnn_softmax=nn.Softmax(dim=1) # 按列SoftMax,列和为1  #注意nn.softmax的定义和调用\n",
    "        #self.dnn_softmax_=F.softmax(dim=1)\n",
    "        #self.dnn_hidden_units=config['dnn_hidden_units']\n",
    "    def forward(self, x,bi_x):\n",
    "        # 先区分出稀疏特征和稠密特征，这里是按照列来划分的，即所有的行都要进行筛选\n",
    "        #bi_x=bi_x.long()\n",
    "        #print(x.dtype)\n",
    "        # 求出线性部分\n",
    "        #x=F.relu(self.drop(self.BN_linear1(self.linear_model1(self.BN_num(x))))\n",
    "        #x=F.relu(self.drop(self.BN_linear1(self.linear_model1(x))))\n",
    "        x=self.BN_num(x)\n",
    "        #x=self.linear_model1(x)\n",
    "        \n",
    "        \n",
    "        #print(\"linear_output:\",linear_output)\n",
    "        #linear_output=linear_output.view(-1,self.__config['linear_hidden1'])\n",
    "        #linear_output=self.drop(linear_output)\n",
    "        #linear_output=self.BN_linear(linear_output)\n",
    "        # 求出稀疏特征的embedding向量\n",
    "        \n",
    "        \n",
    "        #print('bi_out.shape:',bi_out.shape)\n",
    "        #print(x.dtype)\n",
    "        #print(bi_out.dtype)\n",
    "        \n",
    "        #input=x,bi_x#不能是list，必须是tensor\n",
    "        #x1,x2=input\n",
    "        y1=self.relu1(self.drop1(self.bn1(self.linear1(x))))\n",
    "        #print('y1.shape:',y1.shape)\n",
    "        x2=torch.cat((y1,bi_x),dim=1)\n",
    "        y2=self.relu2(self.drop2(self.bn2(self.linear2(x2))))\n",
    "        #print('y2.shape:',y2.shape)\n",
    "        #x3=torch.cat((y2,x2),dim=1)\n",
    "        \n",
    "        y=F.softmax(y2,dim=1)\n",
    "        \n",
    "        y_pred=y\n",
    "        #y_pred=self.dnn_softmax(dnn_output)#增加\n",
    "        #y_pred=F.softmax(dnn_output,dim=0)\n",
    "        # Final\n",
    "        #output = linear_output + y_pred#修改\n",
    "        #y_pred = self.dnn_softmax(output,dim=0)\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acac5f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NFM: NFM(\n",
      "  (BN_num): BatchNorm1d(10477, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (linear1): Linear(in_features=10477, out_features=1000, bias=True)\n",
      "  (bn1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop1): Dropout(p=0.5, inplace=False)\n",
      "  (relu1): ReLU()\n",
      "  (linear2): Linear(in_features=1010, out_features=9, bias=True)\n",
      "  (bn2): BatchNorm1d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop2): Dropout(p=0.5, inplace=False)\n",
      "  (relu2): ReLU()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/.local/lib/python3.6/site-packages/ipykernel_launcher.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/zhengfang/.local/lib/python3.6/site-packages/ipykernel_launcher.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/zhengfang/.local/lib/python3.6/site-packages/ipykernel_launcher.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_train_accuracy: tensor(0.1458, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.2083, device='cuda:0')\n",
      "Training Epoch: 0, total loss: 56.943988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/.local/lib/python3.6/site-packages/ipykernel_launcher.py:94: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/zhengfang/.local/lib/python3.6/site-packages/ipykernel_launcher.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/zhengfang/.local/lib/python3.6/site-packages/ipykernel_launcher.py:96: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_train_accuracy: tensor(0.1490, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.2083, device='cuda:0')\n",
      "Training Epoch: 1, total loss: 56.825853\n",
      "total_train_accuracy: tensor(0.1795, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.2500, device='cuda:0')\n",
      "Training Epoch: 2, total loss: 56.221736\n",
      "total_train_accuracy: tensor(0.1875, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.3750, device='cuda:0')\n",
      "Training Epoch: 3, total loss: 55.700310\n",
      "total_train_accuracy: tensor(0.1923, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.3333, device='cuda:0')\n",
      "Training Epoch: 4, total loss: 56.021870\n",
      "total_train_accuracy: tensor(0.1955, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.2083, device='cuda:0')\n",
      "Training Epoch: 5, total loss: 55.683634\n",
      "total_train_accuracy: tensor(0.2612, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.2500, device='cuda:0')\n",
      "Training Epoch: 6, total loss: 54.984410\n",
      "total_train_accuracy: tensor(0.2115, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.2083, device='cuda:0')\n",
      "Training Epoch: 7, total loss: 55.359940\n",
      "total_train_accuracy: tensor(0.2949, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.2917, device='cuda:0')\n",
      "Training Epoch: 8, total loss: 53.981185\n",
      "total_train_accuracy: tensor(0.2644, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 9, total loss: 54.475414\n",
      "total_train_accuracy: tensor(0.2788, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4583, device='cuda:0')\n",
      "Training Epoch: 10, total loss: 53.915356\n",
      "total_train_accuracy: tensor(0.2917, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.2917, device='cuda:0')\n",
      "Training Epoch: 11, total loss: 53.628687\n",
      "total_train_accuracy: tensor(0.2917, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4583, device='cuda:0')\n",
      "Training Epoch: 12, total loss: 53.391599\n",
      "total_train_accuracy: tensor(0.3189, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.3750, device='cuda:0')\n",
      "Training Epoch: 13, total loss: 53.266093\n",
      "total_train_accuracy: tensor(0.3365, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 14, total loss: 52.999827\n",
      "total_train_accuracy: tensor(0.3045, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.6667, device='cuda:0')\n",
      "Training Epoch: 15, total loss: 53.390362\n",
      "total_train_accuracy: tensor(0.3301, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 16, total loss: 53.055472\n",
      "total_train_accuracy: tensor(0.3494, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.2917, device='cuda:0')\n",
      "Training Epoch: 17, total loss: 52.351170\n",
      "total_train_accuracy: tensor(0.3750, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.3750, device='cuda:0')\n",
      "Training Epoch: 18, total loss: 52.231151\n",
      "total_train_accuracy: tensor(0.3397, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5417, device='cuda:0')\n",
      "Training Epoch: 19, total loss: 52.878617\n",
      "total_train_accuracy: tensor(0.4119, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.3750, device='cuda:0')\n",
      "Training Epoch: 20, total loss: 51.378706\n",
      "total_train_accuracy: tensor(0.3798, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.2917, device='cuda:0')\n",
      "Training Epoch: 21, total loss: 51.815861\n",
      "total_train_accuracy: tensor(0.3830, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 22, total loss: 51.502724\n",
      "total_train_accuracy: tensor(0.3462, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4583, device='cuda:0')\n",
      "Training Epoch: 23, total loss: 52.197440\n",
      "total_train_accuracy: tensor(0.3990, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4167, device='cuda:0')\n",
      "Training Epoch: 24, total loss: 51.533532\n",
      "total_train_accuracy: tensor(0.3638, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4583, device='cuda:0')\n",
      "Training Epoch: 25, total loss: 51.810769\n",
      "total_train_accuracy: tensor(0.4263, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4167, device='cuda:0')\n",
      "Training Epoch: 26, total loss: 50.731123\n",
      "total_train_accuracy: tensor(0.3814, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.7083, device='cuda:0')\n",
      "Training Epoch: 27, total loss: 51.576623\n",
      "total_train_accuracy: tensor(0.3862, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4167, device='cuda:0')\n",
      "Training Epoch: 28, total loss: 51.677249\n",
      "total_train_accuracy: tensor(0.3542, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4167, device='cuda:0')\n",
      "Training Epoch: 29, total loss: 52.044840\n",
      "total_train_accuracy: tensor(0.4103, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5833, device='cuda:0')\n",
      "Training Epoch: 30, total loss: 50.764808\n",
      "total_train_accuracy: tensor(0.3638, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 31, total loss: 51.750782\n",
      "total_train_accuracy: tensor(0.4119, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5417, device='cuda:0')\n",
      "Training Epoch: 32, total loss: 50.744546\n",
      "total_train_accuracy: tensor(0.4439, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5417, device='cuda:0')\n",
      "Training Epoch: 33, total loss: 50.406698\n",
      "total_train_accuracy: tensor(0.4151, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4583, device='cuda:0')\n",
      "Training Epoch: 34, total loss: 50.433570\n",
      "total_train_accuracy: tensor(0.4183, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4583, device='cuda:0')\n",
      "Training Epoch: 35, total loss: 50.582658\n",
      "total_train_accuracy: tensor(0.3798, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 36, total loss: 51.231106\n",
      "total_train_accuracy: tensor(0.4199, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4167, device='cuda:0')\n",
      "Training Epoch: 37, total loss: 50.117425\n",
      "total_train_accuracy: tensor(0.4407, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.6250, device='cuda:0')\n",
      "Training Epoch: 38, total loss: 50.000952\n",
      "total_train_accuracy: tensor(0.4279, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5417, device='cuda:0')\n",
      "Training Epoch: 39, total loss: 50.159599\n",
      "total_train_accuracy: tensor(0.4439, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4167, device='cuda:0')\n",
      "Training Epoch: 40, total loss: 49.916353\n",
      "total_train_accuracy: tensor(0.4183, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4583, device='cuda:0')\n",
      "Training Epoch: 41, total loss: 50.331726\n",
      "total_train_accuracy: tensor(0.4407, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.7083, device='cuda:0')\n",
      "Training Epoch: 42, total loss: 49.701204\n",
      "total_train_accuracy: tensor(0.4551, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4167, device='cuda:0')\n",
      "Training Epoch: 43, total loss: 49.363723\n",
      "total_train_accuracy: tensor(0.4215, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5833, device='cuda:0')\n",
      "Training Epoch: 44, total loss: 50.152527\n",
      "total_train_accuracy: tensor(0.4423, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.7500, device='cuda:0')\n",
      "Training Epoch: 45, total loss: 49.559311\n",
      "total_train_accuracy: tensor(0.4215, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.6667, device='cuda:0')\n",
      "Training Epoch: 46, total loss: 49.983975\n",
      "total_train_accuracy: tensor(0.4119, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 47, total loss: 50.044265\n",
      "total_train_accuracy: tensor(0.4615, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.3750, device='cuda:0')\n",
      "Training Epoch: 48, total loss: 48.925816\n",
      "total_train_accuracy: tensor(0.4744, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 49, total loss: 48.714084\n",
      "total_train_accuracy: tensor(0.4327, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5833, device='cuda:0')\n",
      "Training Epoch: 50, total loss: 49.486666\n",
      "total_train_accuracy: tensor(0.4760, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4583, device='cuda:0')\n",
      "Training Epoch: 51, total loss: 48.605531\n",
      "total_train_accuracy: tensor(0.4696, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 52, total loss: 48.780942\n",
      "total_train_accuracy: tensor(0.5096, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4167, device='cuda:0')\n",
      "Training Epoch: 53, total loss: 47.968748\n",
      "total_train_accuracy: tensor(0.4760, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.3750, device='cuda:0')\n",
      "Training Epoch: 54, total loss: 48.743436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_train_accuracy: tensor(0.4824, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5833, device='cuda:0')\n",
      "Training Epoch: 55, total loss: 48.552345\n",
      "total_train_accuracy: tensor(0.4423, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4167, device='cuda:0')\n",
      "Training Epoch: 56, total loss: 49.220528\n",
      "total_train_accuracy: tensor(0.4599, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.6667, device='cuda:0')\n",
      "Training Epoch: 57, total loss: 48.997712\n",
      "total_train_accuracy: tensor(0.4567, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 58, total loss: 49.041066\n",
      "total_train_accuracy: tensor(0.4760, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4583, device='cuda:0')\n",
      "Training Epoch: 59, total loss: 48.715497\n",
      "total_train_accuracy: tensor(0.4920, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.3333, device='cuda:0')\n",
      "Training Epoch: 60, total loss: 48.130703\n",
      "total_train_accuracy: tensor(0.4471, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4583, device='cuda:0')\n",
      "Training Epoch: 61, total loss: 49.234944\n",
      "total_train_accuracy: tensor(0.4679, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5833, device='cuda:0')\n",
      "Training Epoch: 62, total loss: 48.615113\n",
      "total_train_accuracy: tensor(0.5064, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.6250, device='cuda:0')\n",
      "Training Epoch: 63, total loss: 47.753338\n",
      "total_train_accuracy: tensor(0.4679, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5417, device='cuda:0')\n",
      "Training Epoch: 64, total loss: 48.699452\n",
      "total_train_accuracy: tensor(0.4327, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 65, total loss: 49.355692\n",
      "total_train_accuracy: tensor(0.4776, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4583, device='cuda:0')\n",
      "Training Epoch: 66, total loss: 48.522895\n",
      "total_train_accuracy: tensor(0.4888, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 67, total loss: 47.935555\n",
      "total_train_accuracy: tensor(0.4423, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.3750, device='cuda:0')\n",
      "Training Epoch: 68, total loss: 48.980219\n",
      "total_train_accuracy: tensor(0.4567, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4167, device='cuda:0')\n",
      "Training Epoch: 69, total loss: 48.823505\n",
      "total_train_accuracy: tensor(0.4824, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.6667, device='cuda:0')\n",
      "Training Epoch: 70, total loss: 48.307046\n",
      "total_train_accuracy: tensor(0.4760, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.3333, device='cuda:0')\n",
      "Training Epoch: 71, total loss: 48.330247\n",
      "total_train_accuracy: tensor(0.4439, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5417, device='cuda:0')\n",
      "Training Epoch: 72, total loss: 49.198078\n",
      "total_train_accuracy: tensor(0.4728, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4583, device='cuda:0')\n",
      "Training Epoch: 73, total loss: 48.361655\n",
      "total_train_accuracy: tensor(0.4599, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5417, device='cuda:0')\n",
      "Training Epoch: 74, total loss: 48.728892\n",
      "total_train_accuracy: tensor(0.4728, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.2917, device='cuda:0')\n",
      "Training Epoch: 75, total loss: 48.347848\n",
      "total_train_accuracy: tensor(0.4647, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.6667, device='cuda:0')\n",
      "Training Epoch: 76, total loss: 48.577917\n",
      "total_train_accuracy: tensor(0.4599, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5417, device='cuda:0')\n",
      "Training Epoch: 77, total loss: 48.462533\n",
      "total_train_accuracy: tensor(0.4984, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.2917, device='cuda:0')\n",
      "Training Epoch: 78, total loss: 47.666741\n",
      "total_train_accuracy: tensor(0.4904, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4583, device='cuda:0')\n",
      "Training Epoch: 79, total loss: 47.864579\n",
      "total_train_accuracy: tensor(0.4808, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.6667, device='cuda:0')\n",
      "Training Epoch: 80, total loss: 48.140085\n",
      "total_train_accuracy: tensor(0.5032, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 81, total loss: 47.763037\n",
      "total_train_accuracy: tensor(0.5192, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.3333, device='cuda:0')\n",
      "Training Epoch: 82, total loss: 47.305104\n",
      "total_train_accuracy: tensor(0.4696, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5417, device='cuda:0')\n",
      "Training Epoch: 83, total loss: 48.201341\n",
      "total_train_accuracy: tensor(0.4663, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.3750, device='cuda:0')\n",
      "Training Epoch: 84, total loss: 48.364798\n",
      "total_train_accuracy: tensor(0.4936, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4167, device='cuda:0')\n",
      "Training Epoch: 85, total loss: 47.776668\n",
      "total_train_accuracy: tensor(0.4728, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4167, device='cuda:0')\n",
      "Training Epoch: 86, total loss: 48.129332\n",
      "total_train_accuracy: tensor(0.4615, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.2917, device='cuda:0')\n",
      "Training Epoch: 87, total loss: 48.527788\n",
      "total_train_accuracy: tensor(0.5000, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5417, device='cuda:0')\n",
      "Training Epoch: 88, total loss: 47.734537\n",
      "total_train_accuracy: tensor(0.5000, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5417, device='cuda:0')\n",
      "Training Epoch: 89, total loss: 47.767566\n",
      "total_train_accuracy: tensor(0.5032, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.7083, device='cuda:0')\n",
      "Training Epoch: 90, total loss: 47.696619\n",
      "total_train_accuracy: tensor(0.4904, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5417, device='cuda:0')\n",
      "Training Epoch: 91, total loss: 47.975684\n",
      "total_train_accuracy: tensor(0.4968, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5417, device='cuda:0')\n",
      "Training Epoch: 92, total loss: 47.540188\n",
      "total_train_accuracy: tensor(0.4808, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 93, total loss: 48.250291\n",
      "total_train_accuracy: tensor(0.4904, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4583, device='cuda:0')\n",
      "Training Epoch: 94, total loss: 47.993981\n",
      "total_train_accuracy: tensor(0.4599, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.3333, device='cuda:0')\n",
      "Training Epoch: 95, total loss: 48.499867\n",
      "total_train_accuracy: tensor(0.4792, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.6667, device='cuda:0')\n",
      "Training Epoch: 96, total loss: 48.163550\n",
      "total_train_accuracy: tensor(0.4696, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 97, total loss: 48.177978\n",
      "total_train_accuracy: tensor(0.5000, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 98, total loss: 47.676193\n",
      "total_train_accuracy: tensor(0.4647, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.6250, device='cuda:0')\n",
      "Training Epoch: 99, total loss: 48.447669\n",
      "total_train_accuracy: tensor(0.4583, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5417, device='cuda:0')\n",
      "Training Epoch: 100, total loss: 48.554371\n",
      "total_train_accuracy: tensor(0.4872, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.3750, device='cuda:0')\n",
      "Training Epoch: 101, total loss: 47.886842\n",
      "total_train_accuracy: tensor(0.4808, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5417, device='cuda:0')\n",
      "Training Epoch: 102, total loss: 48.016567\n",
      "total_train_accuracy: tensor(0.4920, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.6250, device='cuda:0')\n",
      "Training Epoch: 103, total loss: 47.868666\n",
      "total_train_accuracy: tensor(0.5000, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.3750, device='cuda:0')\n",
      "Training Epoch: 104, total loss: 47.683004\n",
      "total_train_accuracy: tensor(0.4808, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.2500, device='cuda:0')\n",
      "Training Epoch: 105, total loss: 48.263499\n",
      "total_train_accuracy: tensor(0.5369, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5833, device='cuda:0')\n",
      "Training Epoch: 106, total loss: 46.775490\n",
      "total_train_accuracy: tensor(0.4696, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5417, device='cuda:0')\n",
      "Training Epoch: 107, total loss: 48.221983\n",
      "total_train_accuracy: tensor(0.5208, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5833, device='cuda:0')\n",
      "Training Epoch: 108, total loss: 47.272911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_train_accuracy: tensor(0.5048, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5833, device='cuda:0')\n",
      "Training Epoch: 109, total loss: 47.137747\n",
      "total_train_accuracy: tensor(0.4776, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.3750, device='cuda:0')\n",
      "Training Epoch: 110, total loss: 47.853509\n",
      "total_train_accuracy: tensor(0.4712, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4583, device='cuda:0')\n",
      "Training Epoch: 111, total loss: 47.945816\n",
      "total_train_accuracy: tensor(0.4936, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5417, device='cuda:0')\n",
      "Training Epoch: 112, total loss: 47.738570\n",
      "total_train_accuracy: tensor(0.4984, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 113, total loss: 47.575769\n",
      "total_train_accuracy: tensor(0.4984, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 114, total loss: 47.510371\n",
      "total_train_accuracy: tensor(0.5000, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5417, device='cuda:0')\n",
      "Training Epoch: 115, total loss: 47.873608\n",
      "total_train_accuracy: tensor(0.4968, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4167, device='cuda:0')\n",
      "Training Epoch: 116, total loss: 47.743579\n",
      "total_train_accuracy: tensor(0.4968, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4167, device='cuda:0')\n",
      "Training Epoch: 117, total loss: 47.415156\n",
      "total_train_accuracy: tensor(0.4808, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 118, total loss: 47.965236\n",
      "total_train_accuracy: tensor(0.5304, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.6667, device='cuda:0')\n",
      "Training Epoch: 119, total loss: 46.733242\n",
      "total_train_accuracy: tensor(0.4744, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5417, device='cuda:0')\n",
      "Training Epoch: 120, total loss: 48.218300\n",
      "total_train_accuracy: tensor(0.4888, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 121, total loss: 47.744744\n",
      "total_train_accuracy: tensor(0.4776, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4167, device='cuda:0')\n",
      "Training Epoch: 122, total loss: 47.955709\n",
      "total_train_accuracy: tensor(0.4936, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5417, device='cuda:0')\n",
      "Training Epoch: 123, total loss: 47.603297\n",
      "total_train_accuracy: tensor(0.4872, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5417, device='cuda:0')\n",
      "Training Epoch: 124, total loss: 47.780924\n",
      "total_train_accuracy: tensor(0.4776, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4583, device='cuda:0')\n",
      "Training Epoch: 125, total loss: 47.935632\n",
      "total_train_accuracy: tensor(0.4856, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 126, total loss: 47.904569\n",
      "total_train_accuracy: tensor(0.5385, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 127, total loss: 46.938398\n",
      "total_train_accuracy: tensor(0.4920, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4167, device='cuda:0')\n",
      "Training Epoch: 128, total loss: 47.766034\n",
      "total_train_accuracy: tensor(0.5304, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4583, device='cuda:0')\n",
      "Training Epoch: 129, total loss: 47.008162\n",
      "total_train_accuracy: tensor(0.5064, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.3750, device='cuda:0')\n",
      "Training Epoch: 130, total loss: 47.411316\n",
      "total_train_accuracy: tensor(0.5112, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5833, device='cuda:0')\n",
      "Training Epoch: 131, total loss: 47.149834\n",
      "total_train_accuracy: tensor(0.5192, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.3750, device='cuda:0')\n",
      "Training Epoch: 132, total loss: 46.940515\n",
      "total_train_accuracy: tensor(0.5144, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 133, total loss: 47.450739\n",
      "total_train_accuracy: tensor(0.4952, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5417, device='cuda:0')\n",
      "Training Epoch: 134, total loss: 47.734427\n",
      "total_train_accuracy: tensor(0.4872, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5417, device='cuda:0')\n",
      "Training Epoch: 135, total loss: 47.891198\n",
      "total_train_accuracy: tensor(0.4936, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5417, device='cuda:0')\n",
      "Training Epoch: 136, total loss: 47.457410\n",
      "total_train_accuracy: tensor(0.4936, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4583, device='cuda:0')\n",
      "Training Epoch: 137, total loss: 47.486732\n",
      "total_train_accuracy: tensor(0.5401, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.3750, device='cuda:0')\n",
      "Training Epoch: 138, total loss: 46.812703\n",
      "total_train_accuracy: tensor(0.5064, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.6250, device='cuda:0')\n",
      "Training Epoch: 139, total loss: 47.234586\n",
      "total_train_accuracy: tensor(0.5096, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 140, total loss: 47.399436\n",
      "total_train_accuracy: tensor(0.4856, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5417, device='cuda:0')\n",
      "Training Epoch: 141, total loss: 47.789783\n",
      "total_train_accuracy: tensor(0.5112, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.2917, device='cuda:0')\n",
      "Training Epoch: 142, total loss: 47.101098\n",
      "total_train_accuracy: tensor(0.4968, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 143, total loss: 47.644886\n",
      "total_train_accuracy: tensor(0.5096, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.6667, device='cuda:0')\n",
      "Training Epoch: 144, total loss: 47.227704\n",
      "total_train_accuracy: tensor(0.5048, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.3750, device='cuda:0')\n",
      "Training Epoch: 145, total loss: 47.515454\n",
      "total_train_accuracy: tensor(0.4920, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4167, device='cuda:0')\n",
      "Training Epoch: 146, total loss: 47.662632\n",
      "total_train_accuracy: tensor(0.4856, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.6250, device='cuda:0')\n",
      "Training Epoch: 147, total loss: 47.702874\n",
      "total_train_accuracy: tensor(0.4872, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.6250, device='cuda:0')\n",
      "Training Epoch: 148, total loss: 47.702842\n",
      "total_train_accuracy: tensor(0.5160, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 149, total loss: 47.284859\n",
      "total_train_accuracy: tensor(0.4984, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4583, device='cuda:0')\n",
      "Training Epoch: 150, total loss: 47.474221\n",
      "total_train_accuracy: tensor(0.4920, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4167, device='cuda:0')\n",
      "Training Epoch: 151, total loss: 47.583558\n",
      "total_train_accuracy: tensor(0.4792, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 152, total loss: 48.027287\n",
      "total_train_accuracy: tensor(0.4984, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4583, device='cuda:0')\n",
      "Training Epoch: 153, total loss: 47.377317\n",
      "total_train_accuracy: tensor(0.5080, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4583, device='cuda:0')\n",
      "Training Epoch: 154, total loss: 47.135629\n",
      "total_train_accuracy: tensor(0.5240, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5417, device='cuda:0')\n",
      "Training Epoch: 155, total loss: 47.119275\n",
      "total_train_accuracy: tensor(0.5288, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5833, device='cuda:0')\n",
      "Training Epoch: 156, total loss: 46.883901\n",
      "total_train_accuracy: tensor(0.5256, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.6250, device='cuda:0')\n",
      "Training Epoch: 157, total loss: 46.743110\n",
      "total_train_accuracy: tensor(0.5000, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 158, total loss: 47.348827\n",
      "total_train_accuracy: tensor(0.4856, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.6250, device='cuda:0')\n",
      "Training Epoch: 159, total loss: 47.647143\n",
      "total_train_accuracy: tensor(0.5112, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5833, device='cuda:0')\n",
      "Training Epoch: 160, total loss: 47.227957\n",
      "total_train_accuracy: tensor(0.5160, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.6250, device='cuda:0')\n",
      "Training Epoch: 161, total loss: 47.181599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_train_accuracy: tensor(0.5064, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4583, device='cuda:0')\n",
      "Training Epoch: 162, total loss: 47.326452\n",
      "total_train_accuracy: tensor(0.5192, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.3333, device='cuda:0')\n",
      "Training Epoch: 163, total loss: 47.174931\n",
      "total_train_accuracy: tensor(0.5032, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 164, total loss: 47.286277\n",
      "total_train_accuracy: tensor(0.5208, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4583, device='cuda:0')\n",
      "Training Epoch: 165, total loss: 46.826406\n",
      "total_train_accuracy: tensor(0.4984, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 166, total loss: 47.350659\n",
      "total_train_accuracy: tensor(0.4840, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4167, device='cuda:0')\n",
      "Training Epoch: 167, total loss: 47.804247\n",
      "total_train_accuracy: tensor(0.5080, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5833, device='cuda:0')\n",
      "Training Epoch: 168, total loss: 47.242163\n",
      "total_train_accuracy: tensor(0.5208, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 169, total loss: 46.894364\n",
      "total_train_accuracy: tensor(0.4920, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4583, device='cuda:0')\n",
      "Training Epoch: 170, total loss: 47.595976\n",
      "total_train_accuracy: tensor(0.5048, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5833, device='cuda:0')\n",
      "Training Epoch: 171, total loss: 47.388725\n",
      "total_train_accuracy: tensor(0.4567, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 172, total loss: 48.226437\n",
      "total_train_accuracy: tensor(0.5032, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4167, device='cuda:0')\n",
      "Training Epoch: 173, total loss: 47.310439\n",
      "total_train_accuracy: tensor(0.4760, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5417, device='cuda:0')\n",
      "Training Epoch: 174, total loss: 47.793012\n",
      "total_train_accuracy: tensor(0.5256, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 175, total loss: 46.757093\n",
      "total_train_accuracy: tensor(0.4920, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4167, device='cuda:0')\n",
      "Training Epoch: 176, total loss: 47.596807\n",
      "total_train_accuracy: tensor(0.5048, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4583, device='cuda:0')\n",
      "Training Epoch: 177, total loss: 47.357252\n",
      "total_train_accuracy: tensor(0.4856, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 178, total loss: 47.842323\n",
      "total_train_accuracy: tensor(0.4535, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.4167, device='cuda:0')\n",
      "Training Epoch: 179, total loss: 48.266685\n",
      "total_train_accuracy: tensor(0.5321, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 180, total loss: 46.756073\n",
      "total_train_accuracy: tensor(0.5321, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.6250, device='cuda:0')\n",
      "Training Epoch: 181, total loss: 46.855920\n",
      "total_train_accuracy: tensor(0.5128, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.2917, device='cuda:0')\n",
      "Training Epoch: 182, total loss: 47.092772\n",
      "total_train_accuracy: tensor(0.5000, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 183, total loss: 47.339714\n",
      "total_train_accuracy: tensor(0.4936, device='cuda:0')\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 184, total loss: 47.370633\n"
     ]
    }
   ],
   "source": [
    "train_dataset,train_loader=prepare_dataset(nfm_config['train_data'],nfm_config['train_label'],nfm_config['batch_size'],nfm_config['n_class'])\n",
    "test_dataset,test_loader=prepare_dataset(nfm_config['test_data'],nfm_config['test_label'],nfm_config['batch_size'],nfm_config['n_class'])\n",
    "#from MLP import MLP\n",
    "#from nfm_network_adjust import NFM\n",
    "#model=MLP(4224,1000,100,9)\n",
    "model=NFM(nfm_config)\n",
    "model.cuda()\n",
    "print(\"NFM:\",model)\n",
    "train_data(model,train_loader,test_loader,nfm_config['batch_size'],'dataset/qiuguan/model/NFM_bi_encode_1000_3/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b5fa8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
