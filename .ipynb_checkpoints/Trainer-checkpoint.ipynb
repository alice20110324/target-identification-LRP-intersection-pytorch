{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771b2719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load trainer.py\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def auc(y_pred, y_true):\n",
    "    pred = y_pred.data\n",
    "    y = y_true.data\n",
    "    return roc_auc_score(y, pred)\n",
    "\n",
    "class Trainer(object):\n",
    "    def __init__(self, model, config):\n",
    "        self._model = model\n",
    "        self._config = config\n",
    "        self._optimizer = torch.optim.Adam(self._model.parameters(), lr=config['lr'], weight_decay=config['l2_regularization'])\n",
    "        #self._loss_func = torch.nn.BCELoss()\n",
    "        self._loss_func=nn.CrossEntropyLoss(reduction='mean')\n",
    "    def _train_single_batch(self, x, labels):\n",
    "        \"\"\"\n",
    "        对单个小批量数据进行训练\n",
    "        \"\"\"\n",
    "        self._optimizer.zero_grad()\n",
    "        y_predict = self._model(x)\n",
    "        loss = self._loss_func(y_predict.view(-1), labels)\n",
    "\n",
    "        loss.backward()\n",
    "        self._optimizer.step()\n",
    "\n",
    "        loss = loss.item()\n",
    "        return loss, y_predict\n",
    "\n",
    "    def _train_an_epoch(self, train_loader, epoch_id):\n",
    "        \"\"\"\n",
    "        训练一个Epoch，即将训练集中的所有样本全部都过一遍\n",
    "        \"\"\"\n",
    "        # 设置模型为训练模式，启用dropout以及batch normalization\n",
    "        self._model.train()\n",
    "\n",
    "        total = 0\n",
    "        # 从DataLoader中获取小批量的id以及数据\n",
    "        for batch_id, (x, labels) in enumerate(train_loader):\n",
    "            x = Variable(x)\n",
    "            labels = Variable(labels)\n",
    "            if self._config['use_cuda'] is True:\n",
    "                x, labels = x.cuda(), labels.cuda()\n",
    "\n",
    "            loss, predicted = self._train_single_batch(x, labels)\n",
    "\n",
    "            total += loss\n",
    "            # print('[Training Epoch: {}] Batch: {}, Loss: {}'.format(epoch_id, batch_id, loss))\n",
    "        print(\"Training Epoch: %d, total loss: %f\" % (epoch_id, total))\n",
    "\n",
    "    def train(self, train_dataset):\n",
    "        self.use_cuda()\n",
    "        for epoch in range(self._config['num_epoch']):\n",
    "            print('-' * 20 + ' Epoch {} starts '.format(epoch) + '-' * 20)\n",
    "            # 构造DataLoader\n",
    "            data_loader = DataLoader(dataset=train_dataset, batch_size=self._config['batch_size'], shuffle=True)\n",
    "            # 训练一个轮次\n",
    "            self._train_an_epoch(data_loader, epoch_id=epoch)\n",
    "\n",
    "    def use_cuda(self):\n",
    "        if self._config['use_cuda'] is True:\n",
    "            assert torch.cuda.is_available(), 'CUDA is not available'\n",
    "            torch.cuda.set_device(self._config['device_id'])\n",
    "            self._model.cuda()\n",
    "\n",
    "    def save(self):\n",
    "        self._model.saveModel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
