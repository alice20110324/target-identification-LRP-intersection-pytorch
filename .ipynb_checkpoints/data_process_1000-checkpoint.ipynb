{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e5ca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def normalization(data):\n",
    "    _range = np.max(data) - np.min(data)\n",
    "    #3print(_range)\n",
    "    return (data - np.min(data)) / _range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd1e1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math \n",
    "#file_name='data/frappe/gene_4000/final.csv'\n",
    "#file_name='data/xiaoqiu/train/gene_500_train_data.csv'\n",
    "#file_name='data/xiaoqiu_gene_5000//train/gene_5000_data.csv'\n",
    "#file_name='data/data/guan/data_for_train/datas_no_names.csv'\n",
    "#file_name='data/data/guan/gene_4000/float/float_all_gene_4000_data.csv'\n",
    "#file_name='dataset/xiaoguan/RF/RF_for_train/train_class_9/train/train_data.csv'\n",
    "#file_name='dataset/xiaoguan/RF/RF_for_train/train_class_9/test/test_data.csv'\n",
    "#file_name='dataset/xiaoqiu/train/train_5000_datas.csv'\n",
    "#file_name='dataset/xiaoqiu/test/test_5000_datas.csv'\n",
    "#file_name='dataset/xiaoguan/RF/RF_for_train/train_class_9/test_aug/test_datas.csv'\n",
    "file_name='dataset/qiuguan/non_code/test/test_datas.csv'\n",
    "#import pandas\n",
    "#df = pd.read_csv('../data/XX_FINAL/T_afterBatchEffect_guan_mann.anno1.csv',header=None)\n",
    "#df = pd.read_csv('gene_500_data.csv',header=None)#\n",
    "df = pd.read_csv(file_name,sep=',',header=None)\n",
    "#print(df.shape)\n",
    "'''\n",
    "row,col=df.shape\n",
    "for i in range(col):\n",
    "    if df.iloc[:,i].isnull().values.any():\n",
    "        print(\"T\")\n",
    "        print(i)\n",
    "'''\n",
    "\n",
    "#df=df.iloc[1:,1:]\n",
    "#print(df)\n",
    "\n",
    "#df.drop(df.index[0], inplace=True) #删除第一行(列名)\n",
    "#print(df)\n",
    "\n",
    "#df.drop(df.columns[0], axis=1, inplace=True)       # 删除第1列（行名）\n",
    "#print(df)\n",
    "\n",
    "#删除最后一列\n",
    "#df.drop(df.columns[-1], axis=1, inplace=True)       # 删除第1列（标签）\n",
    "#print(df)\n",
    "#print(df.isnull()==True)\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "\n",
    "#print(df[df.isnull().T.any()])       \n",
    "#print(i)\n",
    "#print(df)\n",
    "n_df=df.values\n",
    "n_df=np.array(n_df,dtype=np.float)\n",
    "#df.astype(float)\n",
    "#print(n_df.shape)\n",
    "\n",
    "print(n_df.dtype)\n",
    "#print('max:',np.max(n_df))\n",
    "print('max:',np.max(n_df))\n",
    "n_n_df=normalization(n_df)#正则化\n",
    "#del n_df\n",
    "print(n_n_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19393c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(n_df))\n",
    "\n",
    "n_n_df=normalization(n_df)#正则化\n",
    "#del n_df\n",
    "print(n_n_df)\n",
    "max_df=np.max(n_n_df)\n",
    "print(max_df)\n",
    "\n",
    "min_df=np.min(n_n_df)\n",
    "print(min_df)\n",
    "\n",
    "numvalue=max_df-min_df\n",
    "#3print(numvalue)\n",
    "\n",
    "split_nums=1000#将最大值和最小值之间的值分成1000份\n",
    "gap=numvalue/split_nums\n",
    "#print(gap)\n",
    "\n",
    "encoded=[0]\n",
    "start=0\n",
    "m=start\n",
    "for i in range(split_nums):#生成间隔列表[0,0,3,0.6,0.9....]\n",
    "    #start=-0.5\n",
    "    m=m+gap\n",
    "    encoded.append(m)\n",
    "#print(encoded)\n",
    "\n",
    "\n",
    "rows,cols=n_n_df.shape\n",
    "#print(rows,cols)\n",
    "print(n_n_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0990266b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#作用是遍历上边处理后的数据中的每一个值，如果它在第n个列表间隔中（encoded），就将n值赋予它\n",
    "import numpy as np\n",
    "#del df_v\n",
    "#df_v=[[0]*cols]*rows#非常重要，这样定义的二维数组值才可以修改#cols代表列，rows代表行，切勿写反了，否则容易出现bug：数组边界溢出\n",
    "#df_v = [ [0] * cols for i in range(50)]#正确\n",
    "#f=[[]]\n",
    "#df_v=np.array(f)\n",
    "vv=[]\n",
    "v=[]\n",
    "#print(df_v)\n",
    "#df_v=np.array(df_v)\n",
    "#print(df_v)\n",
    "#for i in np.nditer(df, op_flags = ['writeonly']):#遍历df中的每一个元素，如果它在encoded的范围内，就给它赋予一个数值，下一步需要将这个数值转换成on-hot编码\n",
    "#for row,u in enumerate(n_n_df[:100,]):#对于特别大的数据，可以按行拆分开分批进行，否则一次难以运行出来\n",
    "for row,u in enumerate(n_n_df):\n",
    "    v=[]\n",
    "    for col,i in enumerate(u): \n",
    "        #print(col,i)\n",
    "        #print(row)\n",
    "        \n",
    "        \n",
    "        #print(\"the number of cols:\",col)\n",
    "        for c,j in enumerate(encoded):\n",
    "            \n",
    "            #if c>0:\n",
    "                #if i>=encoded[c-1]:\n",
    "            if i<=j:\n",
    "                        #print(c)\n",
    "                        #df_value.append(c)\n",
    "                v.append(c)\n",
    "                vv=np.array(v).reshape(1,-1)\n",
    "                        #print(row,col,c)\n",
    "                break;\n",
    "    #print(row,vv)\n",
    "    if row==0:\n",
    "        df_v=vv\n",
    "    else:\n",
    "        print(\"row=\",row,\"col=\",col)\n",
    "        #print(vv)\n",
    "        df_v=np.concatenate([df_v,vv],axis=0)\n",
    "        #print(df_v)\n",
    "                        \n",
    "\n",
    "                        \n",
    "f_df_v=pd.DataFrame(df_v)\n",
    "print(f_df_v)\n",
    "f_df_v.to_csv('dataset/qiuguan/non_code/test/test_encode_data.csv')#将处理后的数据保存到csv中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c9382e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
