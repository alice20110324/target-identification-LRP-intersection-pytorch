{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56782c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import Trainer\n",
    "from network import NFM\n",
    "import torch.utils.data as Data\n",
    "from Utils.criteo_loader import getTestData, getTrainData\n",
    "\n",
    "nfm_config = \\\n",
    "{\n",
    "    'n_class':8,\n",
    "    'linear_hidden':100,#线性模型输出层（隐层个数）\n",
    "    'embed_input_dim':1001,#embed输入维度\n",
    "    'embed_dim': 100, # 用于控制稀疏特征经过Embedding层后的稠密特征大小，embed输出维度\n",
    "    'dnn_hidden_units': [50,8],#MLP隐层和输出层\n",
    "    'num_sparse_features_cols':538,#the number of the gene columns\n",
    "    'num_dense_features': 0,#dense features number\n",
    "    'bi_dropout': 0.8,#Bi-Interaction 的dropout\n",
    "    'num_epoch': 500,#训练epoch次数\n",
    "    'batch_size': 100,#batch_size\n",
    "    'lr': 1e-3,\n",
    "    'l2_regularization': 1e-4,\n",
    "    'device_id': 0,\n",
    "    'use_cuda': False\n",
    "    #'train_file': '../Data/criteo/processed_data/train_set.csv',\n",
    "    #'fea_file': '../Data/criteo/processed_data/fea_col.npy',\n",
    "    #'validate_file': '../Data/criteo/processed_data/val_set.csv',\n",
    "    #'test_file': '../Data/criteo/processed_data/test_set.csv',\n",
    "    #'model_name': '../TrainedModels/NFM.model'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a85bb269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.backends.cudnn as cudnn\n",
    "#3from tensorboardX import SummaryWriter\n",
    "\n",
    "#import network\n",
    "import config\n",
    "import evaluate\n",
    "import data_utils\n",
    "import Trainer\n",
    "#from utils import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07442345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "205edc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row: 0 label: [0]\n",
      "row: 1 label: [0]\n",
      "row: 2 label: [0]\n",
      "row: 3 label: [0]\n",
      "row: 4 label: [0]\n",
      "row: 5 label: [0]\n",
      "row: 6 label: [0]\n",
      "row: 7 label: [0]\n",
      "row: 8 label: [0]\n",
      "row: 9 label: [0]\n",
      "row: 10 label: [0]\n",
      "row: 11 label: [0]\n",
      "row: 12 label: [0]\n",
      "row: 13 label: [0]\n",
      "row: 14 label: [0]\n",
      "row: 15 label: [0]\n",
      "row: 16 label: [0]\n",
      "row: 17 label: [0]\n",
      "row: 18 label: [0]\n",
      "row: 19 label: [0]\n",
      "row: 20 label: [0]\n",
      "row: 21 label: [0]\n",
      "row: 22 label: [0]\n",
      "row: 23 label: [0]\n",
      "row: 24 label: [0]\n",
      "row: 25 label: [0]\n",
      "row: 26 label: [0]\n",
      "row: 27 label: [0]\n",
      "row: 28 label: [0]\n",
      "row: 29 label: [0]\n",
      "row: 30 label: [0]\n",
      "row: 31 label: [0]\n",
      "row: 32 label: [0]\n",
      "row: 33 label: [0]\n",
      "row: 34 label: [0]\n",
      "row: 35 label: [0]\n",
      "row: 36 label: [0]\n",
      "row: 37 label: [0]\n",
      "row: 38 label: [0]\n",
      "row: 39 label: [0]\n",
      "row: 40 label: [0]\n",
      "row: 41 label: [0]\n",
      "row: 42 label: [0]\n",
      "row: 43 label: [0]\n",
      "row: 44 label: [0]\n",
      "row: 45 label: [0]\n",
      "row: 46 label: [0]\n",
      "row: 47 label: [0]\n",
      "row: 48 label: [0]\n",
      "row: 49 label: [0]\n",
      "row: 50 label: [0]\n",
      "row: 51 label: [0]\n",
      "row: 52 label: [0]\n",
      "row: 53 label: [0]\n",
      "row: 54 label: [0]\n",
      "row: 55 label: [0]\n",
      "row: 56 label: [0]\n",
      "row: 57 label: [1]\n",
      "row: 58 label: [1]\n",
      "row: 59 label: [1]\n",
      "row: 60 label: [1]\n",
      "row: 61 label: [2]\n",
      "row: 62 label: [2]\n",
      "row: 63 label: [2]\n",
      "row: 64 label: [2]\n",
      "row: 65 label: [2]\n",
      "row: 66 label: [2]\n",
      "row: 67 label: [2]\n",
      "row: 68 label: [2]\n",
      "row: 69 label: [2]\n",
      "row: 70 label: [2]\n",
      "row: 71 label: [2]\n",
      "row: 72 label: [2]\n",
      "row: 73 label: [2]\n",
      "row: 74 label: [2]\n",
      "row: 75 label: [2]\n",
      "row: 76 label: [2]\n",
      "row: 77 label: [2]\n",
      "row: 78 label: [2]\n",
      "row: 79 label: [2]\n",
      "row: 80 label: [2]\n",
      "row: 81 label: [2]\n",
      "row: 82 label: [2]\n",
      "row: 83 label: [2]\n",
      "row: 84 label: [2]\n",
      "row: 85 label: [2]\n",
      "row: 86 label: [2]\n",
      "row: 87 label: [2]\n",
      "row: 88 label: [2]\n",
      "row: 89 label: [2]\n",
      "row: 90 label: [2]\n",
      "row: 91 label: [2]\n",
      "row: 92 label: [2]\n",
      "row: 93 label: [2]\n",
      "row: 94 label: [2]\n",
      "row: 95 label: [2]\n",
      "row: 96 label: [3]\n",
      "row: 97 label: [3]\n",
      "row: 98 label: [3]\n",
      "row: 99 label: [3]\n",
      "row: 100 label: [3]\n",
      "row: 101 label: [3]\n",
      "row: 102 label: [3]\n",
      "row: 103 label: [3]\n",
      "row: 104 label: [3]\n",
      "row: 105 label: [3]\n",
      "row: 106 label: [3]\n",
      "row: 107 label: [3]\n",
      "row: 108 label: [3]\n",
      "row: 109 label: [3]\n",
      "row: 110 label: [3]\n",
      "row: 111 label: [3]\n",
      "row: 112 label: [3]\n",
      "row: 113 label: [3]\n",
      "row: 114 label: [3]\n",
      "row: 115 label: [3]\n",
      "row: 116 label: [3]\n",
      "row: 117 label: [3]\n",
      "row: 118 label: [3]\n",
      "row: 119 label: [3]\n",
      "row: 120 label: [3]\n",
      "row: 121 label: [3]\n",
      "row: 122 label: [3]\n",
      "row: 123 label: [3]\n",
      "row: 124 label: [3]\n",
      "row: 125 label: [3]\n",
      "row: 126 label: [3]\n",
      "row: 127 label: [3]\n",
      "row: 128 label: [3]\n",
      "row: 129 label: [3]\n",
      "row: 130 label: [3]\n",
      "row: 131 label: [3]\n",
      "row: 132 label: [3]\n",
      "row: 133 label: [3]\n",
      "row: 134 label: [3]\n",
      "row: 135 label: [3]\n",
      "row: 136 label: [3]\n",
      "row: 137 label: [3]\n",
      "row: 138 label: [3]\n",
      "row: 139 label: [3]\n",
      "row: 140 label: [3]\n",
      "row: 141 label: [3]\n",
      "row: 142 label: [3]\n",
      "row: 143 label: [3]\n",
      "row: 144 label: [3]\n",
      "row: 145 label: [3]\n",
      "row: 146 label: [3]\n",
      "row: 147 label: [3]\n",
      "row: 148 label: [3]\n",
      "row: 149 label: [3]\n",
      "row: 150 label: [3]\n",
      "row: 151 label: [3]\n",
      "row: 152 label: [3]\n",
      "row: 153 label: [3]\n",
      "row: 154 label: [3]\n",
      "row: 155 label: [3]\n",
      "row: 156 label: [3]\n",
      "row: 157 label: [3]\n",
      "row: 158 label: [3]\n",
      "row: 159 label: [3]\n",
      "row: 160 label: [3]\n",
      "row: 161 label: [3]\n",
      "row: 162 label: [3]\n",
      "row: 163 label: [3]\n",
      "row: 164 label: [3]\n",
      "row: 165 label: [3]\n",
      "row: 166 label: [3]\n",
      "row: 167 label: [3]\n",
      "row: 168 label: [3]\n",
      "row: 169 label: [3]\n",
      "row: 170 label: [3]\n",
      "row: 171 label: [3]\n",
      "row: 172 label: [3]\n",
      "row: 173 label: [3]\n",
      "row: 174 label: [3]\n",
      "row: 175 label: [3]\n",
      "row: 176 label: [3]\n",
      "row: 177 label: [3]\n",
      "row: 178 label: [3]\n",
      "row: 179 label: [3]\n",
      "row: 180 label: [3]\n",
      "row: 181 label: [3]\n",
      "row: 182 label: [3]\n",
      "row: 183 label: [3]\n",
      "row: 184 label: [3]\n",
      "row: 185 label: [3]\n",
      "row: 186 label: [3]\n",
      "row: 187 label: [3]\n",
      "row: 188 label: [3]\n",
      "row: 189 label: [3]\n",
      "row: 190 label: [3]\n",
      "row: 191 label: [3]\n",
      "row: 192 label: [3]\n",
      "row: 193 label: [3]\n",
      "row: 194 label: [3]\n",
      "row: 195 label: [3]\n",
      "row: 196 label: [3]\n",
      "row: 197 label: [3]\n",
      "row: 198 label: [3]\n",
      "row: 199 label: [3]\n",
      "row: 200 label: [3]\n",
      "row: 201 label: [3]\n",
      "row: 202 label: [3]\n",
      "row: 203 label: [3]\n",
      "row: 204 label: [3]\n",
      "row: 205 label: [3]\n",
      "row: 206 label: [3]\n",
      "row: 207 label: [3]\n",
      "row: 208 label: [3]\n",
      "row: 209 label: [3]\n",
      "row: 210 label: [3]\n",
      "row: 211 label: [3]\n",
      "row: 212 label: [3]\n",
      "row: 213 label: [3]\n",
      "row: 214 label: [3]\n",
      "row: 215 label: [3]\n",
      "row: 216 label: [3]\n",
      "row: 217 label: [3]\n",
      "row: 218 label: [3]\n",
      "row: 219 label: [3]\n",
      "row: 220 label: [3]\n",
      "row: 221 label: [3]\n",
      "row: 222 label: [3]\n",
      "row: 223 label: [3]\n",
      "row: 224 label: [3]\n",
      "row: 225 label: [3]\n",
      "row: 226 label: [3]\n",
      "row: 227 label: [3]\n",
      "row: 228 label: [3]\n",
      "row: 229 label: [3]\n",
      "row: 230 label: [3]\n",
      "row: 231 label: [3]\n",
      "row: 232 label: [3]\n",
      "row: 233 label: [3]\n",
      "row: 234 label: [3]\n",
      "row: 235 label: [3]\n",
      "row: 236 label: [3]\n",
      "row: 237 label: [3]\n",
      "row: 238 label: [3]\n",
      "row: 239 label: [3]\n",
      "row: 240 label: [3]\n",
      "row: 241 label: [3]\n",
      "row: 242 label: [3]\n",
      "row: 243 label: [3]\n",
      "row: 244 label: [3]\n",
      "row: 245 label: [3]\n",
      "row: 246 label: [3]\n",
      "row: 247 label: [3]\n",
      "row: 248 label: [3]\n",
      "row: 249 label: [3]\n",
      "row: 250 label: [3]\n",
      "row: 251 label: [3]\n",
      "row: 252 label: [3]\n",
      "row: 253 label: [3]\n",
      "row: 254 label: [3]\n",
      "row: 255 label: [3]\n",
      "row: 256 label: [3]\n",
      "row: 257 label: [3]\n",
      "row: 258 label: [3]\n",
      "row: 259 label: [3]\n",
      "row: 260 label: [3]\n",
      "row: 261 label: [3]\n",
      "row: 262 label: [3]\n",
      "row: 263 label: [3]\n",
      "row: 264 label: [3]\n",
      "row: 265 label: [3]\n",
      "row: 266 label: [3]\n",
      "row: 267 label: [3]\n",
      "row: 268 label: [3]\n",
      "row: 269 label: [3]\n",
      "row: 270 label: [3]\n",
      "row: 271 label: [3]\n",
      "row: 272 label: [3]\n",
      "row: 273 label: [3]\n",
      "row: 274 label: [4]\n",
      "row: 275 label: [4]\n",
      "row: 276 label: [4]\n",
      "row: 277 label: [4]\n",
      "row: 278 label: [4]\n",
      "row: 279 label: [4]\n",
      "row: 280 label: [4]\n",
      "row: 281 label: [4]\n",
      "row: 282 label: [5]\n",
      "row: 283 label: [5]\n",
      "row: 284 label: [5]\n",
      "row: 285 label: [5]\n",
      "row: 286 label: [5]\n",
      "row: 287 label: [5]\n",
      "row: 288 label: [5]\n",
      "row: 289 label: [5]\n",
      "row: 290 label: [5]\n",
      "row: 291 label: [5]\n",
      "row: 292 label: [5]\n",
      "row: 293 label: [5]\n",
      "row: 294 label: [5]\n",
      "row: 295 label: [5]\n",
      "row: 296 label: [5]\n",
      "row: 297 label: [5]\n",
      "row: 298 label: [5]\n",
      "row: 299 label: [5]\n",
      "row: 300 label: [5]\n",
      "row: 301 label: [5]\n",
      "row: 302 label: [5]\n",
      "row: 303 label: [5]\n",
      "row: 304 label: [5]\n",
      "row: 305 label: [5]\n",
      "row: 306 label: [5]\n",
      "row: 307 label: [5]\n",
      "row: 308 label: [5]\n",
      "row: 309 label: [5]\n",
      "row: 310 label: [5]\n",
      "row: 311 label: [5]\n",
      "row: 312 label: [5]\n",
      "row: 313 label: [5]\n",
      "row: 314 label: [5]\n",
      "row: 315 label: [5]\n",
      "row: 316 label: [5]\n",
      "row: 317 label: [5]\n",
      "row: 318 label: [5]\n",
      "row: 319 label: [5]\n",
      "row: 320 label: [5]\n",
      "row: 321 label: [5]\n",
      "row: 322 label: [5]\n",
      "row: 323 label: [6]\n",
      "row: 324 label: [6]\n",
      "row: 325 label: [6]\n",
      "row: 326 label: [6]\n",
      "row: 327 label: [6]\n",
      "row: 328 label: [6]\n",
      "row: 329 label: [6]\n",
      "row: 330 label: [6]\n",
      "row: 331 label: [6]\n",
      "row: 332 label: [6]\n",
      "row: 333 label: [6]\n",
      "row: 334 label: [6]\n",
      "row: 335 label: [6]\n",
      "row: 336 label: [6]\n",
      "row: 337 label: [6]\n",
      "row: 338 label: [6]\n",
      "row: 339 label: [6]\n",
      "row: 340 label: [6]\n",
      "row: 341 label: [6]\n",
      "row: 342 label: [6]\n",
      "row: 343 label: [6]\n",
      "row: 344 label: [6]\n",
      "row: 345 label: [6]\n",
      "row: 346 label: [6]\n",
      "row: 347 label: [6]\n",
      "row: 348 label: [6]\n",
      "row: 349 label: [6]\n",
      "row: 350 label: [6]\n",
      "row: 351 label: [6]\n",
      "row: 352 label: [6]\n",
      "row: 353 label: [6]\n",
      "row: 354 label: [6]\n",
      "row: 355 label: [6]\n",
      "row: 356 label: [6]\n",
      "row: 357 label: [6]\n",
      "row: 358 label: [6]\n",
      "row: 359 label: [6]\n",
      "row: 360 label: [6]\n",
      "row: 361 label: [6]\n",
      "row: 362 label: [6]\n",
      "row: 363 label: [6]\n",
      "row: 364 label: [6]\n",
      "row: 365 label: [6]\n",
      "row: 366 label: [6]\n",
      "row: 367 label: [6]\n",
      "row: 368 label: [6]\n",
      "row: 369 label: [6]\n",
      "row: 370 label: [6]\n",
      "row: 371 label: [6]\n",
      "row: 372 label: [6]\n",
      "row: 373 label: [6]\n",
      "row: 374 label: [6]\n",
      "row: 375 label: [6]\n",
      "row: 376 label: [6]\n",
      "row: 377 label: [6]\n",
      "row: 378 label: [6]\n",
      "row: 379 label: [6]\n",
      "row: 380 label: [6]\n",
      "row: 381 label: [6]\n",
      "row: 382 label: [6]\n",
      "row: 383 label: [6]\n",
      "row: 384 label: [6]\n",
      "row: 385 label: [6]\n",
      "row: 386 label: [6]\n",
      "row: 387 label: [6]\n",
      "row: 388 label: [6]\n",
      "row: 389 label: [6]\n",
      "row: 390 label: [6]\n",
      "row: 391 label: [6]\n",
      "row: 392 label: [6]\n",
      "row: 393 label: [6]\n",
      "row: 394 label: [6]\n",
      "row: 395 label: [6]\n",
      "row: 396 label: [6]\n",
      "row: 397 label: [6]\n",
      "row: 398 label: [6]\n",
      "row: 399 label: [7]\n",
      "row: 400 label: [7]\n",
      "row: 401 label: [7]\n",
      "row: 402 label: [7]\n",
      "row: 403 label: [7]\n",
      "row: 404 label: [7]\n",
      "row: 405 label: [7]\n",
      "row: 406 label: [7]\n",
      "row: 407 label: [7]\n",
      "row: 408 label: [7]\n",
      "row: 409 label: [7]\n",
      "row: 410 label: [7]\n",
      "row: 411 label: [7]\n",
      "row: 412 label: [7]\n",
      "row: 413 label: [7]\n",
      "row: 414 label: [7]\n",
      "row: 415 label: [7]\n",
      "row: 416 label: [7]\n",
      "row: 417 label: [7]\n",
      "row: 418 label: [7]\n",
      "row: 419 label: [7]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 8 is out of bounds for axis 1 with size 8",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d93a0c06536f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset_process\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFMData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFMData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_libfm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnfm_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NFM-pyorch-master/NFM-pyorch-master/dataset_process.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, label_file, n_class)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_fd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"label:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NFM-pyorch-master/NFM-pyorch-master/dataset_process.py\u001b[0m in \u001b[0;36mone_hot\u001b[0;34m(labels, classes, label_smoothing)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0meoff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlabel_smoothing\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meoff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"row:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"label:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 8 is out of bounds for axis 1 with size 8"
     ]
    }
   ],
   "source": [
    "from dataset_process import FMData\n",
    "\n",
    "train_dataset = FMData(config.train_libfm,config.train_label,nfm_config['n_class'])\n",
    "train_loader = data.DataLoader(train_dataset, drop_last=True,batch_size=100,shuffle=True, num_workers=4)\n",
    "\n",
    "#validate_dataset = FMData(config.valid_libfm,config.valid_label)\n",
    "#validate_loader = data.DataLoader(train_dataset, drop_last=True,batch_size=100,shuffle=True, num_workers=4)\n",
    "\n",
    "#test_dataset = FMData(config.test_libfm,config.test_label)\n",
    "#test_loader = data.DataLoader(test_dataset, drop_last=True,batch_size=100,shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdb60202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nfm: NFM(\n",
      "  (drop): Dropout(p=0.7, inplace=False)\n",
      "  (linear_model): Linear(in_features=538, out_features=100, bias=True)\n",
      "  (BN_linear): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (embedding_layers): Embedding(1001, 100)\n",
      "  (bi_pooling): BiInteractionPooling()\n",
      "  (dropout): Dropout(p=0.8, inplace=False)\n",
      "  (BN_bi): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dnn_layers): ModuleList(\n",
      "    (0): Linear(in_features=200, out_features=50, bias=True)\n",
      "    (1): Linear(in_features=50, out_features=8, bias=True)\n",
      "  )\n",
      "  (dnn_softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-53d3be5d3289>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mcorrect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from nfm_network import NFM\n",
    "if __name__ == \"__main__\":\n",
    "    ####################################################################################\n",
    "    # NFM 模型\n",
    "    ####################################################################################\n",
    "    BATCH_SIZE=100\n",
    "    \"\"\"\n",
    "    training_data, training_label, dense_features_col, sparse_features_col = getTrainData(nfm_config['train_file'], nfm_config['fea_file'])\n",
    "    train_dataset = Data.TensorDataset(torch.tensor(training_data).float(), torch.tensor(training_label).float())\n",
    "\n",
    "    test_data = getTestData(nfm_config['test_file'])\n",
    "    test_dataset = Data.TensorDataset(torch.tensor(test_data).float())\n",
    "    \n",
    "    test_data = getTestData(nfm_config['test_file'])\n",
    "    test_dataset = Data.TensorDataset(torch.tensor(test_data).float())\n",
    "\n",
    "    \"\"\"\n",
    "    #device = torch.device('cuda:0')\n",
    "    #epoch=0\n",
    "    \n",
    "    #model=nn.Linear(10149,16).to(device)\n",
    "    #model=nn.Linear(10149,16)\n",
    "    #model=nn.ReLU(nn.Linear(10149,16))#RuntimeError: all elements of input should be between 0 and 1\n",
    "    #print('model:',model)\n",
    "    nfm = NFM(nfm_config).cuda()#加了device防止出现GPU CPU两种设备的错误提示\n",
    "    print(\"nfm:\",nfm)\n",
    "    #print(nfm)\n",
    "    #nfm.train()\n",
    "    #u=nfm.parameters()\n",
    "    #print(u)\n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr=nfm_config['lr'], weight_decay=nfm_config['l2_regularization'])\n",
    "    optimizer = torch.optim.Adam(nfm.parameters(), lr=nfm_config['lr'], weight_decay=nfm_config['l2_regularization'])\n",
    "    total = 0\n",
    "    #loss_func = torch.nn.BCELoss()\n",
    "    loss_func=torch.nn.CrossEntropyLoss()\n",
    "    #loss_func=torch.nn.LogSoftmax()\n",
    "    \n",
    "    #model=nn.Softmax(nn.Linear(10149,16)).to(device)\n",
    "    # 从DataLoader中获取小批量的id以及数据\n",
    "    for epoch_id in range(100):\n",
    "        correct=0\n",
    "        total=0\n",
    "        for batch_idx, (x, labels) in enumerate(train_loader):\n",
    "            x = Variable(x)\n",
    "            labels = Variable(labels)\n",
    "            \n",
    "            \n",
    "            #x = torch.tensor(x, dtype=torch.float)\n",
    "            #x=x.clone().detach().requires_grad_(True)\n",
    "            x=torch.tensor(x,dtype=torch.float)\n",
    "            labels=torch.tensor(labels,dtype=torch.float)\n",
    "            x, labels = x.cuda(), labels.cuda()\n",
    "            \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_predict = nfm(x)\n",
    "            #loss = loss_func(y_predict.view(-1), labels)\n",
    "            loss = loss_func(y_predict, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss = loss.item()\n",
    "            #loss, predicted = self._train_single_batch(x, labels)\n",
    "\n",
    "            total += loss\n",
    "            \n",
    "            \n",
    "            \n",
    "            predicted = torch.max(y_predict.data,1)\n",
    "            #print(\"predicted:\",predicted)\n",
    "            predicted = torch.max(y_predict.data,1)[1]\n",
    "            \n",
    "            \n",
    "            labels=torch.max(labels,1)\n",
    "            #print(\"labels:\",labels)\n",
    "            labels=labels[1]\n",
    "            \n",
    "            correct += (predicted == labels).sum()\n",
    "            #print(\"correct:\",correct)\n",
    "            #correct=correct[0]\n",
    "            print(\"new_correct:\",float(correct))\n",
    "            correct=float(correct)   \n",
    "            #if batch_idx % 10 == 0:\n",
    "            print(\"batch_idx:\",batch_idx)\n",
    "            print(correct/(BATCH_SIZE*(batch_idx+1)))\n",
    "            \n",
    "            \"\"\"\n",
    "            #y_predict.detach().numpy()\n",
    "            pred = y_predict\n",
    "            print(\"pred:\",pred.shape)\n",
    "            y=labels.clone().detach().requires_grad_(True)\n",
    "            print(\"y:\",y.shape)\n",
    "            #y=labels.data.cpu().numpy()\n",
    "            #y = labels.detach().numpy()\n",
    "            roc_auc_score(y, pred)\n",
    "            \"\"\"\n",
    "           \n",
    "            # print('[Training Epoch: {}] Batch: {}, Loss: {}'.format(epoch_id, batch_id, loss))\n",
    "        print(\"Training Epoch: %d, total loss: %f\" % (epoch_id, total))\n",
    "        #print(\"auc:\",roc_auc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ed7abc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
