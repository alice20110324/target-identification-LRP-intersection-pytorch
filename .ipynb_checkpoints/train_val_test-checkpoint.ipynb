{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac1a7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from new_nfm_network import NFM\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.backends.cudnn as cudnn\n",
    "#3from tensorboardX import SummaryWriter\n",
    "import sys \n",
    "#import network\n",
    "import config\n",
    "import evaluate\n",
    "import data_utils\n",
    "import Trainer\n",
    "import torchmetrics\n",
    "#LRP\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "%matplotlib inline\n",
    "\n",
    "from innvestigator import InnvestigateModel\n",
    "from utils import Flatten\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_epoch(model,train_loader,batch_size,optimizer,loss_func):\n",
    "    BATCH_SIZE=batch_size\n",
    "    total = 0\n",
    "    correct=0\n",
    "    total_loss=0\n",
    "    #loss_score=torch.tensor([[]]).cuda()\n",
    "    #\n",
    "    #loss_op=0\n",
    "    loss2_list=[]\n",
    "    model.train()\n",
    "    total_train_accuracy=0  \n",
    "    for batch_idx, (x, labels) in enumerate(train_loader):\n",
    "            \n",
    "        labels = Variable(labels)\n",
    "        x = Variable(x)\n",
    "            \n",
    "        x_row,x_col=x.shape   \n",
    "        x=torch.tensor(x,dtype=torch.float)\n",
    "        #print(x.shape)\n",
    "        labels=torch.tensor(labels,dtype=torch.float)\n",
    "        x, labels = x.cuda(), labels.cuda()\n",
    "        labels_int=labels=torch.max(labels,1)[1]#########\n",
    "        #print(labels_int)\n",
    "        #print('labels_int:',labels_int.shape)\n",
    "        #print('labels:',labels) \n",
    "        #print('x:',x.shape)\n",
    "        loss_op=0\n",
    "       \n",
    "        optimizer.zero_grad()\n",
    "        y_predict = model(x)\n",
    "        \n",
    "        loss1 = loss_func(y_predict, labels)\n",
    "        #loss2=u*(1/loss_op)\n",
    "        #print('input_relevance_values:',input_relevance_values.shape)\n",
    "        #print('loss_score:',loss_score.shape)\n",
    "        \n",
    "        #print('input_relevance_values:',input_relevance_values)\n",
    "        loss=loss1\n",
    "        #loss = loss_func(y_predict, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #loss2_list.append(u*loss2)   \n",
    "        loss = loss.item()\n",
    "           \n",
    "\n",
    "        total_loss += loss\n",
    "            \n",
    "            \n",
    "            \n",
    "        batch_train_acc=torchmetrics.functional.accuracy(y_predict,labels_int)\n",
    "        total_train_accuracy+=batch_train_acc\n",
    "    #plotLoss(loss2_list,batch_idx+1)   #################################     \n",
    "    total_train_accuracy/=(batch_idx+1)\n",
    "    print('total_train_accuracy:',total_train_accuracy)\n",
    "    print(\"Training Epoch: %d, total loss: %f\" % (epoch_id, total_loss))\n",
    "    return total_loss,total_train_accuracy\n",
    "\n",
    "def val_epoch(model,test_loader,batch_size,optimizer): \n",
    "    batch_size_num=0\n",
    "    total_test_acc=0\n",
    "    model.eval()\n",
    "    for i , (inputs , targets) in enumerate(test_loader):   \n",
    "            print(\"test\")\n",
    "            \n",
    "            inputs = Variable(inputs)   \n",
    "            targets = Variable(targets)     \n",
    "           \n",
    "            inputs=torch.tensor(inputs ,dtype=torch.float)   \n",
    "            targets=torch.tensor(targets ,dtype=torch.float)   \n",
    "            inputs , targets = inputs.cuda(),  targets.cuda()   \n",
    "            yhat = model(inputs)  \n",
    "            \n",
    "            \n",
    "            \n",
    "            targets=torch.max(targets,1)[1]\n",
    "            \n",
    "            \n",
    "            \n",
    "            batch_test_acc=torchmetrics.functional.accuracy(yhat,targets)\n",
    "            \n",
    "            total_test_acc+=batch_test_acc\n",
    "            \n",
    "            batch_size_num=i\n",
    "    total_test_acc/=(batch_size_num+1)\n",
    "        ###print('total_test_accuracy:',total_test_acc/(batch_size+1))\n",
    "    print('total_test_accuracy:',total_test_acc)\n",
    "        \n",
    "                    \n",
    "                    \n",
    "            \n",
    "            \n",
    "    \n",
    "        \n",
    "   \n",
    "    \n",
    "    return total_test_acc\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84be8728",
   "metadata": {},
   "outputs": [],
   "source": [
    "from innvestigator import InnvestigateModel\n",
    "from utils import Flatten\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_IA_epoch(model,train_loader,batch_size,optimizer,loss_func):\n",
    "    \n",
    "    BATCH_SIZE=batch_size\n",
    "    total = 0\n",
    "    correct=0\n",
    "    total_loss=0\n",
    "    #loss_score=torch.tensor([[]]).cuda()\n",
    "    #\n",
    "    #loss_op=0\n",
    "    loss2_list=[]\n",
    "    model.train()\n",
    "    total_train_accuracy=0  \n",
    "    for batch_idx, (x, labels) in enumerate(train_loader):\n",
    "            \n",
    "        labels = Variable(labels)\n",
    "        x = Variable(x)\n",
    "            \n",
    "        x_row,x_col=x.shape   \n",
    "        x=torch.tensor(x,dtype=torch.float)\n",
    "        #print(x.shape)\n",
    "        labels=torch.tensor(labels,dtype=torch.float)\n",
    "        x, labels = x.cuda(), labels.cuda()\n",
    "        labels_int=labels=torch.max(labels,1)[1]#########labels已经变成了类别0，1，2，3，4，。。。。。。。，not one_hot\n",
    "        #print(labels_int)\n",
    "        #print('labels_int:',labels_int.shape)\n",
    "        #print('labels:',labels) \n",
    "        #print('x:',x.shape)\n",
    "        loss_op=0\n",
    "       \n",
    "        loss1=0\n",
    "        \n",
    "        \n",
    "        pre_tar=[[0]*9]*batch_size\n",
    "        pre_target=torch.tensor(pre_tar,dtype=torch.float)#dtype非常重要，否则就四舍五入为0，因为上边定义的0是整型#torch.float,not float\n",
    "        #print(pre_target)\n",
    "        pre_target=pre_target.cuda()\n",
    "        \n",
    "        \n",
    "        #print(labels.shape,labels)   \n",
    "        model_prediction, input_relevance_values = inn_model.innvestigate(in_tensor=x, rel_for_class=None,target=None)\n",
    "        #print(\"torch.argmax(labels[batch_idx]):\",torch.argmax(labels[batch_idx]))\n",
    "        #print(model_prediction.shape, model_prediction)\n",
    "        model_prediction.cuda()\n",
    "        \n",
    "       \n",
    "        for i in range(batch_size):\n",
    "            max_pre=torch.argmax(model_prediction[i])\n",
    "            if max_pre==labels[i]:\n",
    "                \n",
    "                input_relevance_values[i]=input_relevance_values[i].exp()\n",
    "                x[i]=torch.mul(x[i],input_relevance_values[i])+torch.tensor(0.1,dtype=torch.float)##############注意力\n",
    "                #print('pre_target:',pre_target[i])\n",
    "            else:\n",
    "                \n",
    "                x[i]=x[i]\n",
    "                    \n",
    "        optimizer.zero_grad()\n",
    "        y_predict=model(x)\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        loss1 = loss_func(y_predict, labels)\n",
    "        #loss2=u*(1/loss_op)\n",
    "        #print('input_relevance_values:',input_relevance_values.shape)\n",
    "        #print('loss_score:',loss_score.shape)\n",
    "        \n",
    "        #print('input_relevance_values:',input_relevance_values)\n",
    "        loss=loss1\n",
    "        #loss = loss_func(y_predict, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #loss2_list.append(u*loss2)   \n",
    "        loss = loss.item()\n",
    "           \n",
    "\n",
    "        total_loss += loss\n",
    "            \n",
    "            \n",
    "            \n",
    "        batch_train_acc=torchmetrics.functional.accuracy(y_predict,labels_int)\n",
    "        total_train_accuracy+=batch_train_acc\n",
    "    #plotLoss(loss2_list,batch_idx+1)   #################################     \n",
    "    total_train_accuracy/=(batch_idx+1)\n",
    "    print('total_train_accuracy:',total_train_accuracy)\n",
    "    print(\"Training Epoch: %d, total loss: %f\" % (epoch_id, total_loss))\n",
    "    return total_loss,total_train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e64856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_SA_epoch(model,train_loader,batch_size,optimizer,loss_func):\n",
    "    inn_model = InnvestigateModel(model, lrp_exponent=2,\n",
    "                              method=\"e-rule\",\n",
    "                              beta=.5)\n",
    "    BATCH_SIZE=batch_size\n",
    "    total = 0\n",
    "    correct=0\n",
    "    total_loss=0\n",
    "    #loss_score=torch.tensor([[]]).cuda()\n",
    "    #\n",
    "    #loss_op=0\n",
    "    loss2_list=[]\n",
    "    model.train()\n",
    "    total_train_accuracy=0  \n",
    "    for batch_idx, (x, labels) in enumerate(train_loader):\n",
    "            \n",
    "        labels = Variable(labels)\n",
    "        x = Variable(x)\n",
    "            \n",
    "        x_row,x_col=x.shape   \n",
    "        x=torch.tensor(x,dtype=torch.float)\n",
    "        #print(x.shape)\n",
    "        labels=torch.tensor(labels,dtype=torch.float)\n",
    "        x, labels = x.cuda(), labels.cuda()\n",
    "        labels_int=labels=torch.max(labels,1)[1]#########\n",
    "        #print(labels_int)\n",
    "        #print('labels_int:',labels_int.shape)\n",
    "        #print('labels:',labels) \n",
    "        #print('x:',x.shape)\n",
    "        loss_op=0\n",
    "        \n",
    "        \n",
    "        model_prediction, input_relevance_values = inn_model.innvestigate(in_tensor=x, rel_for_class=None,target=None)\n",
    "        #print(\"torch.argmax(labels[batch_idx]):\",torch.argmax(labels[batch_idx]))\n",
    "        input_relevance_values.cuda()\n",
    "        #input_relevance_values=F.softmax(input_relevance_values,dim=1)##############增加激活功能\n",
    "        input_relevance_values=input_relevance_values.exp()###############\n",
    "        #input_relevance_values=F.softmax(input_relevance_values,dim=1)\n",
    "        #xxx=torch.argmax(labels[batch_idx])\n",
    "        #xxx=int(xxx)\n",
    "        #print(\"xxx:\",xxx)\n",
    "        #print('input_relevance:',input_relevance_values.device)\n",
    "        x=torch.mul(x,input_relevance_values)##############注意力\n",
    "        optimizer.zero_grad()\n",
    "        y_predict = model(x)\n",
    "        \n",
    "        loss1 = loss_func(y_predict, labels)\n",
    "        #loss2=u*(1/loss_op)\n",
    "        #print('input_relevance_values:',input_relevance_values.shape)\n",
    "        #print('loss_score:',loss_score.shape)\n",
    "        \n",
    "        #print('input_relevance_values:',input_relevance_values)\n",
    "        loss=loss1\n",
    "        #loss = loss_func(y_predict, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #loss2_list.append(u*loss2)   \n",
    "        loss = loss.item()\n",
    "           \n",
    "\n",
    "        total_loss += loss\n",
    "            \n",
    "            \n",
    "            \n",
    "        batch_train_acc=torchmetrics.functional.accuracy(y_predict,labels_int)\n",
    "        total_train_accuracy+=batch_train_acc\n",
    "    #plotLoss(loss2_list,batch_idx+1)   #################################     \n",
    "    total_train_accuracy/=(batch_idx+1)\n",
    "    print('total_train_accuracy:',total_train_accuracy)\n",
    "    print(\"Training Epoch: %d, total loss: %f\" % (epoch_id, total_loss))\n",
    "    return total_loss,total_train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e3afab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable \n",
    "from torch.utils.data import DataLoader \n",
    "from sklearn.metrics import roc_auc_score \n",
    "from sklearn.metrics import accuracy_score \n",
    " \n",
    "def evaluate_model(test_dl, model): \n",
    "    model.eval()#测试数据稳定\n",
    "    predictions, actuals = [], [] \n",
    "    for i, (inputs, targets) in enumerate(test_dl): \n",
    "        # evaluate the model on the test set \n",
    "        #print(\\ inputs:\\ ,inputs) \n",
    "        #print(\\ targets:\\ ,targets) \n",
    "        inputs = Variable(inputs) \n",
    "        targets = Variable(targets) \n",
    "                 \n",
    "                 \n",
    "        #x = torch.tensor(x, dtype=torch.float) \n",
    "        #x=x.clone().detach().requires_grad_(True) \n",
    "        inputs=torch.tensor(inputs,dtype=torch.float) \n",
    "        \n",
    "        targets=torch.tensor(targets,dtype=torch.float) \n",
    "        inputs, targets = inputs.cuda(), targets.cuda() \n",
    "        yhat = model(inputs) \n",
    "        yhat=(yhat==torch.max(yhat,1,keepdim=True)[0]).to(dtype=torch.int32)\n",
    "        # retrieve numpy array \n",
    "        #yhat = yhat.detach().numpy() \n",
    "        yhat = yhat.detach().cpu().numpy()#转换到cpu \n",
    "        #print(\"yhat:\",yhat)\n",
    "        # yhat=yhat.argmax(axis=1) \n",
    "        #print(yhat:\\ ,yhat) \n",
    "        #print('yhat.shape:',yhat.shape) \n",
    "        actual = targets.detach().cpu().numpy() \n",
    "        actual=actual.round() \n",
    "        #print(\"actual:\",actual)\n",
    "        #print(\\ actual:\\ ,actual) \n",
    "        #print('actual.shape:',actual.shape\n",
    "        #predictions.appe) \n",
    "        #actual = actual.reshape(-1, 1) \n",
    "        # round to class values \n",
    "        yhat = yhat.round() \n",
    "        # store nd(yhat) \n",
    "        actuals.append(actual) \n",
    "        predictions.append(yhat)\n",
    "        \n",
    "    \n",
    "    #print(\"prediction:\" ,predictions) \n",
    "    #print(\"actuals:\",actuals) \n",
    "    predictions, actuals = np.vstack(predictions), np.vstack(actuals) \n",
    "    #print(\"prediction:\" ,predictions) \n",
    "    #print(\"actuals:\" ,actuals) \n",
    "    # calculate accuracy \n",
    "    \n",
    "    #print('actuals.shape:',actuals.shape)\n",
    "    #print('predictions.shape:',predictions.shape)\n",
    "    acc_test = accuracy_score(actuals, predictions) \n",
    "    return  actuals, predictions,acc_test "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
