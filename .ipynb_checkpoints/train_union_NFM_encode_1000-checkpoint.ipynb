{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39b0dc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[331 750 294 ... 459 346 496]\n",
      " [377 709 315 ... 425 355 464]\n",
      " [386 750 312 ... 446 368 465]\n",
      " ...\n",
      " [502 582 209 ... 333 260 383]\n",
      " [511 572 232 ... 330 252 400]\n",
      " [475 588 196 ... 353 253 409]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      " 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      " 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      " 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "(480, 10477)\n",
      "(206, 10477)\n",
      "(480,)\n",
      "(206,)\n",
      "[[534 598 245 ... 348 264 353]\n",
      " [295 815 269 ... 448 356 490]\n",
      " [478 586 224 ... 356 252 395]\n",
      " ...\n",
      " [476 641 267 ... 359 265 336]\n",
      " [472 585 233 ... 343 251 385]\n",
      " [406 641 230 ... 372 242 364]]\n",
      "FMData\n",
      "FMData\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import Trainer\n",
    "from network import NFM\n",
    "import torch.utils.data as Data\n",
    "from Utils.criteo_loader import getTestData, getTrainData\n",
    "\n",
    "nfm_config = \\\n",
    "{\n",
    "    'n_class':9,\n",
    "    'linear_hidden1':2000,\n",
    "    'linear_hidden':100,#线性模型输出层（隐层个数）\n",
    "    'embed_input_dim':1001,#embed输入维度\n",
    "    'embed_dim': 10, # 用于控制稀疏特征经过Embedding层后的稠密特征大小，embed输出维度\n",
    "    #'dnn_hidden_units': [100,11],#MLP隐层和输出层\n",
    "    \n",
    "    'dnn_hidden_units':[100,9],#MLP隐层\n",
    "    'num_sparse_features_cols':10477,#the number of the gene columns\n",
    "    'num_dense_features': 0,#dense features number\n",
    "    'bi_dropout': 0.3,#Bi-Interaction 的dropout\n",
    "    'num_epoch': 500,#训练epoch次数\n",
    "    'batch_size': 24,#batch_size\n",
    "    'lr': 1e-3,\n",
    "    'l2_regularization': 1e-4,\n",
    "    'device_id': 0,\n",
    "    'use_cuda': False,\n",
    "    'epoch':1000,\n",
    "    \n",
    "    #'train_file': '../Data/criteo/processed_data/train_set.csv',\n",
    "    #'fea_file': '../Data/criteo/processed_data/fea_col.npy',\n",
    "    #'validate_file': '../Data/criteo/processed_data/val_set.csv',\n",
    "    #'test_file': '../Data/criteo/processed_data/test_set.csv',\n",
    "    #'model_name': '../TrainedModels/NFM.model'\n",
    "    #'train_file':'data/xiaoqiu_gene_5000/train/final_5000_encode_100x.csv',\n",
    "    'train_data':'dataset/qiuguan/encode/encode_1000/train/train_encode_data_1000_new.csv',\n",
    "    'train_label':'dataset/qiuguan/non_code/train/train_label.csv',\n",
    "    #'test_data':'dataset/qiuguan/non_code/test/test_encode_data.csv',\n",
    "    'test_data':'dataset/qiuguan/encode/encode_1000/test/test_encode_data_1000_new.csv',\n",
    "    'test_label':'dataset/qiuguan/non_code/test/test_labels.csv'\n",
    "    #'title':'dataset/xiaoguan/RF/RF_for_train/train_class_9/test/test_data.csv',\n",
    "    'gene_name:':'dataset/qiuguan/orign/gene_name.csv',\n",
    "    'label_gene:':'dataset/qiuguan/orign/gene_label.csv'\n",
    "    #'all':''\n",
    "    #'title':'data/xiaoqiu_gene_5000/train/gene_5000_gene_name.csv',\n",
    "    #'all':'data/xiaoqiu_gene_5000/train/gene_5000_label_name.csv'\n",
    "}\n",
    "\n",
    "#准备训练集\n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "all=pd.read_csv('dataset/qiuguan/orign/qiuguan_encode_all_1000.csv',sep=',')\n",
    "all=all.iloc[1:,1:]\n",
    "X=all.iloc[:,:-1]\n",
    "X=X.values\n",
    "\n",
    "print(X)\n",
    "\n",
    "y=all.iloc[:,-1]\n",
    "y=y.values\n",
    "\n",
    "print(y)\n",
    "\n",
    "\"\"\"\n",
    "y=pd.read_csv('dataset/gene_247/data/guan/guan_label.csv',sep=',')\n",
    "y=y.values\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#y=np.array(y)\n",
    "train_data,test_data,train_label,test_label=train_test_split(X,y,test_size=0.3,stratify=y,random_state=2)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "print(train_label.shape)\n",
    "print(test_label.shape)\n",
    "print(train_data)\n",
    "\n",
    "\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.backends.cudnn as cudnn\n",
    "#3from tensorboardX import SummaryWriter\n",
    "\n",
    "#import network\n",
    "import config\n",
    "import evaluate\n",
    "import data_utils\n",
    "import Trainer\n",
    "#from utils import \n",
    "#准备训练集\n",
    "#from new_dataset_processed import FMData\n",
    "#from dataset_process import FMData\n",
    "\n",
    "\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.backends.cudnn as cudnn\n",
    "#3from tensorboardX import SummaryWriter\n",
    "\n",
    "#import network\n",
    "import config\n",
    "import evaluate\n",
    "import data_utils\n",
    "import Trainer\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def one_hot_smoothing(labels, classes, label_smoothing=0.2):\n",
    "    #n = len(labels)\n",
    "    n=labels.shape[0]\n",
    "    eoff = label_smoothing / classes\n",
    "    output = np.ones((n, classes), dtype=np.float32) * eoff\n",
    "    for row, label in enumerate(labels):\n",
    "        output[row, label] = 1 - label_smoothing + eoff\n",
    "        #print(\"row:\",row,\"label:\",label)\n",
    "    return output\n",
    "\n",
    "def one_hot(labels, classes):\n",
    "    n = len(labels)\n",
    "    #eoff = label_smoothing / classes\n",
    "    output = np.zeros((n, classes), dtype=np.float32)\n",
    "    for row, label in enumerate(labels):\n",
    "        output[row, label] = 1\n",
    "        #print(\"row:\",row,\"label:\",label)\n",
    "    return output\n",
    "\n",
    "class FMData(data.Dataset):\n",
    "    \"\"\" Construct the FM pytorch dataset. \"\"\"\n",
    "    #def __init__(self, file,label_file, feature_map,n_class=16):\n",
    "    def __init__(self, fdata,flabel, n_class):\n",
    "        super(FMData, self).__init__()\n",
    "        self.label = flabel\n",
    "        self.features =fdata\n",
    "        \n",
    "        print(\"FMData\")\n",
    "        #print('flabel:',self.label.shape)\n",
    "        #print('fdata:',self.features.shape)\n",
    "        \n",
    "       \n",
    "        self.label=one_hot_smoothing(self.label,n_class)\n",
    "        #self.label=label\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #print(\"idx:\",idx)\n",
    "        label = self.label[idx]\n",
    "        #print(\"label:\",label)\n",
    "        features = self.features[idx]\n",
    "        #print(\"features:\",features)\n",
    "        #feature_values = self.feature_values[idx]\n",
    "        #return features, feature_values, label\n",
    "        return features,  label\n",
    "\n",
    "    \n",
    "def prepare_dataset(m_data,m_label,batch_size,n_class):\n",
    "    m_dataset=FMData(m_data,m_label,n_class)\n",
    "    m_dataloader=data.DataLoader(m_dataset, drop_last=True,batch_size=batch_size,shuffle=True,num_workers=4)\n",
    "    \n",
    "    return m_dataset,m_dataloader\n",
    "\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "#from new_nfm_network import NFM\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.backends.cudnn as cudnn\n",
    "#3from tensorboardX import SummaryWriter\n",
    "import sys \n",
    "#import network\n",
    "import config\n",
    "import evaluate\n",
    "import data_utils\n",
    "import Trainer\n",
    "import torchmetrics\n",
    "def   train_model(model,train_loader,test_loader,batch_size,model_path):\n",
    "    #train_accuracy=torchmetrics.Accuracy()\n",
    "    #test_accuracy=torchmetrics.Accuracy()\n",
    "    BATCH_SIZE=batch_size\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=nfm_config['lr'], weight_decay=nfm_config['l2_regularization'])\n",
    "    total = 0\n",
    "    \n",
    "    #loss_func = torch.nn.BCELoss()\n",
    "    loss_func=torch.nn.CrossEntropyLoss()\n",
    "    #loss_func=nn.MultiLabelSoftMarginLoss()\n",
    "    #loss_func=torch.nn.LogSoftmax()\n",
    "    num=8000\n",
    "    #model=nn.Softmax(nn.Linear(10149,16)).to(device)\n",
    "    # 从DataLoader中获取小批量的id以及数据\n",
    "    \n",
    "    batch_size=0\n",
    "    loss_total=[]\n",
    "    acc_train_total=[]\n",
    "    acc_test_total=[]\n",
    "    for epoch_id in range(1000):\n",
    "        correct=0\n",
    "        total=0\n",
    "        total_test_acc=0\n",
    "        total_train_accuracy=0\n",
    "        for batch_idx, (x, labels) in enumerate(train_loader):\n",
    "            x = Variable(x)\n",
    "            #bi_x=Variable(bi_x)\n",
    "            labels = Variable(labels)\n",
    "            \n",
    "            \n",
    "            #x = torch.tensor(x, dtype=torch.float)\n",
    "            #x=x.clone().detach().requires_grad_(True)\n",
    "            x=torch.tensor(x,dtype=torch.float)\n",
    "            #bi_x=torch.tensor(bi_x,dtype=torch.long)\n",
    "            labels=torch.tensor(labels,dtype=torch.float)\n",
    "            x,labels = x.cuda(), labels.cuda()\n",
    "            labels_int=labels=torch.max(labels,1)[1]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_predict = model(x)\n",
    "            #print(\"y_predict:\",y_predict)\n",
    "            #loss = loss_func(y_predict.view(-1), labels)\n",
    "            loss = loss_func(y_predict, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss = loss.item()\n",
    "            #loss, predicted = self._train_single_batch(x, labels)\n",
    "\n",
    "            total += loss\n",
    "            #yhat = torch.max(yhat.data,1)[1]\n",
    "            #yhat=yhat.detach().cpu().numpy()\n",
    "            #print(\"predicted:\",predicted)\n",
    "            #predicted = torch.max(y_predict.data,1)[1]\n",
    "             #predicted = torch.max(y_predict.data,1)[1]\n",
    "            batch_train_acc=torchmetrics.functional.accuracy(y_predict,labels_int)\n",
    "            #print('batch_train_acc:',batch_train_acc)\n",
    "            total_train_accuracy+=batch_train_acc\n",
    "        #total_train_accuracy=torchmetrics.functional.compute_details()\n",
    "        total_train_accuracy/=(batch_idx+1)\n",
    "        print('total_train_accuracy:',total_train_accuracy)\n",
    "        loss_total.append(total)\n",
    "        acc_train_total.append(total_train_accuracy)\n",
    "        #print('total_train_accuracy:',total_train_accuracy)\n",
    "        for i , (inputs , targets) in enumerate(test_loader):   \n",
    "            print(\"test\")\n",
    "            # evaluate the model on the test set   \n",
    "            #print(\\ inputs:\\  inputs)   \n",
    "            #print(\\ targets:\\  targets)   \n",
    "            inputs = Variable(inputs)   \n",
    "            #bi_inputs=Variable(bi_inputs)\n",
    "            targets = Variable(targets)     \n",
    "            #x = torch.tensor(x  dtype=torch.float)   \n",
    "            #x=x.clone().detach().requires_grad_(True)   \n",
    "            inputs=torch.tensor(inputs ,dtype=torch.float)  \n",
    "            #bi_inputs=torch.tensor(bi_inputs,dtype=torch.float)\n",
    "            targets=torch.tensor(targets ,dtype=torch.float)   \n",
    "            inputs , targets = inputs.cuda(), targets.cuda()   \n",
    "            yhat = model(inputs)  \n",
    "            \n",
    "            targets=torch.max(targets,1)[1]\n",
    "            #print(\"labels:\",labels)\n",
    "            #labels=labels[1]\n",
    "            #targets=targets.detach().cpu().numpy()\n",
    "            \n",
    "            \n",
    "            \n",
    "            batch_test_acc=torchmetrics.functional.accuracy(yhat,targets)\n",
    "            #print(\"batch_test_acc:\",batch_test_acc)\n",
    "            total_test_acc+=batch_test_acc\n",
    "            #total_test_accuracy=torchmetrics.functional.compute_details()\n",
    "            batch_size=i\n",
    "        total_test_acc/=(batch_size+1)\n",
    "        print('total_test_accuracy:',total_test_acc)\n",
    "        acc_test_total.append(total_test_acc)\n",
    "        #print(acc_test_total)            \n",
    "                    \n",
    "            \n",
    "            #model.evaluate()\n",
    "            #model.eval()\n",
    "            #train_result = evaluate.metrics(model, train_loader)\n",
    "            #valid_result = evaluate.metrics(model, valid_loader)\n",
    "            #est_result = evaluate.metrics(model, test_loader)\n",
    "            #acturals,predictions,acc_test=evaluate_model(test_loader,model)\n",
    "            #print(\"acc_test:  %d  \" %(acc_test))\n",
    "            #print(\"Train_RMSE: {:.3f}, Valid_RMSE: {:.3f}, Test_RMSE: {:.3f}\".format(\n",
    "            #train_result, valid_result, test_result))\n",
    "            # print('[Training Epoch: {}] Batch: {}, Loss: {}'.format(epoch_id, batch_id, loss))\n",
    "        print(\"Training Epoch: %d, total loss: %f\" % (epoch_id, total))\n",
    "        #print(\"auc:\",roc_auc_score)\n",
    "    #功能：保存训练完的网络的各层参数（即weights和bias)\n",
    "    #path='dataset/xiaoguan/RF/RF_for_train/train_class_9/model/gene_4000_NFM.pkl'\n",
    "        if epoch_id %20==0:\n",
    "            num=num+1\n",
    "            path=os.path.join(model_path,'NMF'+str(num)+'.pkl')\n",
    "            torch.save(model.state_dict(),path)\n",
    "    #plotLoss(loss_total)\n",
    "    return loss_total,acc_train_total,acc_test_total\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plotacc(acc_train,acc_test):\n",
    "    plt.rcParams['font.sans-serif']=['SimHei']\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    x=[i for i in range(2000)]\n",
    "    #acc_train=acc_train.cpu()\n",
    "    #acc_test=acc_test.cpu()\n",
    "    #plt.plot(x, loss, 'r-', mec='k', label='Logistic Loss', lw=2)\n",
    "    plt.plot(x,acc_train,'b-',mec='k',label='accuracy Train',lw=2)\n",
    "    plt.plot(x,acc_test,'g-',mec='k',label='accuracy Test',lw=2)\n",
    "    #plt.plot(x, y_01, 'g-', mec='k', label='0/1 Loss', lw=2)\n",
    "    #plt.plot(x, y_hinge, 'b-',mec='k', label='Hinge Loss', lw=2)\n",
    "    #plt.plot(x, boost, 'm--',mec='k', label='Adaboost Loss',lw=2)\n",
    "    plt.grid(True, ls='--')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('精确度')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plotloss(total_loss):\n",
    "    plt.rcParams['font.sans-serif']=['SimHei']\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    x=[i for i in range(2000)]\n",
    "    #acc_train=acc_train.cpu()\n",
    "    #acc_test=acc_test.cpu()\n",
    "    #plt.plot(x, loss, 'r-', mec='k', label='Logistic Loss', lw=2)\n",
    "    plt.plot(x,total_loss,'b-',mec='k',label='accuracy Train',lw=2)\n",
    "    #plt.plot(x,acc_test,'g-',mec='k',label='accuracy Test',lw=2)\n",
    "    #plt.plot(x, y_01, 'g-', mec='k', label='0/1 Loss', lw=2)\n",
    "    #plt.plot(x, y_hinge, 'b-',mec='k', label='Hinge Loss', lw=2)\n",
    "    #plt.plot(x, boost, 'm--',mec='k', label='Adaboost Loss',lw=2)\n",
    "    plt.grid(True, ls='--')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('损失函数')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "train_dataset,train_loader=prepare_dataset(train_data,train_label,nfm_config['batch_size'],nfm_config['n_class'])\n",
    "test_dataset,test_loader=prepare_dataset(test_data,test_label,nfm_config['batch_size'],nfm_config['n_class'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc01b963",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/.local/lib/python3.6/site-packages/ipykernel_launcher.py:243: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/zhengfang/.local/lib/python3.6/site-packages/ipykernel_launcher.py:245: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_train_accuracy: tensor(0.1583, device='cuda:0')\n",
      "test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/.local/lib/python3.6/site-packages/ipykernel_launcher.py:285: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/zhengfang/.local/lib/python3.6/site-packages/ipykernel_launcher.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.1771, device='cuda:0')\n",
      "Training Epoch: 0, total loss: 43.865125\n",
      "total_train_accuracy: tensor(0.1792, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.1823, device='cuda:0')\n",
      "Training Epoch: 1, total loss: 43.687160\n",
      "total_train_accuracy: tensor(0.1854, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.2031, device='cuda:0')\n",
      "Training Epoch: 2, total loss: 43.061483\n",
      "total_train_accuracy: tensor(0.2292, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.2448, device='cuda:0')\n",
      "Training Epoch: 3, total loss: 42.384143\n",
      "total_train_accuracy: tensor(0.2875, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.2813, device='cuda:0')\n",
      "Training Epoch: 4, total loss: 41.772283\n",
      "total_train_accuracy: tensor(0.3167, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.2708, device='cuda:0')\n",
      "Training Epoch: 5, total loss: 41.064706\n",
      "total_train_accuracy: tensor(0.3167, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.3021, device='cuda:0')\n",
      "Training Epoch: 6, total loss: 40.813254\n",
      "total_train_accuracy: tensor(0.3312, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.2813, device='cuda:0')\n",
      "Training Epoch: 7, total loss: 40.505012\n",
      "total_train_accuracy: tensor(0.3437, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.3073, device='cuda:0')\n",
      "Training Epoch: 8, total loss: 40.440537\n",
      "total_train_accuracy: tensor(0.3458, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.3073, device='cuda:0')\n",
      "Training Epoch: 9, total loss: 40.089473\n",
      "total_train_accuracy: tensor(0.3604, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.3073, device='cuda:0')\n",
      "Training Epoch: 10, total loss: 39.795102\n",
      "total_train_accuracy: tensor(0.3604, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.3385, device='cuda:0')\n",
      "Training Epoch: 11, total loss: 39.846256\n",
      "total_train_accuracy: tensor(0.4062, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.3073, device='cuda:0')\n",
      "Training Epoch: 12, total loss: 39.667194\n",
      "total_train_accuracy: tensor(0.4042, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.3385, device='cuda:0')\n",
      "Training Epoch: 13, total loss: 39.353601\n",
      "total_train_accuracy: tensor(0.4021, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.3802, device='cuda:0')\n",
      "Training Epoch: 14, total loss: 39.296529\n",
      "total_train_accuracy: tensor(0.4500, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.3437, device='cuda:0')\n",
      "Training Epoch: 15, total loss: 38.751149\n",
      "total_train_accuracy: tensor(0.4396, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.3646, device='cuda:0')\n",
      "Training Epoch: 16, total loss: 38.816754\n",
      "total_train_accuracy: tensor(0.4521, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.3594, device='cuda:0')\n",
      "Training Epoch: 17, total loss: 38.761027\n",
      "total_train_accuracy: tensor(0.4917, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.3698, device='cuda:0')\n",
      "Training Epoch: 18, total loss: 38.001194\n",
      "total_train_accuracy: tensor(0.4938, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.4323, device='cuda:0')\n",
      "Training Epoch: 19, total loss: 37.635222\n",
      "total_train_accuracy: tensor(0.4833, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.3698, device='cuda:0')\n",
      "Training Epoch: 20, total loss: 37.858052\n",
      "total_train_accuracy: tensor(0.4563, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.3958, device='cuda:0')\n",
      "Training Epoch: 21, total loss: 38.126835\n",
      "total_train_accuracy: tensor(0.4813, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.3906, device='cuda:0')\n",
      "Training Epoch: 22, total loss: 37.757333\n",
      "total_train_accuracy: tensor(0.5000, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.4219, device='cuda:0')\n",
      "Training Epoch: 23, total loss: 37.435377\n",
      "total_train_accuracy: tensor(0.4958, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.3906, device='cuda:0')\n",
      "Training Epoch: 24, total loss: 37.572192\n",
      "total_train_accuracy: tensor(0.5188, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.3698, device='cuda:0')\n",
      "Training Epoch: 25, total loss: 37.201412\n",
      "total_train_accuracy: tensor(0.5229, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.3854, device='cuda:0')\n",
      "Training Epoch: 26, total loss: 37.130533\n",
      "total_train_accuracy: tensor(0.5271, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.3854, device='cuda:0')\n",
      "Training Epoch: 27, total loss: 36.830514\n",
      "total_train_accuracy: tensor(0.5208, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.4635, device='cuda:0')\n",
      "Training Epoch: 28, total loss: 36.832076\n",
      "total_train_accuracy: tensor(0.5250, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.4375, device='cuda:0')\n",
      "Training Epoch: 29, total loss: 37.047478\n",
      "total_train_accuracy: tensor(0.5396, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.3958, device='cuda:0')\n",
      "Training Epoch: 30, total loss: 36.609973\n",
      "total_train_accuracy: tensor(0.5208, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.4167, device='cuda:0')\n",
      "Training Epoch: 31, total loss: 36.881852\n",
      "total_train_accuracy: tensor(0.5250, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.4479, device='cuda:0')\n",
      "Training Epoch: 32, total loss: 36.820758\n",
      "total_train_accuracy: tensor(0.5271, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.4635, device='cuda:0')\n",
      "Training Epoch: 33, total loss: 36.720581\n",
      "total_train_accuracy: tensor(0.5479, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.4479, device='cuda:0')\n",
      "Training Epoch: 34, total loss: 36.473007\n",
      "total_train_accuracy: tensor(0.5521, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.4010, device='cuda:0')\n",
      "Training Epoch: 35, total loss: 36.518560\n",
      "total_train_accuracy: tensor(0.5979, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.3958, device='cuda:0')\n",
      "Training Epoch: 36, total loss: 35.727694\n",
      "total_train_accuracy: tensor(0.5812, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.4531, device='cuda:0')\n",
      "Training Epoch: 37, total loss: 35.872762\n",
      "total_train_accuracy: tensor(0.6063, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.4792, device='cuda:0')\n",
      "Training Epoch: 38, total loss: 35.443094\n",
      "total_train_accuracy: tensor(0.6083, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.4688, device='cuda:0')\n",
      "Training Epoch: 39, total loss: 35.435878\n",
      "total_train_accuracy: tensor(0.5625, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.4687, device='cuda:0')\n",
      "Training Epoch: 40, total loss: 36.175303\n",
      "total_train_accuracy: tensor(0.6167, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.4792, device='cuda:0')\n",
      "Training Epoch: 41, total loss: 35.268762\n",
      "total_train_accuracy: tensor(0.6313, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.4688, device='cuda:0')\n",
      "Training Epoch: 42, total loss: 35.061037\n",
      "total_train_accuracy: tensor(0.5896, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.4531, device='cuda:0')\n",
      "Training Epoch: 43, total loss: 35.493313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_train_accuracy: tensor(0.6208, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.4115, device='cuda:0')\n",
      "Training Epoch: 44, total loss: 35.040476\n",
      "total_train_accuracy: tensor(0.6125, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.4635, device='cuda:0')\n",
      "Training Epoch: 45, total loss: 35.251288\n",
      "total_train_accuracy: tensor(0.6104, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.4479, device='cuda:0')\n",
      "Training Epoch: 46, total loss: 35.298433\n",
      "total_train_accuracy: tensor(0.6313, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.4740, device='cuda:0')\n",
      "Training Epoch: 47, total loss: 34.779965\n",
      "total_train_accuracy: tensor(0.6375, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.5104, device='cuda:0')\n",
      "Training Epoch: 48, total loss: 34.697359\n",
      "total_train_accuracy: tensor(0.6542, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.5104, device='cuda:0')\n",
      "Training Epoch: 49, total loss: 34.530129\n",
      "total_train_accuracy: tensor(0.6396, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.5208, device='cuda:0')\n",
      "Training Epoch: 50, total loss: 34.570731\n",
      "total_train_accuracy: tensor(0.6292, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 51, total loss: 34.875636\n",
      "total_train_accuracy: tensor(0.6250, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.5208, device='cuda:0')\n",
      "Training Epoch: 52, total loss: 34.855288\n",
      "total_train_accuracy: tensor(0.6292, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.4948, device='cuda:0')\n",
      "Training Epoch: 53, total loss: 34.904294\n",
      "total_train_accuracy: tensor(0.6479, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.4635, device='cuda:0')\n",
      "Training Epoch: 54, total loss: 34.549936\n",
      "total_train_accuracy: tensor(0.6833, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.5208, device='cuda:0')\n",
      "Training Epoch: 55, total loss: 33.880920\n",
      "total_train_accuracy: tensor(0.6562, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.5104, device='cuda:0')\n",
      "Training Epoch: 56, total loss: 34.353762\n",
      "total_train_accuracy: tensor(0.6729, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.4792, device='cuda:0')\n",
      "Training Epoch: 57, total loss: 34.039163\n",
      "total_train_accuracy: tensor(0.6729, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.4948, device='cuda:0')\n",
      "Training Epoch: 58, total loss: 34.029253\n",
      "total_train_accuracy: tensor(0.6750, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.4948, device='cuda:0')\n",
      "Training Epoch: 59, total loss: 34.103905\n",
      "total_train_accuracy: tensor(0.6562, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.4792, device='cuda:0')\n",
      "Training Epoch: 60, total loss: 34.316078\n",
      "total_train_accuracy: tensor(0.6854, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.5208, device='cuda:0')\n",
      "Training Epoch: 61, total loss: 33.862110\n",
      "total_train_accuracy: tensor(0.6917, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.5104, device='cuda:0')\n",
      "Training Epoch: 62, total loss: 33.724173\n",
      "total_train_accuracy: tensor(0.6875, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.4844, device='cuda:0')\n",
      "Training Epoch: 63, total loss: 33.754461\n",
      "total_train_accuracy: tensor(0.7167, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.4740, device='cuda:0')\n",
      "Training Epoch: 64, total loss: 33.288965\n",
      "total_train_accuracy: tensor(0.6792, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.5052, device='cuda:0')\n",
      "Training Epoch: 65, total loss: 33.974768\n",
      "total_train_accuracy: tensor(0.7021, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.5104, device='cuda:0')\n",
      "Training Epoch: 66, total loss: 33.503533\n",
      "total_train_accuracy: tensor(0.6813, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.4740, device='cuda:0')\n",
      "Training Epoch: 67, total loss: 33.798715\n",
      "total_train_accuracy: tensor(0.6854, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.4844, device='cuda:0')\n",
      "Training Epoch: 68, total loss: 33.788017\n",
      "total_train_accuracy: tensor(0.6958, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 69, total loss: 33.649827\n",
      "total_train_accuracy: tensor(0.7292, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.5729, device='cuda:0')\n",
      "Training Epoch: 70, total loss: 33.008727\n",
      "total_train_accuracy: tensor(0.7146, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.5469, device='cuda:0')\n",
      "Training Epoch: 71, total loss: 33.056670\n",
      "total_train_accuracy: tensor(0.7375, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.5052, device='cuda:0')\n",
      "Training Epoch: 72, total loss: 32.908946\n",
      "total_train_accuracy: tensor(0.7437, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.5625, device='cuda:0')\n",
      "Training Epoch: 73, total loss: 32.733698\n",
      "total_train_accuracy: tensor(0.7479, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.5625, device='cuda:0')\n",
      "Training Epoch: 74, total loss: 32.459207\n",
      "total_train_accuracy: tensor(0.7500, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.5417, device='cuda:0')\n",
      "Training Epoch: 75, total loss: 32.444093\n",
      "total_train_accuracy: tensor(0.7687, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.5312, device='cuda:0')\n",
      "Training Epoch: 76, total loss: 32.266943\n",
      "total_train_accuracy: tensor(0.7854, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 77, total loss: 31.914477\n",
      "total_train_accuracy: tensor(0.7792, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.5417, device='cuda:0')\n",
      "Training Epoch: 78, total loss: 31.965576\n",
      "total_train_accuracy: tensor(0.7750, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.5885, device='cuda:0')\n",
      "Training Epoch: 79, total loss: 32.153291\n",
      "total_train_accuracy: tensor(0.7771, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.5885, device='cuda:0')\n",
      "Training Epoch: 80, total loss: 32.044335\n",
      "total_train_accuracy: tensor(0.8104, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.5729, device='cuda:0')\n",
      "Training Epoch: 81, total loss: 31.485935\n",
      "total_train_accuracy: tensor(0.7917, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.5417, device='cuda:0')\n",
      "Training Epoch: 82, total loss: 31.883388\n",
      "total_train_accuracy: tensor(0.7896, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.5573, device='cuda:0')\n",
      "Training Epoch: 83, total loss: 31.792411\n",
      "total_train_accuracy: tensor(0.8146, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.5677, device='cuda:0')\n",
      "Training Epoch: 84, total loss: 31.303859\n",
      "total_train_accuracy: tensor(0.8188, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.5365, device='cuda:0')\n",
      "Training Epoch: 85, total loss: 31.189371\n",
      "total_train_accuracy: tensor(0.8375, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.5469, device='cuda:0')\n",
      "Training Epoch: 86, total loss: 31.099398\n",
      "total_train_accuracy: tensor(0.8208, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.5521, device='cuda:0')\n",
      "Training Epoch: 87, total loss: 31.315481\n",
      "total_train_accuracy: tensor(0.8188, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.6354, device='cuda:0')\n",
      "Training Epoch: 88, total loss: 31.343135\n",
      "total_train_accuracy: tensor(0.8063, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.5781, device='cuda:0')\n",
      "Training Epoch: 89, total loss: 31.320250\n",
      "total_train_accuracy: tensor(0.8500, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.6458, device='cuda:0')\n",
      "Training Epoch: 90, total loss: 30.572394\n",
      "total_train_accuracy: tensor(0.8458, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.6042, device='cuda:0')\n",
      "Training Epoch: 91, total loss: 30.598287\n",
      "total_train_accuracy: tensor(0.8104, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.5885, device='cuda:0')\n",
      "Training Epoch: 92, total loss: 31.393810\n",
      "total_train_accuracy: tensor(0.8438, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.6198, device='cuda:0')\n",
      "Training Epoch: 93, total loss: 30.712609\n",
      "total_train_accuracy: tensor(0.8604, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.5833, device='cuda:0')\n",
      "Training Epoch: 94, total loss: 30.221195\n",
      "total_train_accuracy: tensor(0.8417, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.6094, device='cuda:0')\n",
      "Training Epoch: 95, total loss: 30.682797\n",
      "total_train_accuracy: tensor(0.8313, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.6146, device='cuda:0')\n",
      "Training Epoch: 96, total loss: 30.811903\n",
      "total_train_accuracy: tensor(0.8417, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.6250, device='cuda:0')\n",
      "Training Epoch: 97, total loss: 30.527388\n",
      "total_train_accuracy: tensor(0.8646, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.5990, device='cuda:0')\n",
      "Training Epoch: 98, total loss: 30.266530\n",
      "total_train_accuracy: tensor(0.8396, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.6198, device='cuda:0')\n",
      "Training Epoch: 99, total loss: 30.763029\n",
      "total_train_accuracy: tensor(0.8833, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.6510, device='cuda:0')\n",
      "Training Epoch: 100, total loss: 29.977934\n",
      "total_train_accuracy: tensor(0.8729, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.5833, device='cuda:0')\n",
      "Training Epoch: 101, total loss: 30.035287\n",
      "total_train_accuracy: tensor(0.8958, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.6042, device='cuda:0')\n",
      "Training Epoch: 102, total loss: 29.711028\n",
      "total_train_accuracy: tensor(0.8917, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.5938, device='cuda:0')\n",
      "Training Epoch: 103, total loss: 29.825051\n",
      "total_train_accuracy: tensor(0.8875, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.6823, device='cuda:0')\n",
      "Training Epoch: 104, total loss: 29.827425\n",
      "total_train_accuracy: tensor(0.8979, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.6510, device='cuda:0')\n",
      "Training Epoch: 105, total loss: 29.648763\n",
      "total_train_accuracy: tensor(0.8896, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.6146, device='cuda:0')\n",
      "Training Epoch: 106, total loss: 29.729169\n",
      "total_train_accuracy: tensor(0.9083, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.6354, device='cuda:0')\n",
      "Training Epoch: 107, total loss: 29.462710\n",
      "total_train_accuracy: tensor(0.9500, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.6302, device='cuda:0')\n",
      "Training Epoch: 108, total loss: 28.774966\n",
      "total_train_accuracy: tensor(0.8792, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.6146, device='cuda:0')\n",
      "Training Epoch: 109, total loss: 29.955048\n",
      "total_train_accuracy: tensor(0.9208, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.5990, device='cuda:0')\n",
      "Training Epoch: 110, total loss: 29.133830\n",
      "total_train_accuracy: tensor(0.9083, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.6250, device='cuda:0')\n",
      "Training Epoch: 111, total loss: 29.459698\n",
      "total_train_accuracy: tensor(0.9229, device='cuda:0')\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.6198, device='cuda:0')\n",
      "Training Epoch: 112, total loss: 29.053341\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from new_nfm_network_batch_1 import NFM\n",
    "nfm=NFM(nfm_config)\n",
    "nfm.cuda()\n",
    "loss_total,acc_train,acc_test=train_model(nfm,train_loader,test_loader,nfm_config['batch_size'],'dataset/qiuguan/model_new/NFM_encde_1000_again/')\n",
    "plotacc(acc_train,acc_test)\n",
    "plotLoss(loss_total)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76c0d04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FMData\n",
      "FMData\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ed92212",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c83e4eb04c69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnew_nfm_network_batch_1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNFM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnfm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNFM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnfm_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mloss_total\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnfm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnfm_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'dataset/qiuguan/model_new/NFM_encde_1000_new/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplotacc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \"\"\"\n\u001b[0;32m--> 680\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \"\"\"\n\u001b[0;32m--> 680\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW"
     ]
    }
   ],
   "source": [
    "from new_nfm_network_batch_1 import NFM\n",
    "nfm=NFM(nfm_config)\n",
    "nfm.cuda()\n",
    "loss_total,acc_train,acc_test=train_model(nfm,train_loader,test_loader,nfm_config['batch_size'],'dataset/qiuguan/model_new/NFM_encde_1000_new/')\n",
    "plotacc(acc_train,acc_test)\n",
    "plotLoss(loss_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc6ac24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NFM(\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (BN_num): BatchNorm1d(10477, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (linear_model1): Linear(in_features=10477, out_features=2000, bias=True)\n",
      "  (BN_linear1): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (linear_model2): Linear(in_features=2000, out_features=100, bias=True)\n",
      "  (BN_linear2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (embedding_layers): Embedding(1001, 10)\n",
      "  (bi_pooling): BiInteractionPooling()\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (BN_bi): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dnn_layers): ModuleList(\n",
      "    (0): Linear(in_features=110, out_features=100, bias=True)\n",
      "    (1): Linear(in_features=100, out_features=9, bias=True)\n",
      "  )\n",
      "  (dnn_softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/.local/lib/python3.6/site-packages/ipykernel_launcher.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/zhengfang/.local/lib/python3.6/site-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [array([[0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.]], dtype=float32), array([[0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32), array([[0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.]], dtype=float32), array([[0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.]], dtype=float32), array([[0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32), array([[0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.]], dtype=float32), array([[0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.]], dtype=float32), array([[0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.]], dtype=float32)]\n",
      "actuals: [array([[0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.]], dtype=float32), array([[0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.]], dtype=float32), array([[0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.]], dtype=float32), array([[0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.]], dtype=float32), array([[0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32), array([[0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.]], dtype=float32), array([[0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.]], dtype=float32), array([[0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.]], dtype=float32)]\n",
      "prediction: [[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "actuals: [[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/.local/lib/python3.6/site-packages/ipykernel_launcher.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/zhengfang/.local/lib/python3.6/site-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [array([[0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32), array([[0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.]], dtype=float32), array([[0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32), array([[0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.]], dtype=float32), array([[0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32), array([[1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.]], dtype=float32), array([[1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.]], dtype=float32), array([[0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.]], dtype=float32)]\n",
      "actuals: [array([[0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.]], dtype=float32), array([[0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.]], dtype=float32), array([[0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.]], dtype=float32), array([[0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.]], dtype=float32), array([[0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32), array([[0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32), array([[1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32), array([[0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0.]], dtype=float32)]\n",
      "prediction: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "actuals: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "f1_score:  %.4f 0.6961957971897653\n",
      "accuracy_score: 0.7083333333333334\n",
      "recall_score: 0.6961487586487587\n",
      "pre_recall: 0.7051134643811988\n",
      "n_classes: 9\n",
      "fpr[1]: [0.         0.02272727 1.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/.local/lib/python3.6/site-packages/ipykernel_launcher.py:133: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 19981 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 21516 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 30142 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 30149 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 30340 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 26354 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 32447 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 22270 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 19981 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 21516 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 30142 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 30149 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 30340 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 26354 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 32447 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 22270 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#功能：加载保存到path中的各层参数到神经网络\n",
    "\n",
    "path='dataset/qiuguan/model_new/NFM_encde_1000/NMF8029.pkl'\n",
    "from new_nfm_network_batch_1 import NFM\n",
    "nfm=NFM(nfm_config)\n",
    "\n",
    "#print(nfm)\n",
    "#net = nn.DataParallel(net)\n",
    "#net = net.to(device)\n",
    "nfm.load_state_dict(torch.load(path),strict=False)\n",
    "nfm.cuda()\n",
    "\n",
    "print(nfm)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nfm_params = list(nfm.named_parameters())\n",
    "#print(nfm_params)\n",
    "net=nfm\n",
    "\n",
    "#———————————————— \n",
    "#版权声明：本文为CSDN博主「山阴少年」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。 \n",
    "#原文链接：https://blog.csdn.net/jclian91/article/details/121708431# \n",
    "from torch.autograd import Variable \n",
    "from torch.utils.data import DataLoader \n",
    "from sklearn.metrics import roc_auc_score \n",
    "from sklearn.metrics import accuracy_score \n",
    " \n",
    "def evaluate_model(test_dl, model): \n",
    "    predictions, actuals = [], [] \n",
    "    for i, (inputs, targets) in enumerate(test_dl): \n",
    "        # evaluate the model on the test set \n",
    "        #print(\\ inputs:\\ ,inputs) \n",
    "        #print(\\ targets:\\ ,targets) \n",
    "        inputs = Variable(inputs) \n",
    "        targets = Variable(targets) \n",
    "        #bi_inputs=Variable(bi_inputs)        \n",
    "                 \n",
    "        #x = torch.tensor(x, dtype=torch.float) \n",
    "        #x=x.clone().detach().requires_grad_(True) \n",
    "        inputs=torch.tensor(inputs,dtype=torch.float) \n",
    "        #bi_inputs=torch.tensor(bi_inputs,dtype=torch.float)\n",
    "        targets=torch.tensor(targets,dtype=torch.float) \n",
    "        inputs,targets = inputs.cuda(), targets.cuda() \n",
    "        yhat = model(inputs) \n",
    "        # retrieve numpy array \n",
    "        #yhat = yhat.detach().numpy() \n",
    "        yhat = yhat.detach().cpu().numpy()#转换到cpu \n",
    "        # yhat=yhat.argmax(axis=1) \n",
    "        #print(yhat:\\ ,yhat) \n",
    "        #print('yhat.shape:',yhat.shape) \n",
    "        actual = targets.detach().cpu().numpy() \n",
    "        actual=actual.round() \n",
    "        #print(\\ actual:\\ ,actual) \n",
    "        #print('actual.shape:',actual.shape\n",
    "        #predictions.appe) \n",
    "        #actual = actual.reshape(-1, 1) \n",
    "        # round to class values \n",
    "        yhat = yhat.round() \n",
    "        # store nd(yhat) \n",
    "        actuals.append(actual) \n",
    "        predictions.append(yhat)\n",
    "    print(\"prediction:\" ,predictions) \n",
    "    print(\"actuals:\",actuals) \n",
    "    predictions, actuals = np.vstack(predictions), np.vstack(actuals) \n",
    "    print(\"prediction:\" ,predictions) \n",
    "    print(\"actuals:\" ,actuals) \n",
    "    # calculate accuracy \n",
    "    acc_test = accuracy_score(actuals, predictions) \n",
    "    return  actuals, predictions,acc_test \n",
    "\n",
    "\n",
    "import torch.nn.functional as F \n",
    "\n",
    "actuals,predictions,acc_test=evaluate_model(test_loader,net)\n",
    "\n",
    "\n",
    "import torch.nn.functional as F \n",
    "\n",
    "actuals,predictions,acc_test=evaluate_model(test_loader,net)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score,roc_curve, auc, precision_score, recall_score, f1_score, confusion_matrix, accuracy_score \n",
    "target_list=actuals \n",
    "pred_list=predictions \n",
    "      \n",
    "y_true=target_list \n",
    "y_pred=pred_list \n",
    "      \n",
    "f1=f1_score(y_true=target_list, y_pred=pred_list, average='macro') # 也可以指定micro模式 \n",
    "acc_score=accuracy_score(y_true=target_list, y_pred=pred_list) \n",
    "rec_score=recall_score(y_true=target_list,y_pred=pred_list,average='macro') # 也可以指定micro模式 \n",
    "pre_recall=precision_score(y_true=target_list,y_pred=pred_list,average='macro') \n",
    "print(\"f1_score:  %.4f\" ,f1) \n",
    "print(\"accuracy_score:\" ,acc_score) \n",
    "print(\"recall_score:\",rec_score) \n",
    "print(\"pre_recall:\" ,pre_recall)\n",
    "\n",
    "\n",
    "\n",
    "auc_curve = roc_auc_score(y_true, y_pred, multi_class='ovo')\n",
    "#———————————————— \n",
    "#版权声明：本文为CSDN博主「农民小飞侠」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。 \n",
    "#原文链接：https://blog.csdn.net/w5688414/article/details/106595892 \n",
    "PM_y=y_pred \n",
    "true_y=y_true \n",
    "n_classes=PM_y.shape[1] \n",
    "      \n",
    "print(\"n_classes:\",n_classes) \n",
    "fpr = dict() \n",
    "tpr = dict() \n",
    "roc_auc = dict() \n",
    "for i in range(n_classes): \n",
    "    fpr[i], tpr[i], _ = roc_curve(true_y[:, i], PM_y[:, i]) \n",
    "    roc_auc[i] = auc(fpr[i], tpr[i]) \n",
    "    #print(i) \n",
    "    #print(fpr) \n",
    "    #print(tpr) \n",
    "    \n",
    "print('fpr[1]:',fpr[1])   \n",
    "    \n",
    "#计算macro auc \n",
    "from scipy import interp \n",
    "# First aggregate all false positive rates \n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)])) \n",
    "       \n",
    "# Then interpolate all ROC curves at this points \n",
    "mean_tpr = np.zeros_like(all_fpr) \n",
    "for i in range(n_classes): \n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i]) \n",
    "       \n",
    "    # Finally average it and compute AUC \n",
    "    mean_tpr /= n_classes \n",
    "       \n",
    "    fpr[\"macro\"] = all_fpr \n",
    "    tpr[\"macro\"] = mean_tpr \n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "    \n",
    "    \n",
    "    \n",
    "#画图 \n",
    "      \n",
    "import matplotlib.pyplot as plt \n",
    "from itertools import cycle \n",
    "from matplotlib.ticker import FuncFormatter \n",
    "lw = 2 \n",
    "# Plot all ROC curves \n",
    "plt.figure() \n",
    "labels=['Con(0)','DN(1)','FSGS(2)','HT(3)','IgA(4)','MCD(5)','MGN(6)','RPGN(7)','SLE(8)'] \n",
    "\n",
    "'''\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"], \n",
    "              label='macro-average ROC curve (area = {0:0.4f})' \n",
    "                    ''.format(roc_auc[\"macro\"]), \n",
    "              color='navy', linestyle=':', linewidth=4) \n",
    "'''\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"], \n",
    "              label='macro-average ROC curve (area = {0:0.4f})' \n",
    "                    ''.format(roc_auc[\"macro\"]), \n",
    "              color='navy', linestyle=':', linewidth=4) \n",
    "       \n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue','blue','yellow','burlywood','cornsilk','darkblue','goldenrod','greenyellow','maroon']) \n",
    "for i, color in zip(range(n_classes), colors): \n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw, \n",
    "                  label=labels[i]+'(area = {0:0.4f})'.format(roc_auc[i])) \n",
    "       \n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=lw) \n",
    "    plt.xlim([0.0, 1.0]) \n",
    "    plt.ylim([0.0, 1.05]) \n",
    "      \n",
    "      \n",
    "    plt.xlabel('1-Specificity (%)') \n",
    "    plt.ylabel('Sensitivity (%)') \n",
    "    plt.title('不同疾病的AUC曲线图') \n",
    "      \n",
    "\n",
    "        \n",
    "def to_percent(temp, position): \n",
    "    return '%1.0f'%(100*temp) \n",
    "      \n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(to_percent)) \n",
    "plt.gca().xaxis.set_major_formatter(FuncFormatter(to_percent)) \n",
    "plt.legend(loc=\"lower right\" ) \n",
    "      \n",
    "plt.show() \n",
    "\n",
    "\n",
    "\n",
    "#———————————————— \n",
    "#版权声明：本文为CSDN博主「山阴少年」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。 \n",
    "#原文链接：https://blog.csdn.net/jclian91/article/details/103074506/ \n",
    "      \n",
    "from sklearn.metrics import confusion_matrix \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib as mpl \n",
    "      \n",
    "# 支持中文字体显示, 使用于Mac系统 \n",
    "#zhfont=mpl.font_manager.FontProperties(fname=\\ /Library/Fonts/Songti.ttc\\ ) \n",
    "      \n",
    "y_true=actuals# = ['北京', '上海', '成都', '成都', '上海', '北京', '上海', '成都', '北京', '上海'] \n",
    "y_pred=predictions #= ['北京', '上海', '成都', '上海', '成都', '成都', '上海', '成都', '北京', '上海'] \n",
    "      \n",
    "#ValueError: multilabel-indicator is not supported \n",
    "      \n",
    "classes = [0,1,2,3,4,5,6,7,8] \n",
    "#confusion = confusion_matrix(y_true, y_pred)#ValueError: multilabel-indicator is not supported \n",
    "      \n",
    "confusion = confusion_matrix(y_true.argmax(axis=1), y_pred.argmax(axis=1)) \n",
    "# 绘制热度图 \n",
    "plt.imshow(confusion, cmap=plt.cm.Greens) \n",
    "indices = range(len(confusion)) \n",
    "#plt.xticks(indices, classes, fontproperties=zhfont) \n",
    "#plt.yticks(indices, classes, fontproperties=zhfont) \n",
    "      \n",
    "plt.xticks(indices, classes) \n",
    "plt.yticks(indices, classes) \n",
    "plt.colorbar() \n",
    "plt.xlabel('y_pred') \n",
    "plt.ylabel('y_true') \n",
    "      \n",
    "# 显示数据 \n",
    "for first_index in range(len(confusion)): \n",
    "    for second_index in range(len(confusion[first_index])): \n",
    "        plt.text(first_index, second_index, confusion[first_index][second_index]) \n",
    "      \n",
    "# 显示图片 \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4efc093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d229e90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fc55d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import Trainer\n",
    "#from network import NFM\n",
    "import torch.utils.data as Data\n",
    "from Utils.criteo_loader import getTestData, getTrainData\n",
    "\n",
    "nfm_config = \\\n",
    "{\n",
    "    'n_class':9,\n",
    "    'linear_hidden':100,#线性模型输出层（隐层个数）\n",
    "    'embed_input_dim':1001,#embed输入维度\n",
    "    'embed_dim': 100, # 用于控制稀疏特征经过Embedding层后的稠密特征大小，embed输出维度\n",
    "    'dnn_hidden_units': [50,8],#MLP隐层和输出层\n",
    "    'num_sparse_features_cols':538,#the number of the gene columns\n",
    "    'num_dense_features': 0,#dense features number\n",
    "    'bi_dropout': 0.5,#Bi-Interaction 的dropout\n",
    "    'num_epoch': 500,#训练epoch次数\n",
    "    'batch_size': 24,#batch_size\n",
    "    'lr': 1e-3,\n",
    "    'l2_regularization': 1e-4,\n",
    "    'device_id': 0,\n",
    "    'use_cuda': False,\n",
    "    ##'train_data':'dataset/gene_247/train/guan_train_data.csv',\n",
    "    #'test_label':'dataset/gene_247/test/qiu_test_label.csv',\n",
    "    #'test_data':'dataset/gene_247/test/qiu_test_data.csv',\n",
    "    'gene_name':'dataset/gene_247/data/guan/gene_name.csv',\n",
    "    'label_name':'dataset/gene_247/data/guan/gene_label.csv'\n",
    "    #'fea_file': '../Data/criteo/processed_data/fea_col.npy',\n",
    "    #'validate_file': '../Data/criteo/processed_data/val_set.csv',\n",
    "    #'test_file': '../Data/criteo/processed_data/test_set.csv',\n",
    "    #'model_name': '../TrainedModels/NFM.model'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37360a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NFM(\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (BN_num): BatchNorm1d(10477, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (linear_model1): Linear(in_features=10477, out_features=2000, bias=True)\n",
      "  (BN_linear1): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (linear_model2): Linear(in_features=2000, out_features=100, bias=True)\n",
      "  (BN_linear2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (embedding_layers): Embedding(1001, 10)\n",
      "  (bi_pooling): BiInteractionPooling()\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (BN_bi): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dnn_layers): ModuleList(\n",
      "    (0): Linear(in_features=110, out_features=100, bias=True)\n",
      "    (1): Linear(in_features=100, out_features=9, bias=True)\n",
      "  )\n",
      "  (dnn_softmax): Softmax(dim=1)\n",
      ")\n",
      "BN_num.weight : torch.Size([10477])\n",
      "BN_num.bias : torch.Size([10477])\n",
      "linear_model1.weight : torch.Size([2000, 10477])\n",
      "linear_model1.bias : torch.Size([2000])\n",
      "BN_linear1.weight : torch.Size([2000])\n",
      "BN_linear1.bias : torch.Size([2000])\n",
      "linear_model2.weight : torch.Size([100, 2000])\n",
      "linear_model2.bias : torch.Size([100])\n",
      "BN_linear2.weight : torch.Size([100])\n",
      "BN_linear2.bias : torch.Size([100])\n",
      "embedding_layers.weight : torch.Size([1001, 10])\n",
      "BN_bi.weight : torch.Size([10])\n",
      "BN_bi.bias : torch.Size([10])\n",
      "dnn_layers.0.weight : torch.Size([100, 110])\n",
      "dnn_layers.0.bias : torch.Size([100])\n",
      "dnn_layers.1.weight : torch.Size([9, 100])\n",
      "dnn_layers.1.bias : torch.Size([9])\n",
      "weight: {'BN_num.weight': Parameter containing:\n",
      "tensor([ 3.3062e-03, -3.6208e-04,  1.8176e-03,  ..., -3.7651e-05,\n",
      "        -3.5726e-03,  2.4140e-03], device='cuda:0', requires_grad=True), 'BN_num.bias': Parameter containing:\n",
      "tensor([-2.0358e-07,  2.0133e-07, -4.5645e-08,  ...,  1.1009e-08,\n",
      "         8.6736e-08, -6.6281e-08], device='cuda:0', requires_grad=True), 'linear_model1.weight': Parameter containing:\n",
      "tensor([[-2.5030e-03,  5.2177e-04,  6.1801e-03,  ...,  1.5208e-05,\n",
      "         -6.5831e-03,  2.0600e-03],\n",
      "        [-6.8916e-06,  4.3988e-06,  3.7905e-07,  ...,  6.2958e-08,\n",
      "         -1.7485e-06, -8.6585e-07],\n",
      "        [-1.5568e-05, -5.4668e-07, -8.3050e-07,  ..., -1.2194e-07,\n",
      "         -1.5581e-06, -2.3859e-07],\n",
      "        ...,\n",
      "        [-3.5033e-07, -1.8809e-07, -2.3680e-08,  ..., -5.9514e-09,\n",
      "         -3.2391e-08,  2.7396e-07],\n",
      "        [ 3.4645e-05, -2.7527e-06, -1.2876e-04,  ..., -4.4924e-07,\n",
      "          1.0027e-04,  8.0547e-06],\n",
      "        [-2.8299e-03,  7.5659e-05,  1.8877e-03,  ...,  3.0615e-05,\n",
      "         -1.9200e-03,  9.5863e-04]], device='cuda:0', requires_grad=True), 'linear_model1.bias': Parameter containing:\n",
      "tensor([ 5.6530e-07, -1.3609e-09,  2.0723e-10,  ...,  1.8381e-14,\n",
      "         3.0561e-09,  7.6594e-07], device='cuda:0', requires_grad=True), 'BN_linear1.weight': Parameter containing:\n",
      "tensor([0.8667, 0.0199, 0.0520,  ..., 0.0070, 0.2186, 0.4577], device='cuda:0',\n",
      "       requires_grad=True), 'BN_linear1.bias': Parameter containing:\n",
      "tensor([-0.1022, -0.0337, -0.0815,  ..., -0.0163, -0.1203, -0.0785],\n",
      "       device='cuda:0', requires_grad=True), 'linear_model2.weight': Parameter containing:\n",
      "tensor([[-1.4169e-01,  2.8888e-03, -7.1680e-03,  ...,  4.6931e-05,\n",
      "         -1.8180e-02, -2.5470e-03],\n",
      "        [-1.0739e-02,  1.3682e-03,  8.3067e-03,  ..., -2.1003e-03,\n",
      "          1.3596e-02, -5.6550e-02],\n",
      "        [-9.3580e-02,  3.6581e-03, -5.8447e-03,  ..., -5.5173e-04,\n",
      "         -1.7214e-02, -1.5271e-02],\n",
      "        ...,\n",
      "        [-1.1208e-01, -1.6663e-02,  3.1139e-03,  ...,  4.5761e-03,\n",
      "          2.3408e-02, -1.2856e-01],\n",
      "        [ 1.0482e-01, -9.1404e-03,  8.9571e-03,  ...,  2.4963e-04,\n",
      "          8.9179e-02, -8.2695e-03],\n",
      "        [ 4.8084e-02, -2.4838e-03,  4.2678e-03,  ...,  7.3743e-05,\n",
      "         -7.7028e-02, -1.6879e-02]], device='cuda:0', requires_grad=True), 'linear_model2.bias': Parameter containing:\n",
      "tensor([ 1.6659e-06,  3.1392e-07,  4.3527e-06, -2.6291e-06,  4.5708e-07,\n",
      "        -1.0555e-05,  3.1255e-06,  4.1554e-07, -1.7085e-06, -1.8543e-05,\n",
      "        -4.6381e-06,  4.0252e-07, -3.5521e-06,  1.7848e-07, -1.0033e-06,\n",
      "         4.7863e-06, -2.8561e-06,  1.7158e-06,  3.7799e-06,  4.2603e-07,\n",
      "         1.2622e-05, -7.8561e-07,  4.4300e-06,  1.5180e-05, -1.5253e-07,\n",
      "        -2.9551e-07, -6.8762e-07, -4.2597e-07,  7.6644e-07, -2.1933e-07,\n",
      "        -3.3887e-07, -5.1189e-07, -3.4078e-06, -9.8545e-08, -2.2420e-06,\n",
      "        -1.3198e-06,  4.6603e-07, -3.1719e-06, -9.0013e-07,  7.3492e-07,\n",
      "        -7.9203e-06,  1.7869e-05, -7.4118e-07,  1.1180e-06,  3.6846e-07,\n",
      "        -1.1616e-07,  1.1624e-06,  4.6727e-06,  4.8488e-06,  3.4802e-07,\n",
      "         9.0545e-07, -9.5763e-07, -5.3250e-06, -2.8233e-07, -2.1013e-06,\n",
      "         6.4901e-07,  2.3112e-06,  3.4787e-07, -5.2180e-06, -1.4191e-06,\n",
      "         2.2571e-06, -1.1845e-06, -9.9842e-07, -3.5269e-07, -6.1658e-07,\n",
      "        -2.4006e-06, -8.6098e-07,  6.6267e-07, -6.9490e-06, -1.3346e-07,\n",
      "         2.5253e-06,  1.3366e-05,  2.0333e-06, -5.4208e-08, -2.5655e-06,\n",
      "         2.0230e-07,  2.5601e-06, -3.2755e-06, -1.5122e-07,  5.4461e-06,\n",
      "        -1.8044e-06, -4.2728e-09, -3.4759e-07, -4.6028e-07, -7.1731e-06,\n",
      "        -8.3146e-07, -3.2858e-06,  9.6182e-07,  1.6771e-06,  2.6528e-06,\n",
      "         1.2957e-06, -3.8165e-06,  9.2890e-08, -3.3188e-07, -4.9988e-07,\n",
      "         4.1764e-07,  2.4880e-06,  2.4698e-06,  6.8595e-06,  4.3064e-06],\n",
      "       device='cuda:0', requires_grad=True), 'BN_linear2.weight': Parameter containing:\n",
      "tensor([1.0331, 0.9158, 0.9149, 0.8687, 0.8502, 0.9493, 0.7806, 0.9500, 1.0174,\n",
      "        1.0471, 0.8955, 0.9515, 1.0316, 0.8589, 0.9817, 0.9812, 0.9366, 1.0083,\n",
      "        0.9812, 0.8281, 0.9596, 1.0039, 0.9623, 0.9742, 0.9319, 1.0125, 0.9522,\n",
      "        0.9620, 0.8875, 0.9824, 0.9805, 1.0312, 1.0064, 0.8480, 0.9076, 0.9456,\n",
      "        0.8938, 0.8676, 0.9855, 0.9728, 0.9577, 0.9687, 0.9868, 0.8680, 0.9282,\n",
      "        0.8599, 0.9827, 0.9453, 1.0231, 0.9825, 0.8818, 0.8785, 0.9641, 0.9743,\n",
      "        0.8698, 0.9573, 0.9223, 0.9463, 1.0130, 1.0241, 0.8966, 1.0382, 0.9060,\n",
      "        1.0755, 0.9438, 0.9201, 0.8836, 0.9389, 0.8662, 0.9503, 0.9179, 0.9355,\n",
      "        0.8426, 0.9578, 0.8734, 0.9231, 1.0094, 0.9345, 0.9595, 0.9219, 0.8761,\n",
      "        0.9528, 0.9997, 0.9201, 0.9912, 0.9708, 1.0895, 0.8570, 0.9776, 0.9489,\n",
      "        0.9210, 1.0411, 0.9242, 0.9060, 1.0938, 0.9132, 0.9007, 1.0008, 0.9141,\n",
      "        1.0151], device='cuda:0', requires_grad=True), 'BN_linear2.bias': Parameter containing:\n",
      "tensor([ 0.0652,  0.2058,  0.1693,  0.0417,  0.1008,  0.1072,  0.1981,  0.0046,\n",
      "         0.0291,  0.1110,  0.2216,  0.0925,  0.0724,  0.0722,  0.1646,  0.1200,\n",
      "         0.1801,  0.0900,  0.0258,  0.2672, -0.0025,  0.0284,  0.1506,  0.0562,\n",
      "         0.0574,  0.0169,  0.1635,  0.0948,  0.0149,  0.0667,  0.1178, -0.0299,\n",
      "        -0.0818,  0.1971,  0.1832,  0.0409,  0.0289, -0.0521,  0.0109, -0.0856,\n",
      "         0.0619,  0.0139,  0.0057,  0.1384,  0.1228,  0.0725, -0.0925,  0.1429,\n",
      "         0.0343,  0.0936,  0.1317,  0.1633,  0.0551, -0.0599,  0.0739,  0.0652,\n",
      "         0.0205,  0.0523,  0.1416,  0.0804,  0.2020,  0.0382,  0.0749,  0.0623,\n",
      "         0.1389, -0.0379,  0.0872,  0.0979,  0.1185,  0.0687, -0.0202,  0.1736,\n",
      "         0.0764,  0.0757,  0.0130,  0.0879,  0.0830,  0.0737, -0.0422,  0.1404,\n",
      "         0.0594,  0.0949,  0.0912,  0.0447,  0.0455,  0.1858,  0.1250,  0.1696,\n",
      "         0.0746,  0.0442,  0.1005,  0.1254,  0.1076,  0.1316,  0.0908, -0.0745,\n",
      "         0.0201,  0.1920,  0.2528,  0.1119], device='cuda:0',\n",
      "       requires_grad=True), 'embedding_layers.weight': Parameter containing:\n",
      "tensor([[-1.3218e-04, -1.0526e-06, -4.4645e-05,  ...,  1.7961e-04,\n",
      "          3.3934e-05,  4.7278e-04],\n",
      "        [-7.5625e-41, -4.8464e-41, -2.7408e-41,  ...,  4.5744e-41,\n",
      "         -1.0308e-40,  7.9919e-41],\n",
      "        [-5.9517e-41, -1.0895e-41,  6.3482e-41,  ..., -1.8420e-41,\n",
      "         -4.4823e-41,  1.7565e-41],\n",
      "        ...,\n",
      "        [-8.9757e-41,  1.4024e-41,  1.3965e-41,  ..., -7.3763e-41,\n",
      "         -5.0664e-41,  9.7848e-41],\n",
      "        [-2.6814e-41, -4.0568e-41, -3.8653e-41,  ..., -1.3822e-40,\n",
      "          6.5272e-41, -6.7844e-41],\n",
      "        [-2.1375e-04,  2.3837e-05, -4.1579e-05,  ..., -3.6993e-04,\n",
      "         -4.4749e-04,  3.0772e-04]], device='cuda:0', requires_grad=True), 'BN_bi.weight': Parameter containing:\n",
      "tensor([0.4495, 0.8678, 0.5402, 0.3750, 0.8367, 0.4929, 0.1981, 0.4022, 0.5727,\n",
      "        0.7985], device='cuda:0', requires_grad=True), 'BN_bi.bias': Parameter containing:\n",
      "tensor([ 0.1398, -0.3106,  0.0334, -0.0910, -0.2718, -0.0893, -0.0476, -0.1849,\n",
      "         0.0010,  0.2450], device='cuda:0', requires_grad=True), 'dnn_layers.0.weight': Parameter containing:\n",
      "tensor([[ 0.0110, -0.0113, -0.0117,  ..., -0.0044,  0.0785, -0.0102],\n",
      "        [-0.0013, -0.0207, -0.0550,  ...,  0.1870, -0.0151,  0.0128],\n",
      "        [-0.0342, -0.0015, -0.0503,  ...,  0.0029,  0.0543,  0.1734],\n",
      "        ...,\n",
      "        [ 0.0680, -0.0485,  0.0288,  ..., -0.2272,  0.0498,  0.0010],\n",
      "        [-0.0096,  0.0665,  0.0026,  ...,  0.0922, -0.0449, -0.1571],\n",
      "        [-0.0475,  0.1004, -0.0131,  ...,  0.1226, -0.1759,  0.0808]],\n",
      "       device='cuda:0', requires_grad=True), 'dnn_layers.0.bias': Parameter containing:\n",
      "tensor([ 0.1274, -0.1532, -0.0021,  0.2620,  0.0638,  0.0956, -0.0668,  0.0579,\n",
      "         0.0296,  0.2318,  0.1845,  0.0149,  0.3154, -0.0162, -0.1139,  0.1076,\n",
      "         0.3762,  0.2894, -0.1319, -0.0747,  0.1506,  0.1155,  0.1270, -0.2074,\n",
      "         0.0946,  0.2990, -0.1135,  0.1377,  0.0728,  0.1823, -0.0071, -0.1761,\n",
      "        -0.0881,  0.1160,  0.0663,  0.1016, -0.1852,  0.1032,  0.1638,  0.0551,\n",
      "        -0.0289, -0.0772, -0.0932,  0.2599,  0.0606, -0.0264, -0.1384,  0.0033,\n",
      "         0.1593,  0.1107,  0.0276,  0.0469,  0.1312, -0.0527,  0.2210,  0.2118,\n",
      "         0.0818,  0.2340,  0.2965, -0.1116,  0.2841, -0.0695,  0.1843,  0.3205,\n",
      "         0.0665,  0.1832, -0.0229,  0.0172,  0.2374,  0.1713,  0.0549, -0.0494,\n",
      "         0.1357,  0.4775,  0.2240, -0.1677,  0.0741,  0.1617,  0.0383,  0.2399,\n",
      "         0.0601, -0.0098, -0.0800, -0.1032, -0.1176,  0.0133,  0.0907, -0.0200,\n",
      "         0.1589,  0.1954, -0.2010,  0.1909, -0.1291,  0.3488, -0.0588, -0.0758,\n",
      "        -0.0316,  0.2839,  0.0951, -0.0143], device='cuda:0',\n",
      "       requires_grad=True), 'dnn_layers.1.weight': Parameter containing:\n",
      "tensor([[-2.7324e-01,  2.3644e-01, -5.0318e-03, -1.7710e-01,  6.0423e-02,\n",
      "         -6.7506e-01,  2.5602e-02, -2.0962e-01,  1.4523e-01, -8.7645e-02,\n",
      "         -5.0003e-02, -4.5243e-03,  4.0928e-01, -8.7965e-02,  1.9377e-03,\n",
      "         -8.5524e-02,  2.1357e-02, -1.4935e-01, -1.8714e-01,  9.4485e-03,\n",
      "         -4.2996e-01,  3.2578e-01, -1.2014e-01,  2.6958e-01, -2.2294e-01,\n",
      "          2.3765e-01,  1.7218e-01,  1.3566e-01,  1.8600e-01, -1.5833e-01,\n",
      "         -1.0766e-01,  1.6803e-02,  1.2746e-01, -3.4316e-01,  2.8458e-01,\n",
      "          1.2936e-01, -1.1254e-01, -6.3060e-03, -3.9040e-01, -1.1936e-02,\n",
      "          1.5694e-01, -1.1577e-01,  1.0212e-01, -6.8461e-02, -1.1848e-01,\n",
      "         -1.2158e-01,  2.9727e-01,  1.9192e-01,  5.2898e-02,  2.3800e-02,\n",
      "          1.4437e-01, -3.7839e-01,  1.7680e-01, -2.7888e-01, -1.3518e-01,\n",
      "         -3.1304e-02, -2.7959e-01,  2.7088e-01,  1.0476e-01,  4.9491e-02,\n",
      "          2.0560e-03,  1.9149e-01, -3.0153e-03, -1.0242e-01, -1.0063e-01,\n",
      "          2.1316e-01,  3.1383e-02, -4.4740e-01,  2.9495e-01,  2.3260e-01,\n",
      "         -3.5219e-01,  3.4280e-03, -1.5198e-01,  1.7790e-01, -8.2855e-02,\n",
      "          9.0583e-02, -3.6983e-01, -1.4605e-01,  1.0282e-05, -6.3117e-01,\n",
      "         -1.4582e-01, -2.8048e-01,  1.6936e-01,  1.2146e-01,  1.9336e-01,\n",
      "         -1.7345e-01, -1.3652e-01,  4.5761e-02,  2.6641e-01,  2.0115e-01,\n",
      "          1.7596e-01, -8.4855e-02, -1.2224e-01, -5.3767e-01,  1.2604e-01,\n",
      "         -2.1604e-01, -6.2724e-02, -2.1998e-01,  2.5021e-01,  2.7789e-01],\n",
      "        [ 2.1894e-01, -2.4487e-01, -2.2976e-02, -3.1369e-02,  9.2663e-02,\n",
      "          3.0733e-01,  1.6932e-01,  1.1429e-01,  1.3117e-02, -1.5512e-01,\n",
      "          1.9235e-01, -2.8514e-02, -1.2371e-01,  1.1408e-01,  2.3420e-01,\n",
      "          1.2748e-01, -7.7386e-02,  2.1453e-01,  2.4071e-01,  8.0481e-02,\n",
      "          1.1797e-01, -1.8689e-01, -1.4508e-03, -5.7852e-02, -1.5263e-01,\n",
      "         -4.1431e-01,  1.0185e-03, -2.6565e-01, -1.5344e-01, -9.0942e-02,\n",
      "          2.5347e-01,  1.4670e-01, -1.7806e-01,  1.4923e-01, -3.0979e-01,\n",
      "         -1.5305e-01,  1.0566e-01, -5.6210e-02, -8.9134e-02,  9.4917e-03,\n",
      "         -2.5657e-01,  1.7056e-01, -1.3767e-01,  1.4807e-01,  5.0909e-02,\n",
      "          6.3034e-02, -1.5865e-01, -1.3941e-01, -1.2311e-01,  7.6076e-02,\n",
      "         -2.5810e-01,  3.2789e-01,  5.4795e-02, -2.9573e-01,  2.2144e-01,\n",
      "          2.1636e-01,  1.6045e-01, -3.0788e-01, -2.0970e-01,  1.8439e-01,\n",
      "          3.7055e-02, -2.1132e-01, -1.9557e-01,  1.8215e-01,  2.2133e-01,\n",
      "         -1.7466e-01, -9.8372e-02,  2.0362e-01, -3.8059e-01, -7.7302e-02,\n",
      "          6.9599e-02,  4.0729e-02,  2.6008e-01, -7.1024e-02, -3.1660e-01,\n",
      "          6.5539e-02,  4.1250e-01,  8.5319e-02,  3.2365e-01, -1.7198e-02,\n",
      "          2.9281e-01,  1.2638e-01, -2.3815e-01, -2.1645e-01, -2.0380e-01,\n",
      "          2.1378e-01,  8.2036e-02,  2.0438e-02, -3.4931e-01, -6.4578e-02,\n",
      "          6.3507e-03,  2.8800e-02,  2.2683e-01,  7.7874e-02, -1.7567e-02,\n",
      "          8.3226e-03,  1.9636e-01,  1.7266e-01, -2.2328e-01, -1.6053e-01],\n",
      "        [-2.8589e-01,  5.9732e-02,  2.1090e-01, -3.7414e-01, -3.7339e-02,\n",
      "          1.0625e-02,  1.1762e-01,  2.8088e-01,  2.1300e-02,  3.5293e-02,\n",
      "          1.3302e-02,  2.1186e-02, -3.4744e-01, -9.3678e-02, -1.7448e-01,\n",
      "          1.4626e-01, -2.1139e-01, -4.1043e-01,  1.9092e-01,  2.5212e-01,\n",
      "         -1.1834e-01, -2.5309e-01, -2.3485e-01,  6.4035e-02, -1.9723e-01,\n",
      "         -7.4310e-02,  1.8593e-01, -1.5414e-01,  1.6137e-01, -2.7639e-02,\n",
      "         -5.3811e-02,  2.6159e-01,  2.1107e-01, -3.5522e-01,  1.1648e-01,\n",
      "         -8.9080e-02,  9.9242e-02,  2.1734e-01,  7.3537e-02,  1.4559e-01,\n",
      "         -1.8415e-01,  7.5476e-02,  9.5986e-02, -6.1044e-01, -1.9756e-01,\n",
      "          6.0461e-02,  4.7522e-02,  1.2683e-01, -5.1842e-01, -1.1389e-01,\n",
      "          1.9113e-01,  1.1192e-01, -1.0202e-02, -1.5254e-01, -8.6050e-02,\n",
      "          5.3300e-03, -1.1290e-01, -1.1801e-02, -1.6082e-01,  1.9734e-01,\n",
      "         -1.3791e-01,  3.0124e-01, -2.2827e-01, -5.9131e-02,  2.9028e-01,\n",
      "         -1.9430e-01,  1.4750e-01, -2.2418e-01, -1.2914e-01,  7.8095e-02,\n",
      "          1.1192e-01,  3.3336e-01,  1.3735e-01,  6.2779e-02, -1.3843e-01,\n",
      "          1.9888e-01,  5.2163e-02, -1.2713e-01, -1.3477e-01, -4.6850e-01,\n",
      "          2.3424e-01, -8.0854e-03,  1.4323e-01,  2.2394e-02,  2.5473e-01,\n",
      "          2.9031e-01,  1.5570e-01,  2.2329e-01, -6.3796e-03, -4.8793e-02,\n",
      "          8.7706e-02, -3.5478e-02,  8.0473e-02, -3.0207e-01,  3.2319e-01,\n",
      "          4.1940e-02,  3.0682e-01, -2.6621e-01, -2.6184e-01,  1.2334e-01],\n",
      "        [ 8.2017e-02, -1.3282e-01, -7.5583e-02,  2.8684e-01,  7.3787e-02,\n",
      "         -9.9279e-02, -2.0206e-01, -1.6990e-01,  6.6216e-02,  9.9988e-02,\n",
      "          1.9131e-01, -2.6467e-02,  2.8807e-01, -1.9684e-01, -5.0790e-02,\n",
      "         -2.0165e-03,  2.0837e-01,  3.5745e-01, -1.9950e-01, -1.0381e-01,\n",
      "          6.1983e-02,  3.4346e-01, -1.1526e-01, -7.1278e-02, -3.5904e-02,\n",
      "          3.3011e-01, -1.2137e-01,  2.2358e-01,  2.8740e-02, -4.0397e-02,\n",
      "         -1.6879e-01, -2.9516e-01, -1.3316e-01,  1.1777e-01, -7.9054e-02,\n",
      "          6.1817e-02, -2.3803e-01, -3.6741e-01, -2.7330e-01, -1.5690e-02,\n",
      "          1.4577e-01, -8.7427e-02, -2.0239e-02,  2.4369e-01, -5.1708e-02,\n",
      "         -9.3393e-02, -1.6088e-01, -1.2525e-02,  2.8751e-01,  2.6130e-01,\n",
      "         -2.0957e-01, -1.4988e-01,  1.6626e-01, -3.0531e-01,  2.0958e-01,\n",
      "          2.8275e-01,  2.4231e-02,  1.7718e-01,  2.8430e-01, -3.2888e-01,\n",
      "          1.6998e-01, -1.8923e-01,  1.4007e-01,  1.7371e-01, -1.8827e-01,\n",
      "          1.5669e-01, -1.6369e-01, -2.2678e-02,  3.1696e-01,  2.4723e-01,\n",
      "         -2.4098e-01, -2.0795e-01, -1.3566e-01,  2.3046e-01, -5.0999e-02,\n",
      "         -3.0947e-01, -2.2007e-02,  1.7261e-01, -5.4852e-02,  8.1361e-02,\n",
      "          2.4320e-02, -1.8742e-01, -1.0638e-01, -3.5144e-01, -3.3330e-01,\n",
      "         -2.3982e-01,  5.2452e-02, -2.8589e-01,  1.0417e-01,  3.3910e-01,\n",
      "         -1.3024e-01,  1.6322e-01, -2.6940e-01,  1.1189e-01, -5.1120e-02,\n",
      "         -2.2150e-01, -2.2673e-01,  3.1290e-01,  1.4702e-01, -1.7429e-01],\n",
      "        [ 1.1554e-01,  7.9568e-02,  8.7439e-03,  6.3441e-02, -5.2719e-02,\n",
      "          7.0397e-02, -2.0086e-02,  7.3463e-02, -3.6864e-02,  2.6620e-01,\n",
      "         -6.4852e-02, -1.4075e-01,  2.6580e-01, -2.1298e-01, -8.6686e-02,\n",
      "          4.0779e-02,  1.8767e-01, -1.7156e-01, -3.4163e-01, -2.5452e-01,\n",
      "          1.9608e-01, -1.0781e-01, -1.3336e-01, -2.5406e-01, -3.5136e-02,\n",
      "          9.4258e-02,  8.9737e-02, -2.6044e-01,  1.5138e-01,  2.2823e-01,\n",
      "         -4.8379e-03,  1.4739e-01, -1.1431e-01, -3.4933e-02, -4.2055e-02,\n",
      "          1.7548e-01,  7.2559e-02,  8.9128e-02,  2.0518e-01, -9.3546e-02,\n",
      "         -1.6260e-01,  8.8943e-02, -2.9471e-01,  8.9083e-02,  7.1403e-02,\n",
      "         -1.3268e-01, -1.1856e-01,  2.3470e-01, -6.2004e-02, -3.1890e-01,\n",
      "          1.3999e-01, -2.2315e-01, -2.7357e-01, -1.1195e-01, -2.0538e-01,\n",
      "         -2.7323e-01, -3.3405e-01,  1.8409e-01, -1.0731e-01, -1.8336e-01,\n",
      "         -2.8897e-01,  2.2622e-01, -1.2688e-01,  2.2298e-01,  1.4714e-01,\n",
      "          3.1865e-01,  2.1764e-01, -8.5428e-02,  2.0414e-01,  1.8483e-01,\n",
      "          1.4472e-01, -2.8605e-01,  3.6779e-01,  4.0547e-02,  3.1348e-01,\n",
      "          1.5519e-01, -1.3481e-01,  2.3898e-01, -1.0843e-01,  5.2340e-02,\n",
      "          4.4823e-02,  2.0025e-01, -7.8991e-02,  1.6609e-01,  3.1680e-01,\n",
      "          6.8299e-02, -1.9709e-01,  1.3192e-01,  2.1190e-01, -2.3180e-04,\n",
      "         -5.4928e-02, -1.3957e-01,  1.7083e-01,  2.0475e-01,  2.2401e-01,\n",
      "         -1.9810e-01,  2.6767e-01, -2.9649e-01, -5.6650e-02, -2.1698e-01],\n",
      "        [ 1.6323e-02,  2.0776e-01,  1.8089e-01, -2.1734e-04, -1.8234e-01,\n",
      "          1.3364e-01,  9.2765e-02,  8.3791e-02, -5.8598e-02,  4.9887e-02,\n",
      "         -2.1085e-01, -2.7125e-01,  8.2994e-02, -2.6789e-01,  4.9832e-02,\n",
      "          1.0541e-01, -2.1467e-01, -4.3233e-03,  1.7401e-01,  7.8114e-02,\n",
      "          6.3487e-02,  2.0733e-01, -1.8675e-03,  1.6436e-01, -2.0501e-01,\n",
      "          1.2995e-01,  9.5004e-02,  1.6509e-01,  3.1046e-02, -8.2467e-02,\n",
      "         -1.3807e-01,  1.1524e-01, -1.1723e-01,  1.2334e-01,  1.6001e-02,\n",
      "          7.0626e-03,  1.4549e-01, -3.6065e-01, -3.2184e-01,  5.1445e-02,\n",
      "          1.4983e-01,  1.2910e-01,  1.7991e-01,  1.1379e-01, -7.8274e-02,\n",
      "         -1.8610e-01,  8.9011e-02,  1.1911e-01,  2.3820e-01,  2.8095e-01,\n",
      "          1.7211e-01,  7.3218e-02,  1.7827e-01,  3.4373e-01, -2.5070e-01,\n",
      "          1.1040e-01,  2.3841e-01,  1.2240e-01, -2.5978e-01,  8.4172e-02,\n",
      "         -2.4081e-01,  5.9254e-02, -2.5374e-01,  3.6177e-02, -4.3444e-02,\n",
      "          1.9584e-02, -4.9755e-02, -3.0192e-02,  1.9828e-01,  2.4404e-02,\n",
      "          3.7797e-02, -1.0333e-02, -1.9996e-01, -7.2250e-01, -2.3436e-01,\n",
      "          2.1212e-02,  1.5492e-01, -3.1872e-02, -3.6258e-01,  1.5952e-02,\n",
      "          1.0282e-01, -7.7559e-02,  9.6958e-02,  5.5681e-02,  9.1195e-02,\n",
      "          1.3871e-01,  1.4348e-01,  1.1450e-01,  1.0220e-01,  2.3594e-01,\n",
      "          1.5464e-01, -1.2887e-01,  4.1925e-02,  1.1249e-02,  1.6236e-02,\n",
      "          7.1336e-02,  3.1276e-02, -1.4249e-01, -1.5147e-01, -2.0914e-02],\n",
      "        [-4.1362e-01, -3.0521e-01,  2.0601e-01, -1.4983e-01,  1.1413e-02,\n",
      "         -1.6447e-02,  1.1650e-01,  1.7789e-01, -2.8481e-02,  1.8494e-01,\n",
      "          1.1352e-01, -8.2835e-03, -6.2783e-02,  3.7419e-02, -2.0009e-01,\n",
      "          1.9966e-01,  1.9273e-01,  1.8354e-01,  1.1854e-01,  1.4120e-01,\n",
      "         -2.7348e-01, -2.0972e-01,  4.5659e-01, -1.1709e-01,  2.5764e-02,\n",
      "          1.4127e-01, -3.2264e-01,  1.1892e-01,  7.3338e-02,  2.3959e-01,\n",
      "          6.0353e-02, -3.6244e-01,  3.5655e-02, -9.3052e-02,  3.2955e-01,\n",
      "         -2.3188e-01, -2.9590e-01,  7.6305e-02,  1.0661e-02,  2.8932e-01,\n",
      "         -6.9722e-02, -4.9804e-01,  1.9026e-01, -7.0410e-02,  1.3197e-02,\n",
      "          1.9639e-02,  6.0799e-02, -2.1965e-01, -2.6748e-01,  9.1610e-02,\n",
      "          2.2478e-01,  1.9534e-01,  2.5353e-01,  1.8478e-01,  1.2913e-01,\n",
      "          2.2900e-01,  3.1180e-01,  1.8566e-01,  2.0537e-01,  2.2356e-01,\n",
      "          3.3655e-01, -2.4977e-01, -5.4539e-02,  1.8931e-01,  1.7206e-01,\n",
      "         -2.2407e-01, -4.7127e-02, -1.8956e-01,  4.3023e-02, -4.2144e-02,\n",
      "          1.7687e-01,  2.4265e-01, -2.0369e-01,  1.5991e-01,  1.5603e-01,\n",
      "         -2.6400e-01,  1.7310e-01, -1.2518e-01, -2.4900e-01, -1.6835e-01,\n",
      "          1.0779e-01, -3.2750e-01,  1.2838e-01, -8.0647e-02, -3.6441e-01,\n",
      "          2.1105e-01,  2.7713e-01,  2.4655e-01,  9.9633e-02,  7.9002e-02,\n",
      "         -3.3413e-01,  1.9932e-01, -4.8405e-01,  1.0493e-01, -2.3147e-01,\n",
      "          1.7632e-01, -1.2125e-01,  1.4747e-01, -7.5157e-02,  1.9239e-01],\n",
      "        [ 1.9413e-01, -3.6881e-01, -2.2260e-01,  1.6890e-01,  9.3438e-02,\n",
      "         -3.4980e-02, -1.5275e-01, -1.4710e-01, -1.1653e-01,  1.5014e-01,\n",
      "          1.0953e-01,  1.1226e-01, -1.6308e-01,  1.7210e-01, -5.6901e-02,\n",
      "         -2.4687e-01,  1.7618e-01,  1.8546e-01, -2.1447e-01, -1.8862e-01,\n",
      "          1.6645e-01, -3.1605e-01,  4.7179e-02, -2.9516e-01,  2.7405e-01,\n",
      "         -1.2418e-01, -3.0121e-01, -1.3571e-01, -2.6318e-01,  2.2490e-01,\n",
      "          1.1461e-01, -2.6865e-01, -7.6558e-02,  1.4894e-01, -1.0670e-01,\n",
      "          9.9959e-02, -2.3285e-01,  1.7420e-01,  2.9220e-01, -4.6958e-02,\n",
      "         -1.4746e-01, -4.5057e-02, -2.2432e-01,  8.0687e-02,  1.9084e-01,\n",
      "          1.4571e-01, -2.9712e-01, -2.3104e-01, -7.0340e-02, -1.8640e-01,\n",
      "         -1.7482e-01, -1.5662e-02, -3.7255e-01,  1.8369e-01,  2.4186e-01,\n",
      "         -3.0116e-01, -1.4999e-01, -2.1820e-01,  2.9021e-01, -1.9199e-01,\n",
      "          2.2794e-01, -3.8089e-01,  2.2686e-01,  1.1217e-01, -1.7813e-01,\n",
      "          1.6557e-02,  5.3647e-03,  2.3163e-01, -2.2360e-01, -2.6270e-01,\n",
      "          1.5050e-01, -6.8703e-02, -2.6057e-02, -4.2529e-02,  2.9606e-01,\n",
      "         -8.7776e-02, -8.8554e-02,  1.0225e-01,  2.5903e-01,  2.9594e-01,\n",
      "         -1.3400e-01,  1.7874e-01, -2.5871e-01,  6.5575e-02, -3.0958e-01,\n",
      "         -1.7895e-01, -2.3535e-01, -1.3018e-01, -3.2237e-01, -3.8478e-01,\n",
      "         -3.4506e-01,  1.8506e-01, -2.8291e-02,  2.6799e-01, -1.1656e-01,\n",
      "          1.4825e-01, -2.8331e-01,  2.6323e-01,  9.3169e-02, -2.0666e-01],\n",
      "        [ 1.7039e-01,  2.2440e-01, -2.6111e-01, -1.4159e-01,  2.6529e-01,\n",
      "         -4.7544e-02,  6.2119e-02, -2.2683e-01,  1.3760e-01, -2.2619e-01,\n",
      "          1.4675e-01,  1.8783e-01, -4.7186e-02,  2.3015e-01,  2.4083e-01,\n",
      "         -2.5110e-01, -1.0238e-01, -1.7267e-01,  1.0476e-01,  7.0085e-02,\n",
      "          8.9067e-02, -8.5241e-02,  5.4553e-02,  2.7792e-01,  2.4799e-01,\n",
      "         -1.6378e-01,  2.3648e-01, -4.1392e-02, -2.2785e-01, -2.9170e-01,\n",
      "          1.2592e-01,  2.1727e-01,  2.0969e-01, -7.1650e-02,  1.2003e-01,\n",
      "          1.7177e-01, -2.3382e-02,  2.2410e-01,  1.2395e-01, -6.6334e-02,\n",
      "          2.2875e-01,  1.6044e-01,  2.4555e-01,  6.3577e-02,  1.8907e-01,\n",
      "          2.1361e-01,  2.1108e-01, -1.1152e-01,  9.1445e-02, -1.4851e-01,\n",
      "         -2.2701e-01,  7.3767e-02, -1.2017e-01, -1.7418e-02, -1.6666e-01,\n",
      "         -9.1428e-02, -1.0753e-02, -1.4449e-01, -2.4615e-01,  1.5163e-01,\n",
      "          7.5462e-02,  1.9504e-01,  2.6480e-01, -1.9216e-01, -1.7583e-01,\n",
      "          1.0734e-01,  1.0659e-01,  2.3094e-01, -1.9535e-01, -2.6206e-01,\n",
      "          4.6422e-02,  1.0667e-01, -1.0918e-01,  7.7017e-02, -1.9026e-01,\n",
      "          2.3711e-01, -1.3187e-01, -1.3699e-01, -9.6242e-02, -3.3055e-02,\n",
      "         -2.8966e-01,  1.5048e-01,  2.6073e-01,  2.3456e-01,  6.7180e-02,\n",
      "         -8.3092e-02, -1.5266e-01, -1.1084e-01, -2.3827e-01, -2.1566e-01,\n",
      "          2.6256e-01, -2.5915e-01,  1.5130e-01, -5.6688e-02,  5.4825e-02,\n",
      "          1.4276e-01, -7.4981e-02, -1.3597e-01,  2.9644e-01,  2.1307e-01]],\n",
      "       device='cuda:0', requires_grad=True), 'dnn_layers.1.bias': Parameter containing:\n",
      "tensor([-0.0552,  0.0170, -0.0350,  0.3551,  0.1610, -0.2190,  0.1986,  0.0107,\n",
      "        -0.0133], device='cuda:0', requires_grad=True)}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#功能：加载保存到path中的各层参数到神经网络\n",
    "\n",
    "path='dataset/qiuguan/model_new/NFM_encde_1000/NMF8029.pkl'\n",
    "from new_nfm_network_batch_1 import NFM\n",
    "nfm=NFM(nfm_config)\n",
    "\n",
    "#print(nfm)\n",
    "#net = nn.DataParallel(net)\n",
    "#net = net.to(device)\n",
    "nfm.load_state_dict(torch.load(path),strict=False)\n",
    "nfm.cuda()\n",
    "\n",
    "print(nfm)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nfm_params = list(nfm.named_parameters())\n",
    "#print(nfm_params)\n",
    "net=nfm\n",
    "\n",
    "\n",
    "weight={}\n",
    "for name,parameters in net.named_parameters():\n",
    "    print(name,':',parameters.size())\n",
    "    #names.append(name)\n",
    "    weight[name]=parameters\n",
    "print(\"weight:\",weight)\n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "disease=pd.read_csv(nfm_config['label_name'],sep=',',header=None)\n",
    "disease=np.array(disease)\n",
    "disease=disease[1:,-1]\n",
    "disease=disease.tolist()\n",
    "#print(disease)\n",
    "dis_names=[]\n",
    "#dis_names.append()\n",
    "\n",
    "for id in disease:\n",
    "    if id not in dis_names:\n",
    "        dis_names.append(id)\n",
    "\n",
    "print(dis_names)\n",
    "val=[ i for i in range(nfm_config['n_class'])]\n",
    "print(val)\n",
    "\n",
    "disease_names={}\n",
    "#disease_names.keys=dis_names\n",
    "#disease_names.values=val\n",
    "#disease_names[dis_names]=val\n",
    "#print(disease_names)\n",
    "disease_names=dict(zip(dis_names,val))\n",
    "print(disease_names)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "genes=[]\n",
    "gene_res={}\n",
    "title=pd.read_csv(nfm_config['gene_name'],sep=',',header=None)\n",
    "print(title.shape)\n",
    "\n",
    "\n",
    "\n",
    "def one_hot_smoothing(labels, classes, label_smoothing=0.2):\n",
    "    n = len(labels)\n",
    "    #n=labels.shape[0]\n",
    "    eoff = label_smoothing / classes\n",
    "    output = np.ones((n, classes), dtype=np.float32) * eoff\n",
    "    for row, label in enumerate(labels):\n",
    "        output[row, label] = 1 - label_smoothing + eoff\n",
    "        #print(\"row:\",row,\"label:\",label)\n",
    "    return output\n",
    "\n",
    "\n",
    "new_labels=[i for i in range(nfm_config['n_class'])]\n",
    "new_targets=one_hot_smoothing(new_labels,nfm_config['n_class'])\n",
    "print(new_targets)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(nfm_config['n_class']):\n",
    "    \n",
    "    #new_targets=torch.tensor([0, 0, 0, 0, 0, 0, 0, 1])\n",
    "    new_targets=torch.tensor(new_targets).cuda()\n",
    "    l1=torch.mv(weight['fc3.weight'].T,(new_targets[i]-weight['fc3.bias']))\n",
    "    l2=torch.mv(weight['fc2.weight'].T,(l1-weight['fc2.bias']))\n",
    "    #l2=l2[100:]\n",
    "    l3=torch.mv(weight['fc1.weight'].T,(l2-weight['fc1.bias']))\n",
    "    #l4=torch.mv(weight['linear_model1.weight'].T,(l3-weight['linear_model1.bias']))\n",
    "    top_k=torch.topk(l3,20,largest=True)\n",
    "    #print(top_k)\n",
    "    index=top_k.indices\n",
    "    index=index.tolist()\n",
    "    #print(index)\n",
    "    d1=pd.DataFrame(title,columns=index)#\n",
    "    gene=d1.iloc[1,:]\n",
    "    gene=gene.tolist()\n",
    "    genes.append(gene)\n",
    "    #print(genes)\n",
    "    \n",
    "    gene_res=dict(zip(dis_names,genes))\n",
    "print(gene_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc55a4bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
