{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a33737fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import Trainer\n",
    "from network import NFM\n",
    "import torch.utils.data as Data\n",
    "from Utils.criteo_loader import getTestData, getTrainData\n",
    "\n",
    "nfm_config = \\\n",
    "{\n",
    "    'n_class':9,\n",
    "    'linear_hidden1':1000,\n",
    "    'linear_hidden':100,#线性模型输出层（隐层个数）\n",
    "    'embed_input_dim':1001,#embed输入维度\n",
    "    'embed_dim': 100, # 用于控制稀疏特征经过Embedding层后的稠密特征大小，embed输出维度\n",
    "    #'dnn_hidden_units': [100,11],#MLP隐层和输出层\n",
    "    \n",
    "    'dnn_hidden_units':[100,9],#MLP隐层\n",
    "    'num_sparse_features_cols':4224,#the number of the gene columns\n",
    "    'num_dense_features': 0,#dense features number\n",
    "    'bi_dropout': 0.5,#Bi-Interaction 的dropout\n",
    "    'num_epoch': 500,#训练epoch次数\n",
    "    'batch_size': 16,#batch_size\n",
    "    'lr': 1e-3,\n",
    "    'l2_regularization': 1e-4,\n",
    "    'device_id': 0,\n",
    "    'use_cuda': False,\n",
    "    'epoch':1000,\n",
    "    \n",
    "    #'train_file': '../Data/criteo/processed_data/train_set.csv',\n",
    "    #'fea_file': '../Data/criteo/processed_data/fea_col.npy',\n",
    "    #'validate_file': '../Data/criteo/processed_data/val_set.csv',\n",
    "    #'test_file': '../Data/criteo/processed_data/test_set.csv',\n",
    "    #'model_name': '../TrainedModels/NFM.model'\n",
    "    #'train_file':'data/xiaoqiu_gene_5000/train/final_5000_encode_100x.csv',\n",
    "    'train_data':'dataset/xiaoqiu/train/train_5000_datas.csv',\n",
    "    'train_label':'dataset/xiaoqiu/train/train_5000_labels.csv',\n",
    "    'test_data':'dataset/xiaoqiu/test/test_5000_datas.csv',\n",
    "    'test_label':'dataset/xiaoqiu/test/test_5000_labels.csv',\n",
    "    #'title':'dataset/xiaoguan/RF/RF_for_train/train_class_9/test/test_data.csv',\n",
    "    \n",
    "    #'all':''\n",
    "    #'title':'data/xiaoqiu_gene_5000/train/gene_5000_gene_name.csv',\n",
    "    #'all':'data/xiaoqiu_gene_5000/train/gene_5000_label_name.csv'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3b90f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[190 220 490 ... 360 370 420]\n",
      " [110 220 500 ... 340 260 420]\n",
      " [100 300 500 ... 330 350 390]\n",
      " ...\n",
      " [450 360 500 ... 430 360 500]\n",
      " [420 350 530 ... 440 370 500]\n",
      " [420 360 540 ... 430 370 450]]\n"
     ]
    }
   ],
   "source": [
    "#准备训练集\n",
    "\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.backends.cudnn as cudnn\n",
    "#3from tensorboardX import SummaryWriter\n",
    "\n",
    "#import network\n",
    "import config\n",
    "import evaluate\n",
    "import data_utils\n",
    "import Trainer\n",
    "#from utils import \n",
    "#准备训练集\n",
    "#from new_dataset_processed import FMData\n",
    "from dataset_process import FMData\n",
    "def prepare_dataset(m_data,m_label,batch_size,n_class):\n",
    "    m_dataset=FMData(m_data,m_label,n_class)\n",
    "    m_dataloader=data.DataLoader(m_dataset, drop_last=True,batch_size=batch_size,shuffle=True,num_workers=4)\n",
    "    \n",
    "    return m_dataset,m_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbb89935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from new_nfm_network import NFM\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.backends.cudnn as cudnn\n",
    "#3from tensorboardX import SummaryWriter\n",
    "import sys \n",
    "#import network\n",
    "import config\n",
    "import evaluate\n",
    "import data_utils\n",
    "import Trainer\n",
    "import torchmetrics\n",
    "def   train_data(model,train_loader,test_loader,batch_size,model_path):\n",
    "    #train_accuracy=torchmetrics.Accuracy()\n",
    "    #test_accuracy=torchmetrics.Accuracy()\n",
    "    BATCH_SIZE=batch_size\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=nfm_config['lr'], weight_decay=nfm_config['l2_regularization'])\n",
    "    total = 0\n",
    "    \n",
    "    #loss_func = torch.nn.BCELoss()\n",
    "    loss_func=torch.nn.CrossEntropyLoss()\n",
    "    #loss_func=nn.MultiLabelSoftMarginLoss()\n",
    "    #loss_func=torch.nn.LogSoftmax()\n",
    "    num=1\n",
    "    #model=nn.Softmax(nn.Linear(10149,16)).to(device)\n",
    "    # 从DataLoader中获取小批量的id以及数据\n",
    "    \n",
    "    batch_size=0\n",
    "    for epoch_id in range(1000):\n",
    "        correct=0\n",
    "        total=0\n",
    "        total_test_acc=0\n",
    "        \n",
    "        for batch_idx, (x, labels) in enumerate(train_loader):\n",
    "            x = Variable(x)\n",
    "            labels = Variable(labels)\n",
    "            \n",
    "            \n",
    "            #x = torch.tensor(x, dtype=torch.float)\n",
    "            #x=x.clone().detach().requires_grad_(True)\n",
    "            x=torch.tensor(x,dtype=torch.float)\n",
    "            labels=torch.tensor(labels,dtype=torch.float)\n",
    "            x, labels = x.cuda(), labels.cuda()\n",
    "            labels_int=labels=torch.max(labels,1)[1]\n",
    "            #labels_int.cuda()\n",
    "            #print(\"labels:\",labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_predict = model(x)\n",
    "            #print(\"y_predict:\",y_predict)\n",
    "            #loss = loss_func(y_predict.view(-1), labels)\n",
    "            loss = loss_func(y_predict, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss = loss.item()\n",
    "            #loss, predicted = self._train_single_batch(x, labels)\n",
    "\n",
    "            total += loss\n",
    "            \n",
    "            \n",
    "            #predicted = torch.max(y_predict.data,1)\n",
    "            #print(\"predicted:\",predicted)\n",
    "            #predicted = torch.max(y_predict.data,1)[1]\n",
    "            #predicted=predicted.detach().cpu().numpy()\n",
    "            \n",
    "            #labels=torch.max(labels,1)\n",
    "            #print(\"labels:\",labels)\n",
    "            #labels=labels[1]\n",
    "            #y_predict=y_predict.cuda()\n",
    "            #labels=torch.max(labels,1)[1].cuda()\n",
    "            #labels=labels.detach().cpu().numpy()\n",
    "            #correct += (predicted == labels).sum()\n",
    "            #print(\"correct:\",correct)\n",
    "            #correct=correct[0]\n",
    "            #print(\"new_correct:\",float(correct))\n",
    "            #correct=float(correct)   \n",
    "            #if batch_idx % 10 == 0:\n",
    "            #print(\"batch_idx:\",batch_idx)\n",
    "            #print(correct/(BATCH_SIZE*(batch_idx+1)))\n",
    "            batch_train_acc=torchmetrics.functional.accuracy(y_predict,labels_int)\n",
    "            #print('batch_train_acc:',batch_train_acc)\n",
    "        #total_train_accuracy=torchmetrics.functional.compute_details()\n",
    "        #print('total_train_accuracy:',total_train_accuracy)\n",
    "        for i , (inputs , targets) in enumerate(test_loader):   \n",
    "            print(\"test\")\n",
    "            # evaluate the model on the test set   \n",
    "            #print(\\ inputs:\\  inputs)   \n",
    "            #print(\\ targets:\\  targets)   \n",
    "            inputs = Variable(inputs)   \n",
    "            targets = Variable(targets)     \n",
    "            #x = torch.tensor(x  dtype=torch.float)   \n",
    "            #x=x.clone().detach().requires_grad_(True)   \n",
    "            inputs=torch.tensor(inputs ,dtype=torch.float)   \n",
    "            targets=torch.tensor(targets ,dtype=torch.float)   \n",
    "            inputs , targets = inputs.cuda(),  targets.cuda()   \n",
    "            yhat = model(inputs)  \n",
    "            \n",
    "            #yhat = torch.max(yhat.data,1)[1]\n",
    "            #yhat=yhat.detach().cpu().numpy()\n",
    "            #print(\"predicted:\",predicted)\n",
    "            #predicted = torch.max(y_predict.data,1)[1]\n",
    "             #predicted = torch.max(y_predict.data,1)[1]\n",
    "            \n",
    "            \n",
    "            targets=torch.max(targets,1)[1]\n",
    "            #print(\"labels:\",labels)\n",
    "            #labels=labels[1]\n",
    "            #targets=targets.detach().cpu().numpy()\n",
    "            \n",
    "            \n",
    "            \n",
    "            batch_test_acc=torchmetrics.functional.accuracy(yhat,targets)\n",
    "            #print(\"batch_test_acc:\",batch_test_acc)\n",
    "            total_test_acc+=batch_test_acc\n",
    "            #total_test_accuracy=torchmetrics.functional.compute_details()\n",
    "            batch_size=i\n",
    "        print('total_test_accuracy:',total_test_acc/(batch_size+1))\n",
    "        \n",
    "                    \n",
    "                    \n",
    "            \n",
    "            #model.evaluate()\n",
    "            #model.eval()\n",
    "            #train_result = evaluate.metrics(model, train_loader)\n",
    "            #valid_result = evaluate.metrics(model, valid_loader)\n",
    "            #est_result = evaluate.metrics(model, test_loader)\n",
    "            #acturals,predictions,acc_test=evaluate_model(test_loader,model)\n",
    "            #print(\"acc_test:  %d  \" %(acc_test))\n",
    "            #print(\"Train_RMSE: {:.3f}, Valid_RMSE: {:.3f}, Test_RMSE: {:.3f}\".format(\n",
    "            #train_result, valid_result, test_result))\n",
    "            # print('[Training Epoch: {}] Batch: {}, Loss: {}'.format(epoch_id, batch_id, loss))\n",
    "        print(\"Training Epoch: %d, total loss: %f\" % (epoch_id, total))\n",
    "        #print(\"auc:\",roc_auc_score)\n",
    "    #功能：保存训练完的网络的各层参数（即weights和bias)\n",
    "    #path='dataset/xiaoguan/RF/RF_for_train/train_class_9/model/gene_4000_NFM.pkl'\n",
    "        if epoch_id %100==0:\n",
    "            num=num+1\n",
    "            path=os.path.join(model_path,'MLP'+str(num)+'.pkl')\n",
    "            torch.save(model.state_dict(),path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a86edc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FMData\n",
      "FMData\n",
      "MLP: MLP(\n",
      "  (fc1): Linear(in_features=5510, out_features=1000, bias=True)\n",
      "  (bn1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=1000, out_features=100, bias=True)\n",
      "  (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=100, out_features=9, bias=True)\n",
      "  (bn3): BatchNorm1d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/.local/lib/python3.6/site-packages/ipykernel_launcher.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/zhengfang/.local/lib/python3.6/site-packages/ipykernel_launcher.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_train_acc: tensor(0.1875, device='cuda:0')\n",
      "batch_train_acc: tensor(0., device='cuda:0')\n",
      "batch_train_acc: tensor(0.2500, device='cuda:0')\n",
      "batch_train_acc: tensor(0.1250, device='cuda:0')\n",
      "batch_train_acc: tensor(0.3750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.1875, device='cuda:0')\n",
      "batch_train_acc: tensor(0.1875, device='cuda:0')\n",
      "batch_train_acc: tensor(0.1875, device='cuda:0')\n",
      "batch_train_acc: tensor(0.3750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.3125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.3125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.3750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.3750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.5000, device='cuda:0')\n",
      "batch_train_acc: tensor(0.3750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.2500, device='cuda:0')\n",
      "batch_train_acc: tensor(0.3750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.3750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.2500, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6250, device='cuda:0')\n",
      "test\n",
      "batch_test_acc: tensor(0.4375, device='cuda:0')\n",
      "total_test_accuracy: tensor(0.4375, device='cuda:0')\n",
      "Training Epoch: 0, total loss: 42.405449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/.local/lib/python3.6/site-packages/ipykernel_launcher.py:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/zhengfang/.local/lib/python3.6/site-packages/ipykernel_launcher.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_train_acc: tensor(0.5000, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6250, device='cuda:0')\n",
      "batch_train_acc: tensor(0.5000, device='cuda:0')\n",
      "batch_train_acc: tensor(0.5625, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6250, device='cuda:0')\n",
      "batch_train_acc: tensor(0.3750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.4375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.3125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.3125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.3750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.4375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.4375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.2500, device='cuda:0')\n",
      "batch_train_acc: tensor(0.4375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.3750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.3125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.5000, device='cuda:0')\n",
      "batch_train_acc: tensor(0.7500, device='cuda:0')\n",
      "batch_train_acc: tensor(0.3750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.4375, device='cuda:0')\n",
      "test\n",
      "batch_test_acc: tensor(0.5625, device='cuda:0')\n",
      "total_test_accuracy: tensor(0.5625, device='cuda:0')\n",
      "Training Epoch: 1, total loss: 40.899640\n",
      "batch_train_acc: tensor(0.7500, device='cuda:0')\n",
      "batch_train_acc: tensor(0.4375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.5625, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6250, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6250, device='cuda:0')\n",
      "batch_train_acc: tensor(0.5625, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6250, device='cuda:0')\n",
      "batch_train_acc: tensor(0.5625, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6875, device='cuda:0')\n",
      "batch_train_acc: tensor(0.4375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.5000, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.5000, device='cuda:0')\n",
      "batch_train_acc: tensor(0.5625, device='cuda:0')\n",
      "batch_train_acc: tensor(0.2500, device='cuda:0')\n",
      "batch_train_acc: tensor(0.3750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.5625, device='cuda:0')\n",
      "batch_train_acc: tensor(0.5625, device='cuda:0')\n",
      "batch_train_acc: tensor(0.5000, device='cuda:0')\n",
      "batch_train_acc: tensor(0.5000, device='cuda:0')\n",
      "test\n",
      "batch_test_acc: tensor(0.5625, device='cuda:0')\n",
      "total_test_accuracy: tensor(0.5625, device='cuda:0')\n",
      "Training Epoch: 2, total loss: 39.771062\n",
      "batch_train_acc: tensor(0.7500, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6250, device='cuda:0')\n",
      "batch_train_acc: tensor(0.5000, device='cuda:0')\n",
      "batch_train_acc: tensor(0.5625, device='cuda:0')\n",
      "batch_train_acc: tensor(0.7500, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6875, device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(0.6875, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6875, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6875, device='cuda:0')\n",
      "batch_train_acc: tensor(0.5625, device='cuda:0')\n",
      "batch_train_acc: tensor(0.5000, device='cuda:0')\n",
      "batch_train_acc: tensor(0.4375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6875, device='cuda:0')\n",
      "batch_train_acc: tensor(0.7500, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6875, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6250, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6875, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "test\n",
      "batch_test_acc: tensor(0.6250, device='cuda:0')\n",
      "total_test_accuracy: tensor(0.6250, device='cuda:0')\n",
      "Training Epoch: 3, total loss: 38.993714\n",
      "batch_train_acc: tensor(0.3750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6250, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6875, device='cuda:0')\n",
      "batch_train_acc: tensor(0.7500, device='cuda:0')\n",
      "batch_train_acc: tensor(0.7500, device='cuda:0')\n",
      "batch_train_acc: tensor(0.7500, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6250, device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(0.5625, device='cuda:0')\n",
      "batch_train_acc: tensor(0.5625, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6875, device='cuda:0')\n",
      "batch_train_acc: tensor(0.5625, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.5000, device='cuda:0')\n",
      "batch_train_acc: tensor(0.7500, device='cuda:0')\n",
      "batch_train_acc: tensor(0.7500, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6250, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6250, device='cuda:0')\n",
      "test\n",
      "batch_test_acc: tensor(0.6875, device='cuda:0')\n",
      "total_test_accuracy: tensor(0.6875, device='cuda:0')\n",
      "Training Epoch: 4, total loss: 38.202752\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6875, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6875, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6875, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6875, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6250, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6250, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6875, device='cuda:0')\n",
      "batch_train_acc: tensor(0.5625, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6250, device='cuda:0')\n",
      "test\n",
      "batch_test_acc: tensor(0.6875, device='cuda:0')\n",
      "total_test_accuracy: tensor(0.6875, device='cuda:0')\n",
      "Training Epoch: 5, total loss: 37.471567\n",
      "batch_train_acc: tensor(0.6250, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6875, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.7500, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6875, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6875, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6875, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6875, device='cuda:0')\n",
      "batch_train_acc: tensor(0.4375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6875, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "test\n",
      "batch_test_acc: tensor(0.8750, device='cuda:0')\n",
      "total_test_accuracy: tensor(0.8750, device='cuda:0')\n",
      "Training Epoch: 6, total loss: 36.952368\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.7500, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6250, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.7500, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.7500, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6875, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "test\n",
      "batch_test_acc: tensor(0.5000, device='cuda:0')\n",
      "total_test_accuracy: tensor(0.5000, device='cuda:0')\n",
      "Training Epoch: 7, total loss: 36.280457\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.7500, device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(0.6875, device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(0.7500, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6875, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.7500, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6875, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "batch_test_acc: tensor(0.7500, device='cuda:0')\n",
      "total_test_accuracy: tensor(0.7500, device='cuda:0')\n",
      "Training Epoch: 8, total loss: 36.142603\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6875, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.7500, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6875, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "test\n",
      "batch_test_acc: tensor(0.9375, device='cuda:0')\n",
      "total_test_accuracy: tensor(0.9375, device='cuda:0')\n",
      "Training Epoch: 9, total loss: 35.780073\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6875, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.7500, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6875, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(0.7500, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6875, device='cuda:0')\n",
      "test\n",
      "batch_test_acc: tensor(0.8125, device='cuda:0')\n",
      "total_test_accuracy: tensor(0.8125, device='cuda:0')\n",
      "Training Epoch: 10, total loss: 35.759764\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.5625, device='cuda:0')\n",
      "batch_train_acc: tensor(0.7500, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6875, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.7500, device='cuda:0')\n",
      "test\n",
      "batch_test_acc: tensor(0.7500, device='cuda:0')\n",
      "total_test_accuracy: tensor(0.7500, device='cuda:0')\n",
      "Training Epoch: 11, total loss: 35.663695\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(0.6875, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "test\n",
      "batch_test_acc: tensor(0.9375, device='cuda:0')\n",
      "total_test_accuracy: tensor(0.9375, device='cuda:0')\n",
      "Training Epoch: 12, total loss: 35.006328\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.7500, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6875, device='cuda:0')\n",
      "test\n",
      "batch_test_acc: tensor(0.8125, device='cuda:0')\n",
      "total_test_accuracy: tensor(0.8125, device='cuda:0')\n",
      "Training Epoch: 13, total loss: 34.660125\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(0.7500, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.7500, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.7500, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.7500, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "test\n",
      "batch_test_acc: tensor(0.7500, device='cuda:0')\n",
      "total_test_accuracy: tensor(0.7500, device='cuda:0')\n",
      "Training Epoch: 14, total loss: 34.637880\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.7500, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "test\n",
      "batch_test_acc: tensor(0.8125, device='cuda:0')\n",
      "total_test_accuracy: tensor(0.8125, device='cuda:0')\n",
      "Training Epoch: 15, total loss: 34.476635\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.7500, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_train_acc: tensor(0.6875, device='cuda:0')\n",
      "test\n",
      "batch_test_acc: tensor(1., device='cuda:0')\n",
      "total_test_accuracy: tensor(1., device='cuda:0')\n",
      "Training Epoch: 16, total loss: 34.110890\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.7500, device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.7500, device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "test\n",
      "batch_test_acc: tensor(0.9375, device='cuda:0')\n",
      "total_test_accuracy: tensor(0.9375, device='cuda:0')\n",
      "Training Epoch: 17, total loss: 33.843774\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.6875, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "test\n",
      "batch_test_acc: tensor(0.8750, device='cuda:0')\n",
      "total_test_accuracy: tensor(0.8750, device='cuda:0')\n",
      "Training Epoch: 18, total loss: 33.746646\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.7500, device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.7500, device='cuda:0')\n",
      "test\n",
      "batch_test_acc: tensor(0.9375, device='cuda:0')\n",
      "total_test_accuracy: tensor(0.9375, device='cuda:0')\n",
      "Training Epoch: 19, total loss: 33.636451\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(0.7500, device='cuda:0')\n",
      "batch_train_acc: tensor(0.7500, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(1., device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.9375, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8750, device='cuda:0')\n",
      "batch_train_acc: tensor(0.8125, device='cuda:0')\n",
      "test\n",
      "batch_test_acc: tensor(0.9375, device='cuda:0')\n",
      "total_test_accuracy: tensor(0.9375, device='cuda:0')\n",
      "Training Epoch: 20, total loss: 34.141880\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-54efbe11a155>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MLP:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnfm_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'dataset/xiaoqiu/model/MLP/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-ab5f45d110aa>\u001b[0m in \u001b[0;36mtrain_data\u001b[0;34m(model, train_loader, test_loader, batch_size, model_path)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mtotal_test_acc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_worker_number_rationality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/new_pytorch/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/new_pytorch/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/new_pytorch/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_fork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mSpawnProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/new_pytorch/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush_std_streams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/new_pytorch/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mparent_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_dataset,train_loader=prepare_dataset(nfm_config['train_data'],nfm_config['train_label'],nfm_config['batch_size'],nfm_config['n_class'])\n",
    "test_dataset,test_loader=prepare_dataset(nfm_config['test_data'],nfm_config['test_label'],nfm_config['batch_size'],nfm_config['n_class'])\n",
    "from MLP import MLP\n",
    "#from new_nfm_network import NFM\n",
    "model=MLP(5510,1000,100,9)\n",
    "#model=NFM(nfm_config)\n",
    "model.cuda()\n",
    "print(\"MLP:\",model)\n",
    "train_data(model,train_loader,test_loader,nfm_config['batch_size'],'dataset/xiaoqiu/model/MLP/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e9289bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from new_nfm_network import NFM\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.backends.cudnn as cudnn\n",
    "#3from tensorboardX import SummaryWriter\n",
    "\n",
    "#import network\n",
    "import config\n",
    "import evaluate\n",
    "import data_utils\n",
    "import Trainer\n",
    "\n",
    "\n",
    "def   train_data(model,data_loader,batch_size,model_path):\n",
    "    \n",
    "    BATCH_SIZE=batch_size\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=nfm_config['lr'], weight_decay=nfm_config['l2_regularization'])\n",
    "    total = 0\n",
    "    #loss_func = torch.nn.BCELoss()\n",
    "    loss_func=torch.nn.CrossEntropyLoss()\n",
    "    #loss_func=nn.MultiLabelSoftMarginLoss()\n",
    "    #loss_func=torch.nn.LogSoftmax()\n",
    "    \n",
    "    #model=nn.Softmax(nn.Linear(10149,16)).to(device)\n",
    "    # 从DataLoader中获取小批量的id以及数据\n",
    "    for epoch_id in range(1000):\n",
    "        correct=0\n",
    "        total=0\n",
    "        for batch_idx, (x, labels) in enumerate(data_loader):\n",
    "            x = Variable(x)\n",
    "            labels = Variable(labels)\n",
    "            \n",
    "            \n",
    "            #x = torch.tensor(x, dtype=torch.float)\n",
    "            #x=x.clone().detach().requires_grad_(True)\n",
    "            x=torch.tensor(x,dtype=torch.float)\n",
    "            labels=torch.tensor(labels,dtype=torch.float)\n",
    "            x, labels = x.cuda(), labels.cuda()\n",
    "            \n",
    "            #print(\"labels:\",labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_predict = model(x)\n",
    "            #print(\"y_predict:\",y_predict)\n",
    "            #loss = loss_func(y_predict.view(-1), labels)\n",
    "            loss = loss_func(y_predict, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss = loss.item()\n",
    "            #loss, predicted = self._train_single_batch(x, labels)\n",
    "\n",
    "            total += loss\n",
    "            \n",
    "            \n",
    "            \n",
    "            predicted = torch.max(y_predict.data,1)\n",
    "            #print(\"predicted:\",predicted)\n",
    "            predicted = torch.max(y_predict.data,1)[1]\n",
    "            \n",
    "            \n",
    "            labels=torch.max(labels,1)\n",
    "            #print(\"labels:\",labels)\n",
    "            labels=labels[1]\n",
    "            \n",
    "            correct += (predicted == labels).sum()\n",
    "            #print(\"correct:\",correct)\n",
    "            #correct=correct[0]\n",
    "            #print(\"new_correct:\",float(correct))\n",
    "            correct=float(correct)   \n",
    "            #if batch_idx % 10 == 0:\n",
    "            print(\"batch_idx:\",batch_idx)\n",
    "            print(correct/(BATCH_SIZE*(batch_idx+1)))\n",
    "            \n",
    "            \"\"\"\n",
    "            #y_predict.detach().numpy()\n",
    "            pred = y_predict\n",
    "            print(\"pred:\",pred.shape)\n",
    "            y=labels.clone().detach().requires_grad_(True)\n",
    "            print(\"y:\",y.shape)\n",
    "            #y=labels.data.cpu().numpy()\n",
    "            #y = labels.detach().numpy()\n",
    "            roc_auc_score(y, pred)\n",
    "            \"\"\"\n",
    "           \n",
    "            # print('[Training Epoch: {}] Batch: {}, Loss: {}'.format(epoch_id, batch_id, loss))\n",
    "        print(\"Training Epoch: %d, total loss: %f\" % (epoch_id, total))\n",
    "        #print(\"auc:\",roc_auc_score)\n",
    "    #功能：保存训练完的网络的各层参数（即weights和bias)\n",
    "    #path='dataset/xiaoguan/RF/RF_for_train/train_class_9/model/gene_4000_NFM.pkl'\n",
    "    \n",
    "    torch.save(model.state_dict(),model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7d810a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff40315a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP: MLP(\n",
      "  (fc1): Linear(in_features=4225, out_features=1000, bias=True)\n",
      "  (bn1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=1000, out_features=100, bias=True)\n",
      "  (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=100, out_features=9, bias=True)\n",
      "  (bn3): BatchNorm1d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8451e728d86b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MLP:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnfm_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'dataset/xiaoqiu/model/gene_5000_MLP.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "from MLP import MLP\n",
    "model=MLP(4225,1000,100,9)\n",
    "model.cuda()\n",
    "print(\"MLP:\",model)\n",
    "train_data(model,train_loader,nfm_config['batch_size'],'dataset/xiaoqiu/model/gene_5000_MLP.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564afda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(nfm.state_dict(),'dataset/xiaoqiu/model/gene_5000_MLP.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e431db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dfec61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试\n",
    "##测试集\n",
    "from new_nfm_network import NFM\n",
    "#加载模型\n",
    "path='dataset/xiaoguan/RF/RF_for_train/train_class_9/model/gene_4000_MLP.pkl'\n",
    "#nfm = NFM(nfm_config).cuda()\n",
    "net=model.cuda()\n",
    "#net=nfm\n",
    "print(net)\n",
    "#net = nn.DataParallel(net)\n",
    "#net = net.to(device)\n",
    "net.load_state_dict(torch.load(path),strict=False)\n",
    "net.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=nfm_config['lr'], weight_decay=nfm_config['l2_regularization'])\n",
    "total = 0\n",
    "#loss_func = torch.nn.BCELoss()\n",
    "loss_func=torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e312c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据集准备测试\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.backends.cudnn as cudnn\n",
    "#3from tensorboardX import SummaryWriter\n",
    "\n",
    "#import network\n",
    "import config\n",
    "import evaluate\n",
    "import data_utils\n",
    "import Trainer\n",
    "from dataset_process import FMData\n",
    "\n",
    "'''  \n",
    "test_dataset = FMData(nfm_config['test_data'],nfm_config['test_label'],nfm_config['n_class'])\n",
    "test_loader = data.DataLoader(test_dataset, drop_last=True,batch_size=100,shuffle=True, num_workers=4)\n",
    "\n",
    "'''\n",
    "test_dataset,test_loader=prepare_dataset(nfm_config['test_data'],nfm_config['test_label'],nfm_config['batch_size'],nfm_config['n_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ed3d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#版权声明：本文为CSDN博主「山阴少年」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。  \n",
    "#原文链接：https://blog.csdn.net/jclian91/article/details/121708431#   \n",
    "from torch.autograd import Variable   \n",
    "from torch.utils.data import DataLoader   \n",
    "from sklearn.metrics import roc_auc_score   \n",
    "from sklearn.metrics import accuracy_score   \n",
    "        \n",
    "        \n",
    "def evaluate_model(test_dl , model):   \n",
    "    predictions,  actuals = [] , []   \n",
    "    for i , (inputs , targets) in enumerate(test_dl):   \n",
    "        # evaluate the model on the test set   \n",
    "        #print(\\ inputs:\\  inputs)   \n",
    "        #print(\\ targets:\\  targets)   \n",
    "        inputs = Variable(inputs)   \n",
    "        targets = Variable(targets)   \n",
    "                    \n",
    "                    \n",
    "        #x = torch.tensor(x  dtype=torch.float)   \n",
    "        #x=x.clone().detach().requires_grad_(True)   \n",
    "        inputs=torch.tensor(inputs ,dtype=torch.float)   \n",
    "        targets=torch.tensor(targets ,dtype=torch.float)   \n",
    "        inputs , targets = inputs.cuda(),  targets.cuda()   \n",
    "        yhat = model(inputs)   \n",
    "        # retrieve numpy array   \n",
    "        #yhat = yhat.detach().numpy()   \n",
    "        yhat = yhat.detach().cpu().numpy()#转换到cpu   \n",
    "        # yhat=yhat.argmax(axis=1)   \n",
    "        #print(' yhat:',  yhat)   \n",
    "        #print('yhat.shape:' ,yhat.shape)   \n",
    "        actual = targets.detach().cpu().numpy()   \n",
    "        actual=actual.round()   \n",
    "        #print('actual:',  actual)   \n",
    "        #print('actual.shape:', actual.shape)   \n",
    "        #actual = actual.reshape(-1  1)   \n",
    "        # round to class values   \n",
    "        yhat = yhat.round()   \n",
    "        # store   \n",
    "        predictions.append(yhat)   \n",
    "        actuals.append(actual)   \n",
    "    #print('prediction:',  predictions)   \n",
    "    #print('actuals:',  actuals)   \n",
    "    predictions , actuals = np.vstack(predictions) , np.vstack(actuals)   \n",
    "    #print('prediction:',  predictions)   \n",
    "    #print('actuals:',  actuals)   \n",
    "    # calculate accuracy   \n",
    "    acc_test = accuracy_score(actuals , predictions)   \n",
    "    return  actuals , predictions ,acc_test \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a77025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals,predictions,acc_test=evaluate_model(test_loader,net)\n",
    "print(\"acc_test\",acc_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
