{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0356104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import Trainer\n",
    "from network import NFM\n",
    "import torch.utils.data as Data\n",
    "from Utils.criteo_loader import getTestData, getTrainData\n",
    "\n",
    "nfm_config = \\\n",
    "{\n",
    "    'n_class':9,\n",
    "    'linear_hidden1':1000,\n",
    "    'linear_hidden':100,#线性模型输出层（隐层个数）\n",
    "    'embed_input_dim':1001,#embed输入维度\n",
    "    'embed_dim': 100, # 用于控制稀疏特征经过Embedding层后的稠密特征大小，embed输出维度\n",
    "    #'dnn_hidden_units': [100,11],#MLP隐层和输出层\n",
    "    \n",
    "    'dnn_hidden_units':[100,9],#MLP隐层\n",
    "    'num_sparse_features_cols':4225,#the number of the gene columns\n",
    "    'num_dense_features': 0,#dense features number\n",
    "    'bi_dropout': 0.5,#Bi-Interaction 的dropout\n",
    "    'num_epoch': 500,#训练epoch次数\n",
    "    'batch_size': 24,#batch_size\n",
    "    'lr': 1e-3,\n",
    "    'l2_regularization': 1e-4,\n",
    "    'device_id': 0,\n",
    "    'use_cuda': False,\n",
    "    'epoch':1000,\n",
    "    \n",
    "    #'train_file': '../Data/criteo/processed_data/train_set.csv',\n",
    "    #'fea_file': '../Data/criteo/processed_data/fea_col.npy',\n",
    "    #'validate_file': '../Data/criteo/processed_data/val_set.csv',\n",
    "    #'test_file': '../Data/criteo/processed_data/test_set.csv',\n",
    "    #'model_name': '../TrainedModels/NFM.model'\n",
    "    #'train_file':'data/xiaoqiu_gene_5000/train/final_5000_encode_100x.csv',\n",
    "    'train_data':'dataset/xiaoguan/RF/RF_for_train/train_class_9/train/train_encode_data.csv',\n",
    "    'train_label':'dataset/xiaoguan/RF/RF_for_train/train_class_9/train/train_label.csv',\n",
    "    'test_data':'dataset/xiaoguan/RF/RF_for_train/train_class_9/test/test_encode_data.csv',\n",
    "    'test_label':'dataset/xiaoguan/RF/RF_for_train/train_class_9/test/test_label.csv',\n",
    "    #'title':'dataset/xiaoguan/RF/RF_for_train/train_class_9/test/test_data.csv',\n",
    "    \n",
    "    #'all':''\n",
    "    #'title':'data/xiaoqiu_gene_5000/train/gene_5000_gene_name.csv',\n",
    "    #'all':'data/xiaoqiu_gene_5000/train/gene_5000_label_name.csv'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e0a4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#准备训练集\n",
    "\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.backends.cudnn as cudnn\n",
    "#3from tensorboardX import SummaryWriter\n",
    "\n",
    "#import network\n",
    "import config\n",
    "import evaluate\n",
    "import data_utils\n",
    "import Trainer\n",
    "#from utils import \n",
    "#准备训练集\n",
    "#from new_dataset_processed import FMData\n",
    "from dataset_process import FMData\n",
    "def prepare_dataset(m_data,m_label,batch_size,n_class):\n",
    "    m_dataset=FMData(m_data,m_label,n_class)\n",
    "    m_dataloader=data.DataLoader(m_dataset, drop_last=True,batch_size=batch_size,shuffle=True,num_workers=4)\n",
    "    \n",
    "    return m_dataset,m_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e9e122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from new_nfm_network import NFM\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.backends.cudnn as cudnn\n",
    "#3from tensorboardX import SummaryWriter\n",
    "\n",
    "#import network\n",
    "import config\n",
    "import evaluate\n",
    "import data_utils\n",
    "import Trainer\n",
    "\n",
    "\n",
    "def   train_data(model,data_loader,batch_size,model_path):\n",
    "    \n",
    "    BATCH_SIZE=batch_size\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=nfm_config['lr'], weight_decay=nfm_config['l2_regularization'])\n",
    "    total = 0\n",
    "    #loss_func = torch.nn.BCELoss()\n",
    "    loss_func=torch.nn.CrossEntropyLoss()\n",
    "    #loss_func=nn.MultiLabelSoftMarginLoss()\n",
    "    #loss_func=torch.nn.LogSoftmax()\n",
    "    \n",
    "    #model=nn.Softmax(nn.Linear(10149,16)).to(device)\n",
    "    # 从DataLoader中获取小批量的id以及数据\n",
    "    for epoch_id in range(1000):\n",
    "        correct=0\n",
    "        total=0\n",
    "        for batch_idx, (x, labels) in enumerate(data_loader):\n",
    "            x = Variable(x)\n",
    "            labels = Variable(labels)\n",
    "            \n",
    "            \n",
    "            #x = torch.tensor(x, dtype=torch.float)\n",
    "            #x=x.clone().detach().requires_grad_(True)\n",
    "            x=torch.tensor(x,dtype=torch.float)\n",
    "            labels=torch.tensor(labels,dtype=torch.float)\n",
    "            x, labels = x.cuda(), labels.cuda()\n",
    "            \n",
    "            #print(\"labels:\",labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_predict = model(x)\n",
    "            #print(\"y_predict:\",y_predict)\n",
    "            #loss = loss_func(y_predict.view(-1), labels)\n",
    "            loss = loss_func(y_predict, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss = loss.item()\n",
    "            #loss, predicted = self._train_single_batch(x, labels)\n",
    "\n",
    "            total += loss\n",
    "            \n",
    "            \n",
    "            \n",
    "            predicted = torch.max(y_predict.data,1)\n",
    "            #print(\"predicted:\",predicted)\n",
    "            predicted = torch.max(y_predict.data,1)[1]\n",
    "            \n",
    "            \n",
    "            labels=torch.max(labels,1)\n",
    "            #print(\"labels:\",labels)\n",
    "            labels=labels[1]\n",
    "            \n",
    "            correct += (predicted == labels).sum()\n",
    "            #print(\"correct:\",correct)\n",
    "            #correct=correct[0]\n",
    "            #print(\"new_correct:\",float(correct))\n",
    "            correct=float(correct)   \n",
    "            #if batch_idx % 10 == 0:\n",
    "            print(\"batch_idx:\",batch_idx)\n",
    "            print(correct/(BATCH_SIZE*(batch_idx+1)))\n",
    "            \n",
    "            \"\"\"\n",
    "            #y_predict.detach().numpy()\n",
    "            pred = y_predict\n",
    "            print(\"pred:\",pred.shape)\n",
    "            y=labels.clone().detach().requires_grad_(True)\n",
    "            print(\"y:\",y.shape)\n",
    "            #y=labels.data.cpu().numpy()\n",
    "            #y = labels.detach().numpy()\n",
    "            roc_auc_score(y, pred)\n",
    "            \"\"\"\n",
    "           \n",
    "            # print('[Training Epoch: {}] Batch: {}, Loss: {}'.format(epoch_id, batch_id, loss))\n",
    "        print(\"Training Epoch: %d, total loss: %f\" % (epoch_id, total))\n",
    "        #print(\"auc:\",roc_auc_score)\n",
    "    #功能：保存训练完的网络的各层参数（即weights和bias)\n",
    "    #path='dataset/xiaoguan/RF/RF_for_train/train_class_9/model/gene_4000_NFM.pkl'\n",
    "    \n",
    "    torch.save(nfm.state_dict(),model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f71732",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset,train_loader=prepare_dataset(nfm_config['train_data'],nfm_config['train_label'],nfm_config['batch_size'],nfm_config['n_class'])\n",
    "nfm = NFM(nfm_config).cuda()#加了device防止出现GPU CPU两种设备的错误提示\n",
    "print(\"nfm:\",nfm)\n",
    "train_data(nfm,train_loader,nfm_config['batch_size'],'dataset/xiaoqiu/model/model/gene_5000_NFM.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eaf692",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(nfm.state_dict(),'dataset/xiaoguan/model/gene_5000_NFM.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bde3b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "###测试\n",
    "##测试集\n",
    "from new_nfm_network import NFM\n",
    "#加载模型\n",
    "path='dataset/xiaoguan/model/gene_5000_NFM.pkl'\n",
    "nfm = NFM(nfm_config).cuda()\n",
    "#net=model.cuda()\n",
    "net=nfm\n",
    "print(net)\n",
    "#net = nn.DataParallel(net)\n",
    "#net = net.to(device)\n",
    "net.load_state_dict(torch.load(path),strict=False)\n",
    "net.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=nfm_config['lr'], weight_decay=nfm_config['l2_regularization'])\n",
    "total = 0\n",
    "#loss_func = torch.nn.BCELoss()\n",
    "loss_func=torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff5fde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据集准备测试\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.backends.cudnn as cudnn\n",
    "#3from tensorboardX import SummaryWriter\n",
    "\n",
    "#import network\n",
    "import config\n",
    "import evaluate\n",
    "import data_utils\n",
    "import Trainer\n",
    "from dataset_process import FMData\n",
    "\n",
    "'''  \n",
    "test_dataset = FMData(nfm_config['test_data'],nfm_config['test_label'],nfm_config['n_class'])\n",
    "test_loader = data.DataLoader(test_dataset, drop_last=True,batch_size=100,shuffle=True, num_workers=4)\n",
    "\n",
    "'''\n",
    "test_dataset,test_loader=prepare_dataset(nfm_config['test_data'],nfm_config['test_label'],nfm_config['batch_size'],nfm_config['n_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb5d6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#版权声明：本文为CSDN博主「山阴少年」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。  \n",
    "#原文链接：https://blog.csdn.net/jclian91/article/details/121708431#   \n",
    "from torch.autograd import Variable   \n",
    "from torch.utils.data import DataLoader   \n",
    "from sklearn.metrics import roc_auc_score   \n",
    "from sklearn.metrics import accuracy_score   \n",
    "        \n",
    "        \n",
    "def evaluate_model(test_dl , model):   \n",
    "    predictions,  actuals = [] , []   \n",
    "    for i , (inputs , targets) in enumerate(test_dl):   \n",
    "        # evaluate the model on the test set   \n",
    "        #print(\\ inputs:\\  inputs)   \n",
    "        #print(\\ targets:\\  targets)   \n",
    "        inputs = Variable(inputs)   \n",
    "        targets = Variable(targets)   \n",
    "                    \n",
    "                    \n",
    "        #x = torch.tensor(x  dtype=torch.float)   \n",
    "        #x=x.clone().detach().requires_grad_(True)   \n",
    "        inputs=torch.tensor(inputs ,dtype=torch.float)   \n",
    "        targets=torch.tensor(targets ,dtype=torch.float)   \n",
    "        inputs , targets = inputs.cuda(),  targets.cuda()   \n",
    "        yhat = model(inputs)   \n",
    "        # retrieve numpy array   \n",
    "        #yhat = yhat.detach().numpy()   \n",
    "        yhat = yhat.detach().cpu().numpy()#转换到cpu   \n",
    "        # yhat=yhat.argmax(axis=1)   \n",
    "        #print(' yhat:',  yhat)   \n",
    "        #print('yhat.shape:' ,yhat.shape)   \n",
    "        actual = targets.detach().cpu().numpy()   \n",
    "        actual=actual.round()   \n",
    "        #print('actual:',  actual)   \n",
    "        #print('actual.shape:', actual.shape)   \n",
    "        #actual = actual.reshape(-1  1)   \n",
    "        # round to class values   \n",
    "        yhat = yhat.round()   \n",
    "        # store   \n",
    "        predictions.append(yhat)   \n",
    "        actuals.append(actual)   \n",
    "    #print('prediction:',  predictions)   \n",
    "    #print('actuals:',  actuals)   \n",
    "    predictions , actuals = np.vstack(predictions) , np.vstack(actuals)   \n",
    "    #print('prediction:',  predictions)   \n",
    "    #print('actuals:',  actuals)   \n",
    "    # calculate accuracy   \n",
    "    acc_test = accuracy_score(actuals , predictions)   \n",
    "    return  actuals , predictions ,acc_test \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b9b105",
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals,predictions,acc_test=evaluate_model(test_loader,net)\n",
    "print(\"acc_test\",acc_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
