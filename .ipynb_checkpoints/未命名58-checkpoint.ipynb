{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6859494c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (bn0): BatchNorm1d(3300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=3300, out_features=2000, bias=True)\n",
      "  (bn1): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=2000, out_features=100, bias=True)\n",
      "  (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=100, out_features=9, bias=True)\n",
      "  (bn3): BatchNorm1d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "MLP1(\n",
      "  (bn0): BatchNorm1d(237, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=237, out_features=2000, bias=True)\n",
      "  (bn1): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=2000, out_features=100, bias=True)\n",
      "  (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=100, out_features=9, bias=True)\n",
      "  (bn3): BatchNorm1d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "MLP2(\n",
      "  (bn0): BatchNorm1d(126, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=126, out_features=2000, bias=True)\n",
      "  (bn1): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=2000, out_features=100, bias=True)\n",
      "  (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=100, out_features=9, bias=True)\n",
      "  (bn3): BatchNorm1d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "MLP3(\n",
      "  (bn0): BatchNorm1d(171, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=171, out_features=2000, bias=True)\n",
      "  (bn1): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=2000, out_features=100, bias=True)\n",
      "  (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=100, out_features=9, bias=True)\n",
      "  (bn3): BatchNorm1d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import Trainer\n",
    "from network import NFM\n",
    "import torch.utils.data as Data\n",
    "from Utils.criteo_loader import getTestData, getTrainData\n",
    "\n",
    "nfm_config = \\\n",
    "{\n",
    "    'n_class':9,\n",
    "    'linear_hidden1':2000,\n",
    "    #'linear_hidden':100,#线性模型输出层（隐层个数）\n",
    "    #'embed_input_dim':1001,#embed输入维度\n",
    "    #'embed_dim': 100, # 用于控制稀疏特征经过Embedding层后的稠密特征大小，embed输出维度\n",
    "    #'dnn_hidden_units': [100,11],#MLP隐层和输出层\n",
    "    \n",
    "    'dnn_hidden_units':[100,9],#MLP隐层\n",
    "    'num_sparse_features_cols':10477,#the number of the gene columns\n",
    "    'num_dense_features': 0,#dense features number\n",
    "    'bi_dropout': 0.5,#Bi-Interaction 的dropout\n",
    "    'num_epoch': 500,#训练epoch次数\n",
    "    'batch_size': 16,#batch_size\n",
    "    'lr': 1e-3,\n",
    "    'l2_regularization': 1e-4,\n",
    "    'device_id': 0,\n",
    "    'use_cuda': False,\n",
    "    'epoch':1000,\n",
    "    \n",
    "    #'train_file': '../Data/criteo/processed_data/train_set.csv',\n",
    "    #'fea_file': '../Data/criteo/processed_data/fea_col.npy',\n",
    "    #'validate_file': '../Data/criteo/processed_data/val_set.csv',\n",
    "    #'test_file': '../Data/criteo/processed_data/test_set.csv',\n",
    "    #'model_name': '../TrainedModels/NFM.model'\n",
    "    #'train_file':'data/xiaoqiu_gene_5000/train/final_5000_encode_100x.csv',\n",
    "    #'train_data':'dataset/qiuguan/encode/encode_1000/train/train_encode_data_1000_new.csv',\n",
    "    #'train_label':'dataset/qiuguan/non_code/train/train_label.csv',\n",
    "    #'guan_test_data':'dataset/qiuguan/non_code/guan_test/guan_test_data.csv',\n",
    "    #'guan_test_label':'dataset/qiuguan/non_code/guan_test/guan_test_label.csv',\n",
    "    #'test_data':'dataset/qiuguan/encode/encode_1000/test/test_encode_data_1000_new.csv',\n",
    "    #'test_label':'dataset/qiuguan/non_code/test/test_labels.csv',\n",
    "    #'title':'dataset/xiaoguan/RF/RF_for_train/train_class_9/test/test_data.csv',\n",
    "    \n",
    "    #'all':''\n",
    "    #'title':'data/xiaoqiu_gene_5000/train/gene_5000_gene_name.csv',\n",
    "    #'all':'data/xiaoqiu_gene_5000/train/gene_5000_label_name.csv'\n",
    "}\n",
    "\n",
    "#model definition\n",
    "import torch.nn as nn\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bn0=nn.BatchNorm1d(3300)\n",
    "        self.fc1 = nn.Linear(3300, 2000)\n",
    "        self.bn1= nn.BatchNorm1d(2000)\n",
    "        self.fc2 = nn.Linear(2000, 100)\n",
    "        self.bn2=nn.BatchNorm1d(100)\n",
    "        self.fc3=nn.Linear(100,9)\n",
    "        self.bn3=nn.BatchNorm1d(9)\n",
    "        \n",
    "        self.drop=nn.Dropout(0.5)\n",
    "    def forward(self, x):\n",
    "        x=self.bn0(x)\n",
    "        x = F.relu(self.drop(self.bn1(self.fc1(x))))\n",
    "        x = F.relu(self.drop(self.bn2(self.fc2(x))))\n",
    "        return F.softmax(self.bn3(self.fc3(x)), dim=1)\n",
    "model = MLP().cuda()\n",
    "print(model)\n",
    "\n",
    "class MLP1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bn0=nn.BatchNorm1d(237)\n",
    "        self.fc1 = nn.Linear(237, 2000)\n",
    "        self.bn1= nn.BatchNorm1d(2000)\n",
    "        self.fc2 = nn.Linear(2000, 100)\n",
    "        self.bn2=nn.BatchNorm1d(100)\n",
    "        self.fc3=nn.Linear(100,9)\n",
    "        self.bn3=nn.BatchNorm1d(9)\n",
    "        \n",
    "        self.drop=nn.Dropout(0.5)\n",
    "    def forward(self, x):\n",
    "        x=self.bn0(x)\n",
    "        x = F.relu(self.drop(self.bn1(self.fc1(x))))\n",
    "        x = F.relu(self.drop(self.bn2(self.fc2(x))))\n",
    "        return F.softmax(self.bn3(self.fc3(x)), dim=1)\n",
    "model1 = MLP1().cuda()\n",
    "print(model1)\n",
    "class MLP2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bn0=nn.BatchNorm1d(126)\n",
    "        self.fc1 = nn.Linear(126, 2000)\n",
    "        self.bn1= nn.BatchNorm1d(2000)\n",
    "        self.fc2 = nn.Linear(2000, 100)\n",
    "        self.bn2=nn.BatchNorm1d(100)\n",
    "        self.fc3=nn.Linear(100,9)\n",
    "        self.bn3=nn.BatchNorm1d(9)\n",
    "        \n",
    "        self.drop=nn.Dropout(0.5)\n",
    "    def forward(self, x):\n",
    "        x=self.bn0(x)\n",
    "        x = F.relu(self.drop(self.bn1(self.fc1(x))))\n",
    "        x = F.relu(self.drop(self.bn2(self.fc2(x))))\n",
    "        return F.softmax(self.bn3(self.fc3(x)), dim=1)\n",
    "model2 = MLP2().cuda()\n",
    "print(model2)\n",
    "\n",
    "\n",
    "class MLP3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bn0=nn.BatchNorm1d(171)\n",
    "        self.fc1 = nn.Linear(171, 2000)\n",
    "        self.bn1= nn.BatchNorm1d(2000)\n",
    "        self.fc2 = nn.Linear(2000, 100)\n",
    "        self.bn2=nn.BatchNorm1d(100)\n",
    "        self.fc3=nn.Linear(100,9)\n",
    "        self.bn3=nn.BatchNorm1d(9)\n",
    "        \n",
    "        self.drop=nn.Dropout(0.5)\n",
    "    def forward(self, x):\n",
    "        x=self.bn0(x)\n",
    "        x = F.relu(self.drop(self.bn1(self.fc1(x))))\n",
    "        x = F.relu(self.drop(self.bn2(self.fc2(x))))\n",
    "        return F.softmax(self.bn3(self.fc3(x)), dim=1)\n",
    "model3 = MLP3().cuda()\n",
    "print(model3)\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.backends.cudnn as cudnn\n",
    "#3from tensorboardX import SummaryWriter\n",
    "import torch.nn.functional as F  # 激励函数的库\n",
    "#import network\n",
    "import config\n",
    "import evaluate\n",
    "import data_utils\n",
    "#import Trainer\n",
    "\n",
    "\n",
    "\n",
    "def one_hot_smoothing(labels, classes, label_smoothing=0.2):\n",
    "    #n = len(labels)\n",
    "    n=labels.shape[0]\n",
    "    eoff = label_smoothing / classes\n",
    "    output = np.ones((n, classes), dtype=np.float32) * eoff\n",
    "    for row, label in enumerate(labels):\n",
    "        output[row, label] = 1 - label_smoothing + eoff\n",
    "        #print(\"row:\",row,\"label:\",label)\n",
    "    return output\n",
    "\n",
    "def one_hot(labels, classes):\n",
    "    n = len(labels)\n",
    "    #eoff = label_smoothing / classes\n",
    "    output = np.zeros((n, classes), dtype=np.float32)\n",
    "    for row, label in enumerate(labels):\n",
    "        output[row, label] = 1\n",
    "        #print(\"row:\",row,\"label:\",label)\n",
    "    return output\n",
    "\n",
    "\n",
    "def one_hot_smoothing(labels, classes, label_smoothing=0.2):\n",
    "    #n = len(labels)\n",
    "    n=labels.shape[0]\n",
    "    eoff = label_smoothing / classes\n",
    "    output = np.ones((n, classes), dtype=np.float32) * eoff\n",
    "    for row, label in enumerate(labels):\n",
    "        output[row, label] = 1 - label_smoothing + eoff\n",
    "        #print(\"row:\",row,\"label:\",label)\n",
    "    return output\n",
    "\n",
    "def one_hot(labels, classes):\n",
    "    n = len(labels)\n",
    "    #eoff = label_smoothing / classes\n",
    "    output = np.zeros((n, classes), dtype=np.float32)\n",
    "    for row, label in enumerate(labels):\n",
    "        output[row, label] = 1\n",
    "        #print(\"row:\",row,\"label:\",label)\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "class KZDatasetPredict(data.Dataset):\n",
    "    \"\"\" Construct the FM pytorch dataset. \"\"\"\n",
    "    #def __init__(self, file,label_file, feature_map,n_class=16):\n",
    "    def __init__(self, df_list):\n",
    "    \n",
    "       \n",
    "        self.data_info = self.get_data_info(df_list)\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Dataset读取图片的函数\n",
    "        data,label = self.data_info[index]\n",
    "        #img = Image.open(img_pth).convert('RGB')\n",
    "        \n",
    "        return data,label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_info)\n",
    "   \n",
    "    \n",
    "    \n",
    "    def get_data_info(self,df_list):\n",
    "        #解析路径\n",
    "        #转为一维list存储，每一位为【图片路径，图片类别】\n",
    "        labels=[]\n",
    "        data_info=[]\n",
    "        print('data_info:',df_list[-1])\n",
    "        #df=pd.read_csv(csv_path,sep=',')\n",
    "        #df=df.iloc[:,1:]\n",
    "        \n",
    "        #print(df.iloc[:,-1])\n",
    "        #df=df.applymap(ast.literal_eval)\n",
    "        label=int(df_list[-1])\n",
    "        labels.append(label)\n",
    "        print('labels:',labels)\n",
    "        data=df_list[:-1]\n",
    "        #df_np=np.array(df_list)\n",
    "        #print(rows,cols)\n",
    "        \n",
    "        #print('labels:',labels)\n",
    "        labels=np.array(labels)\n",
    "        print('labels.shape:',labels.shape)\n",
    "        #print('labels:',labels)\n",
    "        #labels=np.array(labels)\n",
    "        labels=one_hot_smoothing(labels,nfm_config['n_class'])\n",
    "        #print(labels)\n",
    "        \n",
    "           \n",
    "        \n",
    "        data=np.array(data)#\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        data=torch.from_numpy(data)#\n",
    "            \n",
    "        labels=torch.from_numpy(labels)#\n",
    "        #bi_data=embding_process(nfm_config,data)\n",
    "        #print(\"bi_data.shape:\",bi_data.shape)\n",
    "            \n",
    "            \n",
    "        data_info.append((data,label))\n",
    "        return data_info\n",
    "class KZDatasetTest(data.Dataset):\n",
    "    \"\"\" Construct the FM pytorch dataset. \"\"\"\n",
    "    #def __init__(self, file,label_file, feature_map,n_class=16):\n",
    "    def __init__(self, csv_path):\n",
    "    \n",
    "       \n",
    "        self.data_info = self.get_data_info(csv_path)\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Dataset读取图片的函数\n",
    "        data, label = self.data_info[index]\n",
    "        #img = Image.open(img_pth).convert('RGB')\n",
    "        \n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_info)\n",
    "   \n",
    "    \n",
    "    \n",
    "    def get_data_info(self,csv_path):\n",
    "        #解析路径\n",
    "        #转为一维list存储，每一位为【图片路径，图片类别】\n",
    "        labels=[]\n",
    "        data_info=[]\n",
    "        df=pd.read_csv(csv_path,sep=',')\n",
    "        df=df.iloc[:,1:]\n",
    "        \n",
    "        #print(df.iloc[:,-1])\n",
    "        #df=df.applymap(ast.literal_eval)\n",
    "        rows,cols=df.shape\n",
    "        print(rows,cols)\n",
    "        for i in df.iloc[:,-1]:\n",
    "            #print(i)\n",
    "            labels.append(int(i))\n",
    "        #print('labels:',labels)\n",
    "        labels=np.array(labels)\n",
    "        #print('labels:',labels)\n",
    "        #labels=np.array(labels)\n",
    "        labels=one_hot_smoothing(labels,nfm_config['n_class'])\n",
    "        #print(labels)\n",
    "        for i in range(rows):\n",
    "            data=df.iloc[i,:-1]\n",
    "            data=data.astype(float)#\n",
    "            data=np.array(data)#\n",
    "            \n",
    "            label=labels[i]\n",
    "            #print(data.shape)\n",
    "            #print(label.shape)\n",
    "            #label=label.tolist()\n",
    "            data=torch.from_numpy(data)#\n",
    "            label=torch.from_numpy(label)#\n",
    "            \n",
    "            \n",
    "            data_info.append((data,label))\n",
    "        return data_info\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.dataset import *\n",
    "from PIL import Image\n",
    "from torch.nn import functional as F\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ast\n",
    "import torchvision\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "class KZDataset(Dataset):\n",
    "    def __init__(self, csv_path, K,n_class,ki=0, typ='train', transform=None, rand=False):\n",
    "       \n",
    "        self.all_data_info = self.get_data_info(csv_path)\n",
    "        \n",
    "        if rand:\n",
    "            random.seed(1)\n",
    "            random.shuffle(self.all_data_info)\n",
    "        leng = len(self.all_data_info)\n",
    "        every_z_len = leng // K\n",
    "        if typ == 'val':\n",
    "            self.data_info = self.all_data_info[every_z_len * ki : every_z_len * (ki+1)]\n",
    "        elif typ == 'train':\n",
    "            self.data_info = self.all_data_info[: every_z_len * ki] + self.all_data_info[every_z_len * (ki+1) :]\n",
    "            \n",
    "        self.transform = transform\n",
    "        \n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Dataset读取图片的函数\n",
    "        data, label = self.data_info[index]\n",
    "        #img = Image.open(img_pth).convert('RGB')\n",
    "        \n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_info)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_data_info(self,csv_path):\n",
    "        #解析路径\n",
    "        #转为一维list存储，每一位为【图片路径，图片类别】\n",
    "        labels=[]\n",
    "        data_info=[]\n",
    "        df=pd.read_csv(csv_path,sep=',')\n",
    "        df=df.iloc[:,1:]\n",
    "        \n",
    "        #print(df.iloc[:,-1])\n",
    "        #df=df.applymap(ast.literal_eval)\n",
    "        rows,cols=df.shape\n",
    "        \n",
    "        print(rows,cols)\n",
    "        for i in df.iloc[:,-1]:\n",
    "            #print(i)\n",
    "            labels.append(int(i))\n",
    "        #print('labels:',labels)\n",
    "        labels=np.array(labels)\n",
    "        #print('labels:',labels)\n",
    "        #labels=np.array(labels)\n",
    "        labels=one_hot_smoothing(labels,nfm_config['n_class'])\n",
    "        #print(labels)\n",
    "        for i in range(rows):\n",
    "            data=df.iloc[i,:-1]\n",
    "            data=data.astype(float)#\n",
    "            data=np.array(data)#\n",
    "            \n",
    "            label=labels[i]\n",
    "            #print(data.shape)\n",
    "            #print(label.shape)\n",
    "            #label=label.tolist()\n",
    "            data=torch.from_numpy(data)#\n",
    "            label=torch.from_numpy(label)#\n",
    "            \n",
    "            \n",
    "            data_info.append((data,label))\n",
    "        return data_info\n",
    "            \n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from new_nfm_network import NFM\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.backends.cudnn as cudnn\n",
    "#3from tensorboardX import SummaryWriter\n",
    "import sys \n",
    "#import network\n",
    "import config\n",
    "import evaluate\n",
    "import data_utils\n",
    "import Trainer\n",
    "import torchmetrics\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from new_nfm_network import NFM\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.backends.cudnn as cudnn\n",
    "#3from tensorboardX import SummaryWriter\n",
    "import sys \n",
    "#import network\n",
    "import config\n",
    "import evaluate\n",
    "import data_utils\n",
    "import Trainer\n",
    "import torchmetrics\n",
    "\n",
    "\n",
    "def train_epoch(model,train_loader,batch_size,optimizer,loss_func):\n",
    "    BATCH_SIZE=batch_size\n",
    "    total = 0\n",
    "    correct=0\n",
    "    total_loss=0\n",
    "    #\n",
    "    model.train()\n",
    "    total_train_accuracy=0  \n",
    "    for batch_idx, (x, labels) in enumerate(train_loader):\n",
    "            \n",
    "        labels = Variable(labels)\n",
    "        x = Variable(x)\n",
    "            \n",
    "            \n",
    "        x=torch.tensor(x,dtype=torch.float)\n",
    "        labels=torch.tensor(labels,dtype=torch.float)\n",
    "        x, labels = x.cuda(), labels.cuda()\n",
    "        labels_int=labels=torch.max(labels,1)[1]\n",
    "        \n",
    "        \n",
    "        for j in batch_size:\n",
    "            l3=torch.mm(weight['fc3.weight[j,:]'],weight['fc2.weight'])\n",
    "            print('l3:',l3.shape)\n",
    "            l2=torch.mm(l3,weight['fc1.weight'])\n",
    "            print('l2:',l2.shape)\n",
    "            uu=l2*x.reshape(3300)\n",
    "            q\n",
    "        optimizer.zero_grad()\n",
    "        y_predict = model(x)\n",
    "            \n",
    "        loss = loss_func(y_predict, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        loss = loss.item()\n",
    "           \n",
    "\n",
    "        total_loss += loss\n",
    "            \n",
    "            \n",
    "            \n",
    "        batch_train_acc=torchmetrics.functional.accuracy(y_predict,labels_int)\n",
    "        total_train_accuracy+=batch_train_acc\n",
    "            \n",
    "    total_train_accuracy/=(batch_idx+1)\n",
    "    print('total_train_accuracy:',total_train_accuracy)\n",
    "    print(\"Training Epoch: %d, total loss: %f\" % (epoch_id, total_loss))\n",
    "    return total_loss,total_train_accuracy\n",
    "\n",
    "def val_epoch(model,test_loader,batch_size,optimizer): \n",
    "    batch_size_num=0\n",
    "    total_test_acc=0\n",
    "    model.eval()\n",
    "    for i , (inputs , targets) in enumerate(test_loader):   \n",
    "            print(\"test\")\n",
    "            \n",
    "            inputs = Variable(inputs)   \n",
    "            targets = Variable(targets)     \n",
    "           \n",
    "            inputs=torch.tensor(inputs ,dtype=torch.float)   \n",
    "            targets=torch.tensor(targets ,dtype=torch.float)   \n",
    "            inputs , targets = inputs.cuda(),  targets.cuda()   \n",
    "            yhat = model(inputs)  \n",
    "            \n",
    "            \n",
    "            \n",
    "            targets=torch.max(targets,1)[1]\n",
    "            \n",
    "            \n",
    "            \n",
    "            batch_test_acc=torchmetrics.functional.accuracy(yhat,targets)\n",
    "            \n",
    "            total_test_acc+=batch_test_acc\n",
    "            \n",
    "            batch_size_num=i\n",
    "    total_test_acc/=(batch_size_num+1)\n",
    "        ###print('total_test_accuracy:',total_test_acc/(batch_size+1))\n",
    "    print('total_test_accuracy:',total_test_acc)\n",
    "        \n",
    "                    \n",
    "                    \n",
    "            \n",
    "            \n",
    "    \n",
    "        \n",
    "   \n",
    "    \n",
    "    return total_test_acc\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plotLoss(loss,epoch):\n",
    "    plt.rcParams['font.sans-serif']=['SimHei']\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    x=[i for i in range(epoch)]\n",
    "    #acc_train=acc_train.cpu()\n",
    "    #acc_test=acc_test.cpu()\n",
    "    plt.plot(x, loss, 'r-', mec='k', label='Logistic Loss', lw=2)\n",
    "    #plt.plot(x,acc_train,'b-',mec='k',label='accuracy Train',lw=2)\n",
    "    #plt.plot(x,acc_test,'g-',mec='k',label='accuracy Test',lw=2)\n",
    "    #plt.plot(x, y_01, 'g-', mec='k', label='0/1 Loss', lw=2)\n",
    "    #plt.plot(x, y_hinge, 'b-',mec='k', label='Hinge Loss', lw=2)\n",
    "    #plt.plot(x, boost, 'm--',mec='k', label='Adaboost Loss',lw=2)\n",
    "    plt.grid(True, ls='--')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('损失函数')\n",
    "    plt.show()\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352693da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549 3301\n",
      "549 3301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/.local/lib/python3.6/site-packages/ipykernel_launcher.py:471: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/zhengfang/.local/lib/python3.6/site-packages/ipykernel_launcher.py:472: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_train_accuracy: tensor(0.1375, device='cuda:0')\n",
      "Training Epoch: 0, total loss: 65.772607\n",
      "total_train_accuracy: tensor(0.1813, device='cuda:0')\n",
      "Training Epoch: 1, total loss: 64.959912\n",
      "total_train_accuracy: tensor(0.2313, device='cuda:0')\n",
      "Training Epoch: 2, total loss: 64.461120\n",
      "total_train_accuracy: tensor(0.2667, device='cuda:0')\n",
      "Training Epoch: 3, total loss: 63.768927\n",
      "total_train_accuracy: tensor(0.3208, device='cuda:0')\n",
      "Training Epoch: 4, total loss: 63.134576\n",
      "total_train_accuracy: tensor(0.3646, device='cuda:0')\n",
      "Training Epoch: 5, total loss: 62.503218\n",
      "total_train_accuracy: tensor(0.4083, device='cuda:0')\n",
      "Training Epoch: 6, total loss: 61.998270\n",
      "total_train_accuracy: tensor(0.4375, device='cuda:0')\n",
      "Training Epoch: 7, total loss: 61.551807\n",
      "total_train_accuracy: tensor(0.4417, device='cuda:0')\n",
      "Training Epoch: 8, total loss: 60.945564\n",
      "total_train_accuracy: tensor(0.4688, device='cuda:0')\n",
      "Training Epoch: 9, total loss: 60.254373\n",
      "total_train_accuracy: tensor(0.5229, device='cuda:0')\n",
      "Training Epoch: 10, total loss: 59.709184\n",
      "total_train_accuracy: tensor(0.5208, device='cuda:0')\n",
      "Training Epoch: 11, total loss: 59.076484\n",
      "total_train_accuracy: tensor(0.5458, device='cuda:0')\n",
      "Training Epoch: 12, total loss: 58.618243\n",
      "total_train_accuracy: tensor(0.5833, device='cuda:0')\n",
      "Training Epoch: 13, total loss: 58.243449\n",
      "total_train_accuracy: tensor(0.5917, device='cuda:0')\n",
      "Training Epoch: 14, total loss: 57.867606\n",
      "total_train_accuracy: tensor(0.5771, device='cuda:0')\n",
      "Training Epoch: 15, total loss: 57.598916\n",
      "total_train_accuracy: tensor(0.6125, device='cuda:0')\n",
      "Training Epoch: 16, total loss: 57.293475\n",
      "total_train_accuracy: tensor(0.6333, device='cuda:0')\n",
      "Training Epoch: 17, total loss: 56.445544\n",
      "total_train_accuracy: tensor(0.6146, device='cuda:0')\n",
      "Training Epoch: 18, total loss: 56.564138\n",
      "total_train_accuracy: tensor(0.6417, device='cuda:0')\n",
      "Training Epoch: 19, total loss: 55.883558\n",
      "total_train_accuracy: tensor(0.6896, device='cuda:0')\n",
      "Training Epoch: 20, total loss: 55.484316\n",
      "total_train_accuracy: tensor(0.6792, device='cuda:0')\n",
      "Training Epoch: 21, total loss: 55.541686\n",
      "total_train_accuracy: tensor(0.7167, device='cuda:0')\n",
      "Training Epoch: 22, total loss: 54.150794\n",
      "total_train_accuracy: tensor(0.6708, device='cuda:0')\n",
      "Training Epoch: 23, total loss: 54.936267\n",
      "total_train_accuracy: tensor(0.7125, device='cuda:0')\n",
      "Training Epoch: 24, total loss: 54.099086\n",
      "total_train_accuracy: tensor(0.7208, device='cuda:0')\n",
      "Training Epoch: 25, total loss: 53.919620\n",
      "total_train_accuracy: tensor(0.6979, device='cuda:0')\n",
      "Training Epoch: 26, total loss: 53.941602\n",
      "total_train_accuracy: tensor(0.7188, device='cuda:0')\n",
      "Training Epoch: 27, total loss: 53.675578\n",
      "total_train_accuracy: tensor(0.7125, device='cuda:0')\n",
      "Training Epoch: 28, total loss: 53.325203\n",
      "total_train_accuracy: tensor(0.7542, device='cuda:0')\n",
      "Training Epoch: 29, total loss: 52.810995\n",
      "total_train_accuracy: tensor(0.7333, device='cuda:0')\n",
      "Training Epoch: 30, total loss: 52.945503\n",
      "total_train_accuracy: tensor(0.7083, device='cuda:0')\n",
      "Training Epoch: 31, total loss: 53.000975\n",
      "total_train_accuracy: tensor(0.7354, device='cuda:0')\n",
      "Training Epoch: 32, total loss: 52.359368\n",
      "total_train_accuracy: tensor(0.7563, device='cuda:0')\n",
      "Training Epoch: 33, total loss: 52.238169\n",
      "total_train_accuracy: tensor(0.7604, device='cuda:0')\n",
      "Training Epoch: 34, total loss: 52.193303\n",
      "total_train_accuracy: tensor(0.7896, device='cuda:0')\n",
      "Training Epoch: 35, total loss: 51.214235\n",
      "total_train_accuracy: tensor(0.8125, device='cuda:0')\n",
      "Training Epoch: 36, total loss: 50.754228\n",
      "total_train_accuracy: tensor(0.7938, device='cuda:0')\n",
      "Training Epoch: 37, total loss: 50.992992\n",
      "total_train_accuracy: tensor(0.7833, device='cuda:0')\n",
      "Training Epoch: 38, total loss: 50.854538\n",
      "total_train_accuracy: tensor(0.7729, device='cuda:0')\n",
      "Training Epoch: 39, total loss: 51.360752\n",
      "total_train_accuracy: tensor(0.7958, device='cuda:0')\n",
      "Training Epoch: 40, total loss: 50.220990\n",
      "total_train_accuracy: tensor(0.8083, device='cuda:0')\n",
      "Training Epoch: 41, total loss: 50.274381\n",
      "total_train_accuracy: tensor(0.7896, device='cuda:0')\n",
      "Training Epoch: 42, total loss: 50.804336\n",
      "total_train_accuracy: tensor(0.7979, device='cuda:0')\n",
      "Training Epoch: 43, total loss: 50.669163\n",
      "total_train_accuracy: tensor(0.8167, device='cuda:0')\n",
      "Training Epoch: 44, total loss: 50.300641\n",
      "total_train_accuracy: tensor(0.8021, device='cuda:0')\n",
      "Training Epoch: 45, total loss: 50.229771\n",
      "total_train_accuracy: tensor(0.7833, device='cuda:0')\n",
      "Training Epoch: 46, total loss: 50.367232\n",
      "total_train_accuracy: tensor(0.7813, device='cuda:0')\n",
      "Training Epoch: 47, total loss: 50.591614\n",
      "total_train_accuracy: tensor(0.8375, device='cuda:0')\n",
      "Training Epoch: 48, total loss: 49.229996\n",
      "total_train_accuracy: tensor(0.8104, device='cuda:0')\n",
      "Training Epoch: 49, total loss: 49.931505\n",
      "total_train_accuracy: tensor(0.8313, device='cuda:0')\n",
      "Training Epoch: 50, total loss: 49.587311\n",
      "total_train_accuracy: tensor(0.8271, device='cuda:0')\n",
      "Training Epoch: 51, total loss: 49.354802\n",
      "total_train_accuracy: tensor(0.8438, device='cuda:0')\n",
      "Training Epoch: 52, total loss: 49.131190\n",
      "total_train_accuracy: tensor(0.8667, device='cuda:0')\n",
      "Training Epoch: 53, total loss: 48.640716\n",
      "total_train_accuracy: tensor(0.8208, device='cuda:0')\n",
      "Training Epoch: 54, total loss: 49.446251\n",
      "total_train_accuracy: tensor(0.8042, device='cuda:0')\n",
      "Training Epoch: 55, total loss: 49.066019\n",
      "total_train_accuracy: tensor(0.8292, device='cuda:0')\n",
      "Training Epoch: 56, total loss: 49.414949\n",
      "total_train_accuracy: tensor(0.8000, device='cuda:0')\n",
      "Training Epoch: 57, total loss: 49.540665\n",
      "total_train_accuracy: tensor(0.8271, device='cuda:0')\n",
      "Training Epoch: 58, total loss: 49.033693\n",
      "total_train_accuracy: tensor(0.8479, device='cuda:0')\n",
      "Training Epoch: 59, total loss: 48.318810\n",
      "total_train_accuracy: tensor(0.8438, device='cuda:0')\n",
      "Training Epoch: 60, total loss: 48.773605\n",
      "total_train_accuracy: tensor(0.8333, device='cuda:0')\n",
      "Training Epoch: 61, total loss: 48.507488\n",
      "total_train_accuracy: tensor(0.8542, device='cuda:0')\n",
      "Training Epoch: 62, total loss: 48.394171\n",
      "total_train_accuracy: tensor(0.8333, device='cuda:0')\n",
      "Training Epoch: 63, total loss: 48.411243\n",
      "total_train_accuracy: tensor(0.8542, device='cuda:0')\n",
      "Training Epoch: 64, total loss: 47.918627\n",
      "total_train_accuracy: tensor(0.8375, device='cuda:0')\n",
      "Training Epoch: 65, total loss: 48.488588\n",
      "total_train_accuracy: tensor(0.8438, device='cuda:0')\n",
      "Training Epoch: 66, total loss: 48.616477\n",
      "total_train_accuracy: tensor(0.8542, device='cuda:0')\n",
      "Training Epoch: 67, total loss: 47.918513\n",
      "total_train_accuracy: tensor(0.8896, device='cuda:0')\n",
      "Training Epoch: 68, total loss: 47.349811\n",
      "total_train_accuracy: tensor(0.8521, device='cuda:0')\n",
      "Training Epoch: 69, total loss: 47.651906\n",
      "total_train_accuracy: tensor(0.8521, device='cuda:0')\n",
      "Training Epoch: 70, total loss: 48.414657\n",
      "total_train_accuracy: tensor(0.8521, device='cuda:0')\n",
      "Training Epoch: 71, total loss: 48.090300\n",
      "total_train_accuracy: tensor(0.8375, device='cuda:0')\n",
      "Training Epoch: 72, total loss: 48.252837\n",
      "total_train_accuracy: tensor(0.8625, device='cuda:0')\n",
      "Training Epoch: 73, total loss: 47.524051\n",
      "total_train_accuracy: tensor(0.8521, device='cuda:0')\n",
      "Training Epoch: 74, total loss: 48.083789\n",
      "total_train_accuracy: tensor(0.8583, device='cuda:0')\n",
      "Training Epoch: 75, total loss: 47.739188\n",
      "total_train_accuracy: tensor(0.8917, device='cuda:0')\n",
      "Training Epoch: 76, total loss: 46.948088\n",
      "total_train_accuracy: tensor(0.8313, device='cuda:0')\n",
      "Training Epoch: 77, total loss: 48.255180\n",
      "total_train_accuracy: tensor(0.8708, device='cuda:0')\n",
      "Training Epoch: 78, total loss: 47.297784\n",
      "total_train_accuracy: tensor(0.8667, device='cuda:0')\n",
      "Training Epoch: 79, total loss: 47.772815\n",
      "total_train_accuracy: tensor(0.8938, device='cuda:0')\n",
      "Training Epoch: 80, total loss: 46.875365\n",
      "total_train_accuracy: tensor(0.8979, device='cuda:0')\n",
      "Training Epoch: 81, total loss: 46.623259\n",
      "total_train_accuracy: tensor(0.8854, device='cuda:0')\n",
      "Training Epoch: 82, total loss: 47.013375\n",
      "total_train_accuracy: tensor(0.8688, device='cuda:0')\n",
      "Training Epoch: 83, total loss: 47.342870\n",
      "total_train_accuracy: tensor(0.8813, device='cuda:0')\n",
      "Training Epoch: 84, total loss: 47.338373\n",
      "total_train_accuracy: tensor(0.8854, device='cuda:0')\n",
      "Training Epoch: 85, total loss: 47.248501\n",
      "total_train_accuracy: tensor(0.9000, device='cuda:0')\n",
      "Training Epoch: 86, total loss: 46.814551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_train_accuracy: tensor(0.8896, device='cuda:0')\n",
      "Training Epoch: 87, total loss: 46.833803\n",
      "total_train_accuracy: tensor(0.9125, device='cuda:0')\n",
      "Training Epoch: 88, total loss: 46.170443\n",
      "total_train_accuracy: tensor(0.8604, device='cuda:0')\n",
      "Training Epoch: 89, total loss: 47.055787\n",
      "total_train_accuracy: tensor(0.8979, device='cuda:0')\n",
      "Training Epoch: 90, total loss: 46.769913\n",
      "total_train_accuracy: tensor(0.8917, device='cuda:0')\n",
      "Training Epoch: 91, total loss: 46.644377\n",
      "total_train_accuracy: tensor(0.8938, device='cuda:0')\n",
      "Training Epoch: 92, total loss: 46.591598\n",
      "total_train_accuracy: tensor(0.8875, device='cuda:0')\n",
      "Training Epoch: 93, total loss: 46.641930\n",
      "total_train_accuracy: tensor(0.9188, device='cuda:0')\n",
      "Training Epoch: 94, total loss: 46.087920\n",
      "total_train_accuracy: tensor(0.8813, device='cuda:0')\n",
      "Training Epoch: 95, total loss: 46.932447\n",
      "total_train_accuracy: tensor(0.8792, device='cuda:0')\n",
      "Training Epoch: 96, total loss: 46.959149\n",
      "total_train_accuracy: tensor(0.9042, device='cuda:0')\n",
      "Training Epoch: 97, total loss: 46.101028\n",
      "total_train_accuracy: tensor(0.8917, device='cuda:0')\n",
      "Training Epoch: 98, total loss: 46.352740\n",
      "total_train_accuracy: tensor(0.8792, device='cuda:0')\n",
      "Training Epoch: 99, total loss: 46.444629\n",
      "total_train_accuracy: tensor(0.9125, device='cuda:0')\n",
      "Training Epoch: 100, total loss: 46.021352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans.\n",
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 25439 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 22833 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 20989 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 25968 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the  0  epoch ends\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 25439 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 22833 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 20989 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 25968 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/.local/lib/python3.6/site-packages/ipykernel_launcher.py:509: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/zhengfang/.local/lib/python3.6/site-packages/ipykernel_launcher.py:510: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "test\n",
      "test\n",
      "total_test_accuracy: tensor(0.7708, device='cuda:0')\n",
      "acc_test_each_k: tensor(0.7708, device='cuda:0')\n",
      "549 3301\n",
      "549 3301\n",
      "total_train_accuracy: tensor(0.8750, device='cuda:0')\n",
      "Training Epoch: 0, total loss: 47.084851\n",
      "total_train_accuracy: tensor(0.9000, device='cuda:0')\n",
      "Training Epoch: 1, total loss: 46.525617\n",
      "total_train_accuracy: tensor(0.8688, device='cuda:0')\n",
      "Training Epoch: 2, total loss: 46.890063\n",
      "total_train_accuracy: tensor(0.9000, device='cuda:0')\n",
      "Training Epoch: 3, total loss: 46.359420\n",
      "total_train_accuracy: tensor(0.8979, device='cuda:0')\n",
      "Training Epoch: 4, total loss: 46.325518\n",
      "total_train_accuracy: tensor(0.8792, device='cuda:0')\n",
      "Training Epoch: 5, total loss: 46.785652\n",
      "total_train_accuracy: tensor(0.9021, device='cuda:0')\n",
      "Training Epoch: 6, total loss: 46.632679\n",
      "total_train_accuracy: tensor(0.8917, device='cuda:0')\n",
      "Training Epoch: 7, total loss: 46.470479\n",
      "total_train_accuracy: tensor(0.9042, device='cuda:0')\n",
      "Training Epoch: 8, total loss: 46.412618\n",
      "total_train_accuracy: tensor(0.9000, device='cuda:0')\n",
      "Training Epoch: 9, total loss: 46.214377\n",
      "total_train_accuracy: tensor(0.9167, device='cuda:0')\n",
      "Training Epoch: 10, total loss: 45.918303\n",
      "total_train_accuracy: tensor(0.9063, device='cuda:0')\n",
      "Training Epoch: 11, total loss: 45.886062\n",
      "total_train_accuracy: tensor(0.9083, device='cuda:0')\n",
      "Training Epoch: 12, total loss: 46.136441\n",
      "total_train_accuracy: tensor(0.8833, device='cuda:0')\n",
      "Training Epoch: 13, total loss: 46.409997\n",
      "total_train_accuracy: tensor(0.8875, device='cuda:0')\n",
      "Training Epoch: 14, total loss: 46.373677\n",
      "total_train_accuracy: tensor(0.9313, device='cuda:0')\n",
      "Training Epoch: 15, total loss: 45.005206\n"
     ]
    }
   ],
   "source": [
    "\n",
    "K=10\n",
    "test_metrics=[]\n",
    "train_loss_total_list=[]\n",
    "for ki in range(K):\n",
    "    trainset = KZDataset(csv_path='dataset/qiuguan/origin_800/xiaoqiu_xiaoguan/train_val_info.csv',K=K, n_class=nfm_config['n_class'],ki=ki,  typ='train', transform=None, rand=True)\n",
    "    valset = KZDataset(csv_path='dataset/qiuguan/origin_800/xiaoqiu_xiaoguan/train_val_info.csv', K=K,n_class=nfm_config['n_class'],ki=ki,  typ='val', transform=None, rand=True)\n",
    "    train_loader = data.DataLoader(\n",
    "         dataset=trainset,\n",
    "         #transform=torchvision.transforms.ToTensor(),\n",
    "         drop_last=True,\n",
    "         batch_size=nfm_config['batch_size'],\n",
    "         shuffle=True)\n",
    "    val_loader = data.DataLoader(\n",
    "         dataset=valset,\n",
    "         #transform=torchvision.transforms.ToTensor(),\n",
    "         drop_last=True,\n",
    "         batch_size=nfm_config['batch_size']\n",
    "        \n",
    "     )\n",
    "    \n",
    "    model_path='models/MLP/loss/'\n",
    "    #BATCH_SIZE=batch_size\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=nfm_config['lr'], weight_decay=nfm_config['l2_regularization'])\n",
    "    #total = 0\n",
    "    \n",
    "    \n",
    "    loss_func=torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    num=0\n",
    "   \n",
    "    \n",
    "    epoches=101\n",
    "    for epoch_id in range(epoches):\n",
    "          \n",
    "        \n",
    "        \n",
    "        train_loss_total,acc_train=train_epoch(model,train_loader,nfm_config['batch_size'],optimizer,loss_func)\n",
    "        train_loss_total_list.append(train_loss_total)#\n",
    "        if epoch_id %20==0:\n",
    "            num=num+1\n",
    "            #path=os.path.join(model_path,'MLP'+str(num)+str(K)+'.pkl')\n",
    "            #torch.save(model.state_dict(),path)\n",
    "            # 保存模型\n",
    "            \n",
    "            path=os.path.join(model_path,'MLP'+str(num)+str(K)+'.pt')##################pt\n",
    "            torch.save(model.state_dict(),path)\n",
    "            #torch.save(model.state_dict(),path)\n",
    "    print(\"the \",ki,\" epoch ends\")\n",
    "    plotLoss(train_loss_total_list,epoches)\n",
    "    train_loss_total_list=[]\n",
    "    acc_test=val_epoch(model,val_loader,nfm_config['batch_size'],optimizer)\n",
    "    print(\"acc_test_each_k:\",acc_test)\n",
    "    test_metrics.append(acc_test)\n",
    "\n",
    "print(test_metrics)\n",
    "#test_metrics=test_metrics.tolist()\n",
    "test_metrics=[x.cpu().detach().numpy() for x in test_metrics]\n",
    "print(test_metrics)\n",
    "acc_test_metrics=np.mean(test_metrics) \n",
    "print(\"acc_test_metrics:\",acc_test_metrics)\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fcbbd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
