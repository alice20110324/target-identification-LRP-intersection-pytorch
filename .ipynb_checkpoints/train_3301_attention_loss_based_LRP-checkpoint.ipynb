{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e46a3e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn0.weight\n",
      "bn0.bias\n",
      "bn0.running_mean\n",
      "bn0.running_var\n",
      "bn0.num_batches_tracked\n",
      "fc1.weight\n",
      "fc1.bias\n",
      "bn1.weight\n",
      "bn1.bias\n",
      "bn1.running_mean\n",
      "bn1.running_var\n",
      "bn1.num_batches_tracked\n",
      "fc2.weight\n",
      "fc2.bias\n",
      "bn2.weight\n",
      "bn2.bias\n",
      "bn2.running_mean\n",
      "bn2.running_var\n",
      "bn2.num_batches_tracked\n",
      "fc3.weight\n",
      "fc3.bias\n",
      "bn3.weight\n",
      "bn3.bias\n",
      "bn3.running_mean\n",
      "bn3.running_var\n",
      "bn3.num_batches_tracked\n",
      "MLP(\n",
      "  (bn0): BatchNorm1d(3300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=3300, out_features=2000, bias=True)\n",
      "  (bn1): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=2000, out_features=100, bias=True)\n",
      "  (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=100, out_features=9, bias=True)\n",
      "  (bn3): BatchNorm1d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.3, inplace=False)\n",
      ")\n",
      "relevance\n",
      "relevance\n"
     ]
    }
   ],
   "source": [
    "#############  u===2   MLP_encode_100 and MLP_encode_1000  :654    ##################\n",
    "import torch\n",
    "#import Trainer\n",
    "from network import NFM\n",
    "import torch.utils.data as Data\n",
    "from Utils.criteo_loader import getTestData, getTrainData\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from new_nfm_network import NFM\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.backends.cudnn as cudnn\n",
    "#3from tensorboardX import SummaryWriter\n",
    "import sys \n",
    "#import network\n",
    "import config\n",
    "import evaluate\n",
    "import data_utils\n",
    "import Trainer\n",
    "import torchmetrics\n",
    "\n",
    "from innvestigator import InnvestigateModel\n",
    "from utils import Flatten\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from mnist_test import Net, train, test\n",
    "\n",
    "input_num=3300\n",
    "# Network parameters\n",
    "class Params(object):\n",
    "    batch_size = 64\n",
    "    test_batch_size = 20\n",
    "    epochs = 5\n",
    "    lr = 0.01\n",
    "    momentum = 0.5\n",
    "    no_cuda = True\n",
    "    seed = 1\n",
    "    log_interval = 10\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "args = Params()\n",
    "torch.manual_seed(args.seed)\n",
    "#device = torch.device(\"cpu\")\n",
    "device=torch.device('cuda')\n",
    "kwargs = {}\n",
    "nfm_config = \\\n",
    "{\n",
    "    'n_class':9,\n",
    "    \n",
    "    'num_epoch': 500,#训练epoch次数\n",
    "    'batch_size': 16,#batch_size\n",
    "    'lr': 1e-3,\n",
    "    'l2_regularization': 1e-4,\n",
    "    'device_id': 0,\n",
    "    'use_cuda': False,\n",
    "    'epoch':1000,\n",
    "    \n",
    "   \n",
    "    'gene_name':'dataset/qiuguan/origin_800/gene_name.csv',\n",
    "    'label_name':'dataset/qiuguan/origin_800/gene_label.csv'\n",
    "    \n",
    "}\n",
    "\n",
    "#model definition\n",
    "import torch.nn as nn\n",
    "    \n",
    "    \n",
    "\n",
    "#model1 = MLP().cuda()\n",
    "#print(model1)\n",
    "\n",
    "class MLP_P(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bn0=nn.BatchNorm1d(input_num)\n",
    "        self.fc1 = nn.Linear(input_num, 2000)\n",
    "        self.bn1= nn.BatchNorm1d(2000)\n",
    "        self.fc2 = nn.Linear(2000, 100)\n",
    "        self.bn2=nn.BatchNorm1d(100)\n",
    "        self.fc3=nn.Linear(100,9)\n",
    "        self.bn3=nn.BatchNorm1d(9)\n",
    "        \n",
    "        self.drop=nn.Dropout(0.3)    \n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bn0=nn.BatchNorm1d(input_num)\n",
    "        self.fc1 = nn.Linear(input_num, 2000)\n",
    "        self.bn1= nn.BatchNorm1d(2000)\n",
    "        self.fc2 = nn.Linear(2000, 100)\n",
    "        self.bn2=nn.BatchNorm1d(100)\n",
    "        self.fc3=nn.Linear(100,9)\n",
    "        self.bn3=nn.BatchNorm1d(9)\n",
    "        \n",
    "        self.drop=nn.Dropout(0.3) \n",
    "        \n",
    "        #self.model1=MLP1().cuda() \n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        y1=self.bn0(x)\n",
    "        y1 = F.relu(self.drop(self.bn1(self.fc1(y1))))\n",
    "        y1= F.relu(self.drop(self.bn2(self.fc2(y1))))\n",
    "        return F.softmax(self.bn3(self.fc3(y1)), dim=1)\n",
    "        \n",
    "           \n",
    "        \n",
    "        \n",
    "        \n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "model = MLP().cuda()\n",
    "\n",
    "for i in model.state_dict():\n",
    "    print(i)\n",
    "print(model)\n",
    "mlp_paras=list(model.named_parameters())\n",
    "#print(mlp_paras)\n",
    "inn_model2 = InnvestigateModel(model, lrp_exponent=2,\n",
    "                              method=\"e-rule\",                              beta=.5)\n",
    "\n",
    "#model1=model\n",
    "inn_model1 = InnvestigateModel(model, lrp_exponent=2,\n",
    "                              method=\"e-rule\",\n",
    "                              beta=.5)\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.backends.cudnn as cudnn\n",
    "#3from tensorboardX import SummaryWriter\n",
    "import torch.nn.functional as F  # 激励函数的库\n",
    "#import network\n",
    "import config\n",
    "import evaluate\n",
    "import data_utils\n",
    "import Trainer\n",
    "\n",
    "def one_hot_smoothing(labels, classes, label_smoothing=0.2):\n",
    "    #n = len(labels)\n",
    "    n=labels.shape[0]\n",
    "    eoff = label_smoothing / classes\n",
    "    output = np.ones((n, classes), dtype=np.float32) * eoff\n",
    "    for row, label in enumerate(labels):\n",
    "        output[row, label] = 1 - label_smoothing + eoff\n",
    "        #print(\"row:\",row,\"label:\",label)\n",
    "    return output\n",
    "\n",
    "def one_hot(labels, classes):\n",
    "    n = len(labels)\n",
    "    #eoff = label_smoothing / classes\n",
    "    output = np.zeros((n, classes), dtype=np.float32)\n",
    "    for row, label in enumerate(labels):\n",
    "        output[row, label] = 1\n",
    "        #print(\"row:\",row,\"label:\",label)\n",
    "    return output\n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def one_hot_smoothing(labels, classes, label_smoothing=0.2):\n",
    "    #n = len(labels)\n",
    "    n=labels.shape[0]\n",
    "    eoff = label_smoothing / classes\n",
    "    output = np.ones((n, classes), dtype=np.float32) * eoff\n",
    "    for row, label in enumerate(labels):\n",
    "        output[row, label] = 1 - label_smoothing + eoff\n",
    "        #print(\"row:\",row,\"label:\",label)\n",
    "    return output\n",
    "\n",
    "def one_hot(labels, classes):\n",
    "    n = len(labels)\n",
    "    #eoff = label_smoothing / classes\n",
    "    output = np.zeros((n, classes), dtype=np.float32)\n",
    "    for row, label in enumerate(labels):\n",
    "        output[row, label] = 1\n",
    "        #print(\"row:\",row,\"label:\",label)\n",
    "    return output\n",
    "\n",
    "class KZDatasetTest(data.Dataset):\n",
    "    \"\"\" Construct the FM pytorch dataset. \"\"\"\n",
    "    #def __init__(self, file,label_file, feature_map,n_class=16):\n",
    "    def __init__(self, csv_path):\n",
    "    \n",
    "       \n",
    "        self.data_info = self.get_data_info(csv_path)\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Dataset读取图片的函数\n",
    "        data, label = self.data_info[index]\n",
    "        #img = Image.open(img_pth).convert('RGB')\n",
    "        \n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_info)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_data_info(self,csv_path):\n",
    "        #解析路径\n",
    "        #转为一维list存储，每一位为【图片路径，图片类别】\n",
    "        labels=[]\n",
    "        data_info=[]\n",
    "        df=pd.read_csv(csv_path,sep=',')\n",
    "        #print(\"df:\",df)\n",
    "        df=df.iloc[:,1:]\n",
    "        \n",
    "        rows,cols=df.shape\n",
    "        #print(rows,cols)\n",
    "        for i in df.iloc[:,-1]:\n",
    "            #print(i)\n",
    "            labels.append(int(float(i)))\n",
    "        #print('labels:',labels)\n",
    "        labels=np.array(labels)\n",
    "        \n",
    "        labels=one_hot_smoothing(labels,nfm_config['n_class'])\n",
    "        #print(labels)\n",
    "        for i in range(rows):\n",
    "            data=df.iloc[i,:-1]\n",
    "            data=data.astype(float)##############\n",
    "            \n",
    "            data=np.array(data)##\n",
    "            \n",
    "            label=labels[i]\n",
    "            \n",
    "            data=torch.from_numpy(data)#\n",
    "            label=torch.from_numpy(label)#\n",
    "           \n",
    "            \n",
    "            data_info.append((data,label))\n",
    "        return data_info\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.dataset import *\n",
    "from PIL import Image\n",
    "from torch.nn import functional as F\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ast\n",
    "import torchvision\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "class KZDataset(Dataset):\n",
    "    def __init__(self, csv_path, K,n_class,ki=0, typ='train', transform=None, rand=False):\n",
    "        \n",
    "        self.all_data_info = self.get_data_info(csv_path)\n",
    "        \n",
    "        if rand:\n",
    "            random.seed(1)\n",
    "            random.shuffle(self.all_data_info)\n",
    "        leng = len(self.all_data_info)\n",
    "        every_z_len = leng // K\n",
    "        if typ == 'val':\n",
    "            self.data_info = self.all_data_info[every_z_len * ki : every_z_len * (ki+1)]\n",
    "        elif typ == 'train':\n",
    "            self.data_info = self.all_data_info[: every_z_len * ki] + self.all_data_info[every_z_len * (ki+1) :]\n",
    "            \n",
    "        self.transform = transform\n",
    "        \n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Dataset读取图片的函数\n",
    "        data, label = self.data_info[index]\n",
    "        #img = Image.open(img_pth).convert('RGB')\n",
    "        \n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_info)\n",
    "       \n",
    "    \n",
    "    def get_data_info(self,csv_path):\n",
    "        #解析路径\n",
    "        #转为一维list存储，每一位为【图片路径，图片类别】\n",
    "        labels=[]\n",
    "        data_info=[]\n",
    "        df=pd.read_csv(csv_path,sep=',')\n",
    "        #print(\"df:\",df)\n",
    "        df=df.iloc[:,1:]\n",
    "        #print(\"df:\",df)\n",
    "        print(df.shape)\n",
    "        #print(\"df:\",df)\n",
    "        #print(df.iloc[:,-1])\n",
    "        #df=df.applymap(ast.literal_eval)\n",
    "        rows,cols=df.shape\n",
    "        #print(rows,cols)\n",
    "        for i in df.iloc[:,-1]:\n",
    "            #print(i)\n",
    "            labels.append(int(float(i)))\n",
    "        #print('labels:',i,labels)\n",
    "        labels=np.array(labels)\n",
    "        #print('labels:',labels)\n",
    "        #labels=np.array(labels)\n",
    "        labels=one_hot_smoothing(labels,nfm_config['n_class'])\n",
    "        #print(labels)\n",
    "        for i in range(rows):\n",
    "            data=df.iloc[i,:-1]\n",
    "            data=data.astype(float)##############\n",
    "            #print(\"i,data:\",i,data)\n",
    "            #data=pd.DataFrame(data,dtype=float)###############\n",
    "            data=np.array(data)##\n",
    "            \n",
    "            label=labels[i]\n",
    "            #print(data.shape)\n",
    "            #print(label.shape)\n",
    "            #label=label.tolist()\n",
    "            data=torch.from_numpy(data)#\n",
    "            label=torch.from_numpy(label)#\n",
    "           \n",
    "            \n",
    "            data_info.append((data,label))\n",
    "        return data_info\n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from new_nfm_network import NFM\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.backends.cudnn as cudnn\n",
    "#3from tensorboardX import SummaryWriter\n",
    "import sys \n",
    "#import network\n",
    "import config\n",
    "import evaluate\n",
    "import data_utils\n",
    "import Trainer\n",
    "import torchmetrics\n",
    "#LRP\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "%matplotlib inline\n",
    "\n",
    "from innvestigator import InnvestigateModel\n",
    "from utils import Flatten\n",
    "def standN(x):\n",
    "    row,col=x.shape\n",
    "    max_x=torch.max(x,1)\n",
    "    min_x=torch.min(x,1)\n",
    "    #print(max_x)\n",
    "    #print(min_x)\n",
    "    for i in range(row):\n",
    "        x[i]=(x[i]-min_x.values[i])/max_x.values[i]\n",
    "    return x\n",
    "\n",
    "def standNorm(x):\n",
    "    row,col=x.shape\n",
    "    mean=torch.mean(x,1)\n",
    "    std=torch.std(x,1)\n",
    "    #print(mean)\n",
    "    #print(std)\n",
    "    for i in range(row):\n",
    "        x[i]=(x[i]-mean[i])/std[i]\n",
    "    return x\n",
    "\n",
    "def train_epoch(kii,epoch,train_loader,batch_size,optimizer,loss_func):\n",
    "    BATCH_SIZE=batch_size\n",
    "    total = 0\n",
    "    correct=0\n",
    "    total_loss=0\n",
    "    #loss_score=torch.tensor([[]]).cuda()\n",
    "    #\n",
    "    #loss_op=0\n",
    "    loss2_list=[]\n",
    "    model.train()\n",
    "    total_train_accuracy=0  \n",
    "    BL=nn.BatchNorm1d(input_num)\n",
    "    BL=BL.cuda()\n",
    "    for batch_idx, (x, labels) in enumerate(train_loader):\n",
    "            \n",
    "        labels = Variable(labels)\n",
    "        x = Variable(x)\n",
    "            \n",
    "        x_row,x_col=x.shape   \n",
    "        x=torch.tensor(x,dtype=torch.float)\n",
    "        #print(x.shape)\n",
    "        labels=torch.tensor(labels,dtype=torch.float)\n",
    "        x, labels = x.cuda(), labels.cuda()\n",
    "        labels_int=labels=torch.max(labels,1)[1]#########\n",
    "        #print(labels_int)\n",
    "        #print('labels_int:',labels_int.shape)\n",
    "        #print('labels:',labels) \n",
    "        #print('x:',x.shape)\n",
    "        #xm=x.clone()\n",
    "        xm=x.clone().detach().cuda()\n",
    "        xn=x.clone().detach().cuda()\n",
    "        if kii>=0 : \n",
    "            \n",
    "            inn_model2.evaluate(in_tensor=xn)\n",
    "            #inn_model1.evaluate(in_tensor=xm)\n",
    "            \n",
    "            model_prediction, only_max_score,org_shape = inn_model2.innvestigatex(in_tensor=x)\n",
    "            model_prediction.cuda()\n",
    "            \n",
    "            #model_prediction1, only_max_score1,org_shape1= inn_model1.innvestigatex()\n",
    "            #model_prediction1.cuda()\n",
    "            \n",
    "            only_max_score1=only_max_score.clone().detach()\n",
    "            \n",
    "            \n",
    "            #print('only_max_score:',only_max_score)\n",
    "            #only_max_score1=only_max_score.detach().clone()\n",
    "            #print(labels.shape,labels)   \n",
    "        \n",
    "            #print(\"torch.argmax(labels[batch_idx]):\",torch.argmax(labels[batch_idx]))\n",
    "            #print(model_prediction.shape, model_prediction)\n",
    "            #model_prediction.cuda()\n",
    "            #print('input_relevance_values:')\n",
    "            rel_for_class_list=labels\n",
    "            rel_for_class_list1=labels\n",
    "            para_list=[]\n",
    "            para_orign_list=[0]*batch_size\n",
    "            print('inn_model1')\n",
    "            input_relevance_values1,layers1=inn_model1.compute_relevance_scorex(only_max_score1,rel_for_class_list1,org_shape1,para_orign_list)\n",
    "            ##input_relevance_values1,layers1=inn_model2.compute_relevance_scorex(only_max_score1,rel_for_class_list1,org_shape,para_orign_list)\n",
    "            \n",
    "            \n",
    "            for i in range(batch_size):\n",
    "            \n",
    "                max_pre=torch.argmax(model_prediction[i])\n",
    "                if max_pre!=labels[i]:\n",
    "                    #print('only_max_score1:',i,only_max_score)\n",
    "                    #only_max_score=only_max_score1\n",
    "                    #input_relevance_values=inn_model.compute_relevance_score(only_max_score,labels[i],org_shape,para=0.1)\n",
    "                    #rel_for_class=labels[i]\n",
    "                    #para=random.gauss(0.6,0.3)\n",
    "                    #para=random.gauss(0.3,0.2)#96.8  92.2\n",
    "                    para=0.3\n",
    "                    para_list.append(para)\n",
    "                    #print('device:',input_relevance_values.device)\n",
    "                    #input_relevance_values[labels[i]]=input_relevance_values[labels[i]].cuda()\n",
    "                    #input_relevance_values[labels[i]]=input_relevance_values[labels[i]].exp()\n",
    "                    #print('input_relevance_values:',i, input_relevance_values)\n",
    "                    #print('input_relevance_values[labels[i]]:',i,batch_idx,input_relevance_values[labels[i]])\n",
    "                    #cc[i]=torch.mul(x[i],input_relevance_values[labels[i]])+torch.tensor(0.1,dtype=torch.float)##############注意力\n",
    "                    #print('pre_target:',pre_target[i])\n",
    "                    #print('cc',i,cc[i].shape)\n",
    "                else:\n",
    "                    #print('only_max_score2:',i,only_max_score)\n",
    "                    #only_max_score=only_max_score1\n",
    "                    #input_relevance_values=inn_model.compute_relevance_score(only_max_score,labels[i],org_shape,para=0)\n",
    "                    #input_relevance_values[labels[i]]=input_relevance_values[labels[i]].exp()\n",
    "                    #print('input_relevance_values:',i, input_relevance_values)\n",
    "                    #print('input_relevance_values[i]:',i,batch_idx,input_relevance_values[labels[i]])\n",
    "                    #cc[i]=torch.mul(x[i],input_relevance_values[labels[i]])##############注意力\n",
    "                    #print('cc',i,cc[i].shape)\n",
    "                    para=0\n",
    "                    para_list.append(para)\n",
    "            #print(para_list)\n",
    "            #print(para_orign_list)\n",
    "            input_relevance_values,layers=inn_model2.compute_relevance_scorex(only_max_score,rel_for_class_list,org_shape,para_list)\n",
    "            print('inn_model2')\n",
    "            #input_relevance_values,input_relevance_values1,layers,layers1=inn_model2.compute_relevance_scorey(only_max_score,only_max_score1,rel_for_class_list,org_shape,para_list,para_orign_list)\n",
    "            input_relevance_values[-1]=input_relevance_values[-1].exp()############\n",
    "            input_relevance_values1[-1]=input_relevance_values1[-1].exp()############\n",
    "            \n",
    "            \n",
    "            '''\n",
    "            input_len=len(input_relevance_values)\n",
    "            #input_relevance_values1,layers1=inn_model.compute_relevance_scorex(only_max_score,rel_for_class_list,org_shape,para_orign_list)\n",
    "            ee=[[0]*input_num]*batch_size\n",
    "            ee=torch.tensor(ee,dtype=torch.float)\n",
    "        \n",
    "            ee=ee.cuda()\n",
    "            #sum_input_relevance_values=torch.sum(input_relevance_values,dim=0)\n",
    "            #input_relevance_values=F.softmax(input_relevance_values/sum_input_relevance_values,dim=1)\n",
    "            input_relevance_values[-1]=F.softmax(input_relevance_values[-1],dim=1)################\n",
    "        \n",
    "            \n",
    "            for i in range(batch_size):\n",
    "                        max_pre=torch.argmax(model_prediction[i])######\n",
    "                        if max_pre!=labels[i]: #and i==min_predict_mis:###\n",
    "                            \n",
    "                                \n",
    "            \n",
    "                                ee[i]=torch.mul(x[i],input_relevance_values[-1][i])##############注意力33333333333333333weight\n",
    "                                #dd=torch.mul(bias,input_relevance_values[-1][i])############bias\n",
    "                                #print('cc:',i,cc)\n",
    "                                #ee[i]=torch.mul(x[i],input_relevance_values[-1][i])\n",
    "                                ################\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            #ee=torch.mul(x,input_relevance_values[-1])\n",
    "            \n",
    "            if epoch%3==0:\n",
    "                x=torch.subtract(x,ee)\n",
    "            else:\n",
    "                \n",
    "                x=torch.add(x,ee)\n",
    "        \n",
    "            \n",
    "            \n",
    "            '''\n",
    "            \n",
    "            \n",
    "            \n",
    "            #x=torch.add(x,ee)\n",
    "            \n",
    "            \n",
    "                    \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "              \n",
    "            \n",
    "            \n",
    "                \n",
    "                \n",
    "                \n",
    "                        \n",
    "        \n",
    "        \n",
    "        \n",
    "       \n",
    "        \n",
    "        \n",
    "        \n",
    "         \n",
    "        #print('x_new:',x)\n",
    "        #print('new_x:',x)\n",
    "        optimizer.zero_grad()\n",
    "        y_predict=model(x)\n",
    "        #y_predict=model(x,labels)\n",
    "            \n",
    "        \n",
    "        loss2=torch.abs(input_relevance_values1[-1]-input_relevance_values[-1])\n",
    "        \n",
    "        loss1 = loss_func(y_predict, labels)\n",
    "        #print('loss1:',loss1)\n",
    "        #loss2=loss_func(y_predict1,labels)\n",
    "        #loss2=u*(1/loss_op)\n",
    "        #print('input_relevance_values:',input_relevance_values.shape)\n",
    "        #print('loss_score:',loss_score.shape)\n",
    "        #cc=1.0/torch.abs(torch.sum(cc))\n",
    "        \n",
    "        print('loss1:',loss1)\n",
    "        print('loss2:',loss2)\n",
    "        \n",
    "        \n",
    "        #loss2=u*cc\n",
    "        #print('input_relevance_values:',input_relevance_values)\n",
    "        \n",
    "        #print('loss1:',loss1)\n",
    "        #print('loss2:',loss2)\n",
    "        #loss=loss1+loss2\n",
    "        \n",
    "        u=1\n",
    "        loss=loss1+u*loss2\n",
    "        #loss = loss_func(y_predict, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #loss2_list.append(u*loss2)   \n",
    "        loss = loss.item()\n",
    "           \n",
    "\n",
    "        total_loss += loss\n",
    "            \n",
    "            \n",
    "            \n",
    "        batch_train_acc=torchmetrics.functional.accuracy(y_predict,labels_int)\n",
    "        total_train_accuracy+=batch_train_acc\n",
    "    #plotLoss(loss2_list,batch_idx+1)   #################################     \n",
    "    total_train_accuracy/=(batch_idx+1)\n",
    "    print('total_train_accuracy:',total_train_accuracy)\n",
    "    print(\"Training Epoch: %d, total loss: %f\" % (epoch_id, total_loss))\n",
    "    return total_loss,total_train_accuracy\n",
    "\n",
    "def val_epoch(test_loader,batch_size,optimizer): \n",
    "    batch_size_num=0\n",
    "    total_test_acc=0\n",
    "    model.eval()\n",
    "    for i , (inputs , targets) in enumerate(test_loader):   \n",
    "        print(\"val\")\n",
    "            \n",
    "            \n",
    "        inputs = Variable(inputs)   \n",
    "        targets = Variable(targets)     \n",
    "           \n",
    "        inputs=torch.tensor(inputs ,dtype=torch.float)   \n",
    "        targets=torch.tensor(targets ,dtype=torch.float)   \n",
    "        inputs , targets = inputs.cuda(),  targets.cuda()\n",
    "        targets=torch.max(targets,1)[1]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        #yhat = model1(inputs,targets)\n",
    "        yhat=model(inputs)\n",
    "            \n",
    "            \n",
    "            \n",
    "        #targets=torch.max(targets,1)[1]\n",
    "            \n",
    "            \n",
    "            \n",
    "        batch_test_acc=torchmetrics.functional.accuracy(yhat,targets)\n",
    "            \n",
    "        total_test_acc+=batch_test_acc\n",
    "            \n",
    "        batch_size_num=i\n",
    "    total_test_acc/=(batch_size_num+1)\n",
    "        ###print('total_test_accuracy:',total_test_acc/(batch_size+1))\n",
    "    print('total_test_accuracy:',total_test_acc)\n",
    "        \n",
    "                    \n",
    "                    \n",
    "            \n",
    "            \n",
    "    \n",
    "        \n",
    "   \n",
    "    \n",
    "    return total_test_acc\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plotLoss(loss,epoch):\n",
    "    plt.rcParams['font.sans-serif']=['SimHei']\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    x=[i for i in range(epoch)]\n",
    "    #acc_train=acc_train.cpu()\n",
    "    #acc_test=acc_test.cpu()\n",
    "    plt.plot(x, loss, 'r-', mec='k', label='Logistic Loss', lw=2)\n",
    "    #plt.plot(x,acc_train,'b-',mec='k',label='accuracy Train',lw=2)\n",
    "    #plt.plot(x,acc_test,'g-',mec='k',label='accuracy Test',lw=2)\n",
    "    #plt.plot(x, y_01, 'g-', mec='k', label='0/1 Loss', lw=2)\n",
    "    #plt.plot(x, y_hinge, 'b-',mec='k', label='Hinge Loss', lw=2)\n",
    "    #plt.plot(x, boost, 'm--',mec='k', label='Adaboost Loss',lw=2)\n",
    "    plt.grid(True, ls='--')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('损失函数')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e6c32ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(549, 3301)\n",
      "(549, 3301)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/.local/lib/python3.6/site-packages/ipykernel_launcher.py:442: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/zhengfang/.local/lib/python3.6/site-packages/ipykernel_launcher.py:444: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inn_model1\n",
      "inn_model2\n",
      "m.in_tensor: tensor([[2.3126, 0.0000, 0.5849,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [1.0334, 0.0000, 0.0000,  ..., 3.6688, 3.3960, 0.0000],\n",
      "        [1.2341, 0.0000, 0.0000,  ..., 0.9152, 1.5614, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 1.4285,  ..., 0.0000, 1.7310, 0.5383],\n",
      "        [0.2699, 0.0519, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.1422]],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Linear' object has no attribute 'in_tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d53ebb5fea55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mtrain_loss_total\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mki\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnfm_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mtrain_loss_total_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss_total\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch_id\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-9119edc13dab>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(kii, epoch, train_loader, batch_size, optimizer, loss_func)\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0;31m#input_relevance_values,layers=inn_model.compute_relevance_scorex(only_max_score,rel_for_class_list,org_shape,para_list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inn_model2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m             \u001b[0minput_relevance_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_relevance_values1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayers1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minn_model2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_relevance_scorey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monly_max_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0monly_max_score1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrel_for_class_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0morg_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpara_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpara_orign_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m             \u001b[0minput_relevance_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_relevance_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m############\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m             \u001b[0minput_relevance_values1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_relevance_values1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m############\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NFM-pyorch-master/NFM-pyorch-master/innvestigator.py\u001b[0m in \u001b[0;36mcompute_relevance_scorey\u001b[0;34m(self, only_max_score, only_max_score1, rel_for_class, org_shape, para, para1)\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0;31m#print('relevance:',relevance)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m                 \u001b[0mrelevance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_propagated_relevance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelevance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m                 \u001b[0mrelevance1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_propagated_relevance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelevance1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m                 \u001b[0;31m#print('relevance:',relevance)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m                 \u001b[0mr_values_per_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NFM-pyorch-master/NFM-pyorch-master/inverter_util.py\u001b[0m in \u001b[0;36mcompute_propagated_relevance\u001b[0;34m(self, layer, relevance)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_inverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelevance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             raise NotImplementedError(\"The network contains layers that\"\n",
      "\u001b[0;32m~/NFM-pyorch-master/NFM-pyorch-master/inverter_util.py\u001b[0m in \u001b[0;36mlinear_inverse\u001b[0;34m(self, m, relevance_in)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"e-rule\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'm.in_tensor:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m             \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m-> 1178\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Linear' object has no attribute 'in_tensor'"
     ]
    }
   ],
   "source": [
    "#_,model=MLPA().cuda\n",
    "'''\n",
    "inn_model = InnvestigateModel(model1, lrp_exponent=2,\n",
    "                              method=\"e-rule\",\n",
    "                              beta=.5)\n",
    "\n",
    "'''\n",
    "import itertools\n",
    "num=0\n",
    "K=10\n",
    "test_metrics=[]\n",
    "train_loss_total_list=[]\n",
    "for ki in range(K):\n",
    "    trainset = KZDataset(csv_path='dataset/qiuguan/origin_800/xiaoqiu_xiaoguan/train_val_info.csv',K=K, n_class=nfm_config['n_class'],ki=ki,  typ='train', transform=None, rand=True)\n",
    "    valset = KZDataset(csv_path='dataset/qiuguan/origin_800/xiaoqiu_xiaoguan/train_val_info.csv', K=K,n_class=nfm_config['n_class'],ki=ki,  typ='val', transform=None, rand=True)\n",
    "    train_loader = data.DataLoader(\n",
    "         dataset=trainset,\n",
    "         #transform=torchvision.transforms.ToTensor(),\n",
    "         drop_last=True,\n",
    "         batch_size=nfm_config['batch_size'],\n",
    "         shuffle=True)\n",
    "    val_loader = data.DataLoader(\n",
    "         dataset=valset,\n",
    "         #transform=torchvision.transforms.ToTensor(),\n",
    "         drop_last=True,\n",
    "         batch_size=nfm_config['batch_size']\n",
    "        \n",
    "     )\n",
    "    \n",
    "    model_path='dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/'\n",
    "    #BATCH_SIZE=batch_size\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=nfm_config['lr'], weight_decay=nfm_config['l2_regularization'])\n",
    "    #total = 0\n",
    "    \n",
    "    \n",
    "    loss_func=torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    \n",
    "   \n",
    "    model_named_parameters=[j for j in model.named_parameters()]\n",
    "    #print('model_parameters:',model_named_parameters)\n",
    "    #print('model.state.dict:',model.state_dict())\n",
    "    epoches=101\n",
    "    for epoch_id in range(epoches):\n",
    "          \n",
    "        \n",
    "        \n",
    "        train_loss_total,acc_train=train_epoch(ki,epoch_id,train_loader,nfm_config['batch_size'],optimizer,loss_func)\n",
    "        train_loss_total_list.append(train_loss_total)#\n",
    "        if epoch_id %10==0:\n",
    "            num=num+1\n",
    "            path=os.path.join(model_path,'MLP'+str(num)+str(K)+'.pkl')\n",
    "            torch.save(model.state_dict(),path)\n",
    "    print(\"the \",ki,\" epoch ends\")\n",
    "    plotLoss(train_loss_total_list,epoches)\n",
    "    \n",
    "    train_loss_total_list=[]\n",
    "    acc_test=val_epoch(val_loader,nfm_config['batch_size'],optimizer)\n",
    "    print(\"acc_test_each_k:\",acc_test)\n",
    "    test_metrics.append(acc_test)\n",
    "\n",
    "print(test_metrics)\n",
    "#test_metrics=test_metrics.tolist()\n",
    "test_metrics=[x.cpu().detach().numpy() for x in test_metrics]\n",
    "print(test_metrics)\n",
    "acc_test_metrics=np.mean(test_metrics) \n",
    "print(\"acc_test_metrics:\",acc_test_metrics)\n",
    "\n",
    "#print(list(mlp.named_parameters()))\n",
    "\n",
    "path=os.path.join(model_path,'MLP'+str(num)+str(12345)+'.pkl')\n",
    "torch.save(model.state_dict(),path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eab3e17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 6.], requires_grad=True)\n",
      "tensor([1., 2., 4.], grad_fn=<CopySlices>)\n",
      "tensor([1., 2., 6.])\n",
      "tensor([1., 2., 5.])\n"
     ]
    }
   ],
   "source": [
    "x= torch.tensor([1., 2., 3.], requires_grad=True)\n",
    "clone_x = x.clone()\n",
    "detach_x = x.detach()\n",
    "clone_detach_x = x.clone().detach()\n",
    "\n",
    "clone_x[2]=4\n",
    "clone_detach_x[2]=5\n",
    "detach_x[2]=6\n",
    "print(x)\n",
    "print(clone_x)\n",
    "print(detach_x)\n",
    "print(clone_detach_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9900b6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plotAcc(len_list,acc_score_list):\n",
    "    plt.rcParams['font.sans-serif']=['SimHei']\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    #x=[i for i in range(lenth)]\n",
    "    #acc_train=acc_train.cpu()\n",
    "    #acc_test=acc_test.cpu()\n",
    "    plt.plot(len_list, acc_score_list, 'r-', mec='k', label='Logistic Loss', lw=2)\n",
    "    #plt.plot(x,acc_train,'b-',mec='k',label='accuracy Train',lw=2)\n",
    "    #plt.plot(x,acc_test,'g-',mec='k',label='accuracy Test',lw=2)\n",
    "    #plt.plot(x, y_01, 'g-', mec='k', label='0/1 Loss', lw=2)\n",
    "    #plt.plot(x, y_hinge, 'b-',mec='k', label='Hinge Loss', lw=2)\n",
    "    #plt.plot(x, boost, 'm--',mec='k', label='Adaboost Loss',lw=2)\n",
    "    plt.grid(True, ls='--')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('损失函数')\n",
    "    plt.show()\n",
    "    \n",
    "testset_guan = KZDatasetTest(csv_path='dataset/qiuguan/origin_800/xiaoguan/test_info.csv')\n",
    "   \n",
    "test_loader_guan = data.DataLoader(\n",
    "         dataset=testset_guan,\n",
    "         #transform=torchvision.transforms.ToTensor(),\n",
    "         drop_last=True,\n",
    "         batch_size=nfm_config['batch_size']\n",
    "        \n",
    "     )\n",
    "\n",
    "testset_qiu = KZDatasetTest(csv_path='dataset/qiuguan/origin_800/xiaoqiu/test_info.csv')\n",
    "   \n",
    "test_loader_qiu = data.DataLoader(\n",
    "         dataset=testset_qiu,\n",
    "         #transform=torchvision.transforms.ToTensor(),\n",
    "         drop_last=True,\n",
    "         batch_size=nfm_config['batch_size']\n",
    "        \n",
    "     )\n",
    "input_num=3300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da2bd2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (bn0): BatchNorm1d(3300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=3300, out_features=2000, bias=True)\n",
      "  (bn1): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=2000, out_features=100, bias=True)\n",
      "  (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=100, out_features=9, bias=True)\n",
      "  (bn3): BatchNorm1d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.3, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "##################149特征基因运行后的示意图\n",
    "################################################特征基因个数为300\n",
    "\n",
    "##############小球测试\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "#功能：加载保存到path中的各层参数到神经网络\n",
    "\n",
    "#path='dataset/qiuguan/origin_800/LRP/non_encode/40/attention0/MLP1112345.pkl'\n",
    "\n",
    "#nfm=NFM(nfm_config)\n",
    "mlp=MLP()\n",
    "#print(nfm)\n",
    "#net = nn.DataParallel(net)\n",
    "#net = net.to(device)\n",
    "mlp.load_state_dict(torch.load(path),strict=False)\n",
    "mlp.cuda()\n",
    "\n",
    "print(mlp)\n",
    "\n",
    "\n",
    "#print(model.state_dict())\n",
    "\n",
    "mlp_params = list(mlp.named_parameters())\n",
    "#print(mlp_params)\n",
    "net=mlp\n",
    "\n",
    "\n",
    "#net=model\n",
    "\n",
    "testset_guan = KZDatasetTest(csv_path='dataset/qiuguan/origin_800/xiaoguan/test_info.csv')\n",
    "   \n",
    "test_loader_guan = data.DataLoader(\n",
    "         dataset=testset_guan,\n",
    "         #transform=torchvision.transforms.ToTensor(),\n",
    "         drop_last=True,\n",
    "         batch_size=nfm_config['batch_size']\n",
    "        \n",
    "     )\n",
    "\n",
    "testset_qiu = KZDatasetTest(csv_path='dataset/qiuguan/origin_800/xiaoqiu/test_info.csv')\n",
    "   \n",
    "test_loader_qiu = data.DataLoader(\n",
    "         dataset=testset_qiu,\n",
    "         #transform=torchvision.transforms.ToTensor(),\n",
    "         drop_last=True,\n",
    "         batch_size=nfm_config['batch_size']\n",
    "        \n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29c359fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP11012345.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP6410.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP3910.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP6010.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP9610.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP2810.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP10910.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP8310.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP9510.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP4910.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP5410.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP6510.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP7610.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP7010.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP10010.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP1110.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP10810.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP6610.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP7510.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP3310.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP2510.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP5310.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP3010.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP8910.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP2710.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP4610.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP2110.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP3410.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP610.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP9710.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP9010.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP1510.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP3610.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP6810.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP8710.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP8110.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP4810.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP8610.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP9410.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP210.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP5110.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP1210.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP2610.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP10410.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP2310.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP3210.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP710.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP9210.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP5810.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP4510.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP10610.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP7910.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP9910.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP3110.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP4010.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP10710.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP1710.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP910.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP410.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP7410.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP310.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP7710.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP9810.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP6310.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP6910.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP3710.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP510.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP1010.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP110.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP5010.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP5510.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP3810.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP1610.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP7810.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP8410.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP10210.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP4710.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP5610.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP10310.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP4110.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP10510.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP8210.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP10110.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP4210.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP8510.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP6710.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP7110.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP7310.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP5210.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP5910.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP4310.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP3510.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP5710.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP4410.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP1910.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP810.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP6110.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP8810.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP9110.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP6210.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP2010.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP1310.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP2910.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP8010.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP1810.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP2210.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP9310.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP11010.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP1410.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP7210.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP2410.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "0.890625\n",
      "30 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP9010.pkl 0.890625\n",
      "51 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP7910.pkl 0.890625\n",
      "82 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP10110.pkl 0.890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 25439 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 22833 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 20989 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 25968 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 25439 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 22833 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 20989 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 25968 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PlotCurves import plotGraph,plotLoss,plotMatrix\n",
    "from train_val_test import evaluate_model\n",
    "import os\n",
    "path_dir='dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/'\n",
    "mlp=MLP()\n",
    "path_list=[]\n",
    "acc_score_list=[]\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score,roc_curve, auc, precision_score, recall_score, f1_score, confusion_matrix, accuracy_score \n",
    "pos=0\n",
    "for parent, _, files in os.walk(path_dir):\n",
    "    pathes=files\n",
    "for path_ in pathes:\n",
    "    if path_.startswith('MLP'):  # 去除隐藏文件\n",
    "\n",
    "\n",
    "        \n",
    "        path=os.path.join(path_dir,path_)\n",
    "        print(path)\n",
    "        mlp.load_state_dict(torch.load(path),strict=False)\n",
    "        mlp.cuda()\n",
    "\n",
    "        net=mlp\n",
    "        actuals,predictions,acc_test=evaluate_model(test_loader_guan,net,input_num)\n",
    "\n",
    "       \n",
    "        target_list=actuals \n",
    "        pred_list=predictions \n",
    "      \n",
    "        y_true=target_list \n",
    "        y_pred=pred_list \n",
    "      \n",
    "\n",
    "        acc_score=accuracy_score(y_true=target_list, y_pred=pred_list) \n",
    "\n",
    "        acc_score_list.append(acc_score)\n",
    "        path_list.append(path)\n",
    "        pos=pos+1\n",
    "max_guan=max(acc_score_list)\n",
    "print(max_guan)\n",
    "#max_len=len(max_qiu)\n",
    "max_guan_list=[]\n",
    "max_guan_len_list=[]\n",
    "for i,score in enumerate(acc_score_list):\n",
    "    \n",
    "    if score==max_guan:\n",
    "        print(i,path_list[i],score)\n",
    "        \n",
    "        max_guan_list.append(score)\n",
    "        max_guan_len_list.append(i)\n",
    "#lenth=len(acc_score_list)\n",
    "\n",
    "plotAcc(max_guan_len_list,max_guan_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d26dd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP11012345.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP6410.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP3910.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP6010.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP9610.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP2810.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP10910.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP8310.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP9510.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP4910.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP5410.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP6510.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP7610.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP7010.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP10010.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP1110.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP10810.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP6610.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP7510.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP3310.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP2510.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP5310.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP3010.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP8910.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP2710.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP4610.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP2110.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP3410.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP610.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP9710.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP9010.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP1510.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP3610.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP6810.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP8710.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP8110.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP4810.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP8610.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP9410.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP210.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP5110.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP1210.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP2610.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP10410.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP2310.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP3210.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP710.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP9210.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP5810.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP4510.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP10610.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP7910.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP9910.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP3110.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP4010.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP10710.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP1710.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP910.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP410.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP7410.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP310.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP7710.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP9810.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP6310.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP6910.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP3710.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP510.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP1010.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP110.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP5010.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP5510.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP3810.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP1610.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP7810.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP8410.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP10210.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP4710.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP5610.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP10310.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP4110.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP10510.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP8210.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP10110.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP4210.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP8510.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP6710.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP7110.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP7310.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP5210.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP5910.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP4310.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP3510.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP5710.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP4410.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP1910.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP810.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP6110.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP8810.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP9110.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP6210.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP2010.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP1310.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP2910.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP8010.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP1810.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP2210.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP9310.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP11010.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP1410.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP7210.pkl\n",
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP2410.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "0.953125\n",
      "0 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP11012345.pkl 0.953125\n",
      "1 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP6410.pkl 0.953125\n",
      "2 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP3910.pkl 0.953125\n",
      "3 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP6010.pkl 0.953125\n",
      "4 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP9610.pkl 0.953125\n",
      "5 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP2810.pkl 0.953125\n",
      "7 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP8310.pkl 0.953125\n",
      "8 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP9510.pkl 0.953125\n",
      "9 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP4910.pkl 0.953125\n",
      "11 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP6510.pkl 0.953125\n",
      "12 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP7610.pkl 0.953125\n",
      "13 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP7010.pkl 0.953125\n",
      "14 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP10010.pkl 0.953125\n",
      "16 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP10810.pkl 0.953125\n",
      "17 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP6610.pkl 0.953125\n",
      "18 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP7510.pkl 0.953125\n",
      "19 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP3310.pkl 0.953125\n",
      "20 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP2510.pkl 0.953125\n",
      "22 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP3010.pkl 0.953125\n",
      "24 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP2710.pkl 0.953125\n",
      "25 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP4610.pkl 0.953125\n",
      "27 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP3410.pkl 0.953125\n",
      "32 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP3610.pkl 0.953125\n",
      "33 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP6810.pkl 0.953125\n",
      "35 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP8110.pkl 0.953125\n",
      "36 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP4810.pkl 0.953125\n",
      "38 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP9410.pkl 0.953125\n",
      "40 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP5110.pkl 0.953125\n",
      "45 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP3210.pkl 0.953125\n",
      "48 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP5810.pkl 0.953125\n",
      "50 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP10610.pkl 0.953125\n",
      "51 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP7910.pkl 0.953125\n",
      "52 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP9910.pkl 0.953125\n",
      "53 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP3110.pkl 0.953125\n",
      "54 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP4010.pkl 0.953125\n",
      "55 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP10710.pkl 0.953125\n",
      "59 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP7410.pkl 0.953125\n",
      "61 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP7710.pkl 0.953125\n",
      "62 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP9810.pkl 0.953125\n",
      "63 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP6310.pkl 0.953125\n",
      "64 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP6910.pkl 0.953125\n",
      "65 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP3710.pkl 0.953125\n",
      "71 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP3810.pkl 0.953125\n",
      "72 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP1610.pkl 0.953125\n",
      "73 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP7810.pkl 0.953125\n",
      "76 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP4710.pkl 0.953125\n",
      "79 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP4110.pkl 0.953125\n",
      "80 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP10510.pkl 0.953125\n",
      "81 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP8210.pkl 0.953125\n",
      "85 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP6710.pkl 0.953125\n",
      "86 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP7110.pkl 0.953125\n",
      "87 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP7310.pkl 0.953125\n",
      "89 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP5910.pkl 0.953125\n",
      "90 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP4310.pkl 0.953125\n",
      "91 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP3510.pkl 0.953125\n",
      "94 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP1910.pkl 0.953125\n",
      "96 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP6110.pkl 0.953125\n",
      "99 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP6210.pkl 0.953125\n",
      "103 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP8010.pkl 0.953125\n",
      "106 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP9310.pkl 0.953125\n",
      "107 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP11010.pkl 0.953125\n",
      "108 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP1410.pkl 0.953125\n",
      "109 dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/MLP7210.pkl 0.953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 25439 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 22833 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 20989 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 25968 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 25439 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 22833 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 20989 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/home/zhengfang/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 25968 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_dir='dataset/qiuguan/origin_800/non_encode_attention/para0.4_0.4/'\n",
    "mlp=MLP()\n",
    "acc_score_list=[]\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score,roc_curve, auc, precision_score, recall_score, f1_score, confusion_matrix, accuracy_score \n",
    "pos=0\n",
    "path_list=[]\n",
    "for parent, _, files in os.walk(path_dir):\n",
    "    pathes=files\n",
    "for path_ in pathes:\n",
    "    if path_.startswith('ML'):  # 去除隐藏文件\n",
    "\n",
    "\n",
    "        #print(path)\n",
    "        path=os.path.join(path_dir,path_)\n",
    "        print(path)\n",
    "        mlp.load_state_dict(torch.load(path),strict=False)\n",
    "        mlp.cuda()\n",
    "\n",
    "        net=mlp\n",
    "        actuals,predictions,acc_test=evaluate_model(test_loader_qiu,net,input_num)\n",
    "\n",
    "       \n",
    "        target_list=actuals \n",
    "        pred_list=predictions \n",
    "      \n",
    "        y_true=target_list \n",
    "        y_pred=pred_list \n",
    "      \n",
    "\n",
    "        acc_score=accuracy_score(y_true=target_list, y_pred=pred_list) \n",
    "\n",
    "        acc_score_list.append(acc_score)\n",
    "        path_list.append(path)\n",
    "        pos=pos+1\n",
    "        \n",
    "max_qiu=max(acc_score_list)\n",
    "print(max_qiu)\n",
    "#max_len=len(max_qiu)\n",
    "max_qiu_list=[]\n",
    "max_qiu_len_list=[]\n",
    "\n",
    "\n",
    "for i,score in enumerate(acc_score_list):\n",
    "    \n",
    "    if score==max_qiu:\n",
    "        print(i,path_list[i],score)\n",
    "        \n",
    "        max_qiu_list.append(score)\n",
    "        max_qiu_len_list.append(i)\n",
    "#lenth=len(acc_score_list)\n",
    "\n",
    "plotAcc(max_qiu_len_list,max_qiu_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7812de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################149特征基因运行后的示意图\n",
    "################################################特征基因个数为300\n",
    "\n",
    "##############小球测试\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "#功能：加载保存到path中的各层参数到神经网络\n",
    "\n",
    "path='dataset/qiuguan/origin_800/LRP/non_encode/40/attention0/MLP1810.pkl'\n",
    "\n",
    "#nfm=NFM(nfm_config)\n",
    "mlp=MLP()\n",
    "#print(nfm)\n",
    "#net = nn.DataParallel(net)\n",
    "#net = net.to(device)\n",
    "mlp.load_state_dict(torch.load(path),strict=False)\n",
    "mlp.cuda()\n",
    "\n",
    "print(mlp)\n",
    "\n",
    "\n",
    "#print(model.state_dict())\n",
    "\n",
    "mlp_params = list(mlp.named_parameters())\n",
    "#print(mlp_params)\n",
    "net=mlp\n",
    "\n",
    "\n",
    "#net=model\n",
    "\n",
    "testset_guan = KZDatasetTest(csv_path='dataset/qiuguan/origin_800/LRP/40/selected_xiaoguan_test_info.csv')\n",
    "   \n",
    "test_loader_guan = data.DataLoader(\n",
    "         dataset=testset_guan,\n",
    "         #transform=torchvision.transforms.ToTensor(),\n",
    "         drop_last=True,\n",
    "         batch_size=nfm_config['batch_size']\n",
    "        \n",
    "     )\n",
    "\n",
    "testset_qiu = KZDatasetTest(csv_path='dataset/qiuguan/origin_800/LRP/40/selected_xiaoqiu_test_info.csv')\n",
    "   \n",
    "test_loader_qiu = data.DataLoader(\n",
    "         dataset=testset_qiu,\n",
    "         #transform=torchvision.transforms.ToTensor(),\n",
    "         drop_last=True,\n",
    "         batch_size=nfm_config['batch_size']\n",
    "        \n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "04626c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "f1_score:  %.4f 0.9393194314762943\n",
      "accuracy_score: 0.953125\n",
      "recall_score: 0.9314814814814815\n",
      "pre_recall: 0.9552469135802468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'roc_auc_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-cf3dc0bd59c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mactuals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader_guan\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#print(actuals, predictions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplotGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactuals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/NFM-pyorch-master/NFM-pyorch-master/PlotCurves.py\u001b[0m in \u001b[0;36mplotGraph\u001b[0;34m(actuals, predictions, acc_test)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mauc_curve\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ovo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0;31m#————————————————\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;31m#版权声明：本文为CSDN博主「农民小飞侠」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'roc_auc_score' is not defined"
     ]
    }
   ],
   "source": [
    "from PlotCurves import plotGraph,plotLoss,plotMatrix\n",
    "from train_val_test import evaluate_model\n",
    "\n",
    "actuals,predictions,acc_test=evaluate_model(test_loader_guan,net,input_num)\n",
    "#print(actuals, predictions)\n",
    "plotGraph(actuals,predictions,acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "668d8d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acturals: (64, 9)\n",
      "yhat: (64, 9)\n",
      "f1_score:  %.4f 0.9387328720662054\n",
      "accuracy_score: 0.9375\n",
      "recall_score: 0.9500000000000001\n",
      "pre_recall: 0.9444444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:374: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs=torch.tensor(inputs,dtype=torch.float)\n",
      "/home/zhengfang/NFM-pyorch-master/NFM-pyorch-master/train_val_test.py:376: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets=torch.tensor(targets,dtype=torch.float)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'roc_auc_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-27ba3e3dcbf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mactuals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader_qiu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplotGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactuals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/NFM-pyorch-master/NFM-pyorch-master/PlotCurves.py\u001b[0m in \u001b[0;36mplotGraph\u001b[0;34m(actuals, predictions, acc_test)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mauc_curve\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ovo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0;31m#————————————————\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;31m#版权声明：本文为CSDN博主「农民小飞侠」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'roc_auc_score' is not defined"
     ]
    }
   ],
   "source": [
    "actuals,predictions,acc_test=evaluate_model(test_loader_qiu,net,input_num)\n",
    "plotGraph(actuals,predictions,acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0a0f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
