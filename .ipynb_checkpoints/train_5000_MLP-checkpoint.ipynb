{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d22fd377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  as pt\n",
    "from torch import nn\n",
    "import torch.nn.functional as F  # 激励函数的库\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96884dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#import Trainer\n",
    "\n",
    "import torch.utils.data as Data\n",
    "#from Utils.criteo_loader import getTestData, getTrainData\n",
    "\n",
    "nfm_config = \\\n",
    "{\n",
    "    'n_class':9,\n",
    "    'linear_hidden1':1000,\n",
    "    'linear_hidden':100,#线性模型输出层（隐层个数）\n",
    "    'embed_input_dim':1001,#embed输入维度\n",
    "    'embed_dim': 100, # 用于控制稀疏特征经过Embedding层后的稠密特征大小，embed输出维度\n",
    "    #'dnn_hidden_units': [100,11],#MLP隐层和输出层\n",
    "    \n",
    "    'dnn_hidden_units':[100,9],#MLP隐层\n",
    "    'num_sparse_features_cols':5510,#the number of the gene columns\n",
    "    'num_dense_features': 0,#dense features number\n",
    "    'bi_dropout': 0.3,#Bi-Interaction 的dropout\n",
    "    'num_epoch': 500,#训练epoch次数\n",
    "    'batch_size': 100,#batch_size\n",
    "    'lr': 1e-3,\n",
    "    'l2_regularization': 1e-4,\n",
    "    'device_id': 0,\n",
    "    'use_cuda': False,\n",
    "    \n",
    "    #'train_file': '../Data/criteo/processed_data/train_set.csv',\n",
    "    #'fea_file': '../Data/criteo/processed_data/fea_col.npy',\n",
    "    #'validate_file': '../Data/criteo/processed_data/val_set.csv',\n",
    "    #'test_file': '../Data/criteo/processed_data/test_set.csv',\n",
    "    #'model_name': '../TrainedModels/NFM.model'\n",
    "    'train_non_em':'data/xiaoqiu_gene_5000/train/gene_5000_data.csv',\n",
    "    'train_file':'data/xiaoqiu_gene_5000/train/final_5000_encode_100x.csv',\n",
    "    'label_file':'data/xiaoqiu_gene_5000/train/gene_5000_labels.csv',\n",
    "    'test_file':'data/frappe/gene_4000/test/test_file.csv',\n",
    "    'test_label':'data/frappe/gene_4000/test/test_label.csv',\n",
    "    'title':'data/xiaoqiu_gene_5000/train/gene_5000_gene_name.csv',\n",
    "    'all':'data/xiaoqiu_gene_5000/train/gene_5000_label_name.csv'\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8df48443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (fc1): Linear(in_features=5510, out_features=1000, bias=True)\n",
      "  (bn1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=1000, out_features=100, bias=True)\n",
      "  (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=100, out_features=9, bias=True)\n",
      "  (bn3): BatchNorm1d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#model definition\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(5510, 1000)\n",
    "        self.bn1= nn.BatchNorm1d(1000)\n",
    "        self.fc2 = nn.Linear(1000, 100)\n",
    "        self.bn2=nn.BatchNorm1d(100)\n",
    "        self.fc3 = nn.Linear(100, 9)\n",
    "        self.bn3=nn.BatchNorm1d(9)\n",
    "        self.drop=nn.Dropout(0.5)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.drop(self.bn1(self.fc1(x))))\n",
    "        x = F.relu(self.drop(self.bn2(self.fc2(x))))\n",
    "        return F.softmax(self.bn3(self.fc3(x)), dim=1)\n",
    "model = MLP().cuda()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4806bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1194834",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def one_hot(labels, classes):\n",
    "    n = len(labels)\n",
    "    #eoff = label_smoothing / classes\n",
    "    output = np.zeros((n, classes), dtype=np.float32)\n",
    "    for row, label in enumerate(labels):\n",
    "        output[row, label] = 1 \n",
    "        print(\"row:\",row,\"label:\",label)\n",
    "    return output\n",
    "'''\n",
    "\n",
    "\n",
    "def one_hot(labels, classes, label_smoothing=0.2):\n",
    "    n = len(labels)\n",
    "    eoff = label_smoothing / classes\n",
    "    output = np.ones((n, classes), dtype=np.float32) * eoff\n",
    "    for row, label in enumerate(labels):\n",
    "        output[row, label] = 1 - label_smoothing + eoff\n",
    "        print(\"row:\",row,\"label:\",label)\n",
    "    return output\n",
    "\n",
    "\n",
    "class FMData(data.Dataset):\n",
    "    \"\"\" Construct the FM pytorch dataset. \"\"\"\n",
    "    #def __init__(self, file,label_file, feature_map,n_class=16):\n",
    "    def __init__(self, file,label_file, n_class):\n",
    "        super(FMData, self).__init__()\n",
    "        self.label = []\n",
    "        self.features = []\n",
    "        #self.feature_values = []\n",
    "        \n",
    "        features=[]\n",
    "        #feature_map.keys()\n",
    "        #self.features=np.array(feature_map)\n",
    "        #feature_map\n",
    "        #file=\"data/frappe/c_df_v_fff2000.csv\"\n",
    "        #num = len(features)\n",
    "        fd=pd.read_csv(file,sep=',')\n",
    "        #nrow=fd.shape[0]\n",
    "        #ncol=fd.shape[1]\n",
    "        n_fd=np.array(fd,dtype=np.float32)\n",
    "        #print(n_fd)\n",
    "        #n_fd=n_fd[:,1:]\n",
    "        \n",
    "        \"\"\"\n",
    "        for i, item in enumerate(n_fd):\n",
    "            u=[feature_map[x] for x in item]\n",
    "            features.append(u)\n",
    "        \"\"\"\n",
    "        \n",
    "        self.features=np.array(n_fd)\n",
    "        #self.features=self.features\n",
    "        \n",
    "        \n",
    "        nrow,ncol=n_fd.shape\n",
    "        #ncol=10150\n",
    "        #feature_v=[]\n",
    "        \"\"\"\n",
    "            feature_v=[1 for i in range(ncol)]\n",
    "            #print(feature_v)\n",
    "            #feature_values=[feature_v for j in range(nrow)]\n",
    "\n",
    "            for item in range(nrow):\n",
    "            feature_values.append(feature_v)\n",
    "        \"\"\"\n",
    "\n",
    "        #feature_v=[[1 for i in range(ncol)] for i in range(nrow)]\n",
    "        #self.feature_values=np.array(feature_v)\n",
    "        #print(feature_value)\n",
    "        #self.feature_values=feature_value.tolist()\n",
    "        #feature_map,lenth=map_features()\n",
    "        #raw = [item for item in  enumerate(n_fd)]\n",
    "        #print(raw)\n",
    "        #raw=raw.tolist()\n",
    "        \n",
    "        #label_file=[]\n",
    "        label_fd=pd.read_csv(label_file,sep=',')\n",
    "        #print(features)\n",
    "        #print(label_fd)\n",
    "        #label=pd.get_dummies(label_fd)\n",
    "        label=np.array(label_fd)\n",
    "        #label=label[:,1:]\n",
    "        label=one_hot(label,n_class)\n",
    "        #label=F.one_hot(tensor, num_classes=- 1) \n",
    "        self.label=label\n",
    "        print(\"label:\",label)\n",
    "        print(\"features:\",self.features)\n",
    "        print(\"label.shape:\",self.label.shape)\n",
    "        print(\"features.shape:\",self.features.shape)\n",
    "        #print(label)\n",
    "        # convert labels\n",
    "        \"\"\"if config.loss_type == 'square_loss':\n",
    "            self.label.append(np.float32(items[0]))\n",
    "        else: # log_loss\n",
    "            label = 1 if float(items[0]) > 0 else 0\n",
    "            self.label.append(label)\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        assert all(len(item) == len(self.features[0]\n",
    "            ) for item in self.features), 'features are of different length'\n",
    "        \"\"\"\n",
    "        #print(len(self.features))\n",
    "        #print(len(self.feature_values))\n",
    "        #print(len(self.label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.label[idx]\n",
    "        features = self.features[idx]\n",
    "        #feature_values = self.feature_values[idx]\n",
    "        #return features, feature_values, label\n",
    "        return features,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f152874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row: 0 label: [0]\n",
      "row: 1 label: [0]\n",
      "row: 2 label: [0]\n",
      "row: 3 label: [0]\n",
      "row: 4 label: [0]\n",
      "row: 5 label: [0]\n",
      "row: 6 label: [0]\n",
      "row: 7 label: [0]\n",
      "row: 8 label: [0]\n",
      "row: 9 label: [0]\n",
      "row: 10 label: [0]\n",
      "row: 11 label: [0]\n",
      "row: 12 label: [0]\n",
      "row: 13 label: [0]\n",
      "row: 14 label: [0]\n",
      "row: 15 label: [0]\n",
      "row: 16 label: [0]\n",
      "row: 17 label: [0]\n",
      "row: 18 label: [0]\n",
      "row: 19 label: [0]\n",
      "row: 20 label: [1]\n",
      "row: 21 label: [1]\n",
      "row: 22 label: [1]\n",
      "row: 23 label: [1]\n",
      "row: 24 label: [1]\n",
      "row: 25 label: [1]\n",
      "row: 26 label: [1]\n",
      "row: 27 label: [1]\n",
      "row: 28 label: [1]\n",
      "row: 29 label: [1]\n",
      "row: 30 label: [1]\n",
      "row: 31 label: [1]\n",
      "row: 32 label: [1]\n",
      "row: 33 label: [1]\n",
      "row: 34 label: [1]\n",
      "row: 35 label: [1]\n",
      "row: 36 label: [1]\n",
      "row: 37 label: [1]\n",
      "row: 38 label: [1]\n",
      "row: 39 label: [1]\n",
      "row: 40 label: [1]\n",
      "row: 41 label: [1]\n",
      "row: 42 label: [1]\n",
      "row: 43 label: [1]\n",
      "row: 44 label: [1]\n",
      "row: 45 label: [1]\n",
      "row: 46 label: [2]\n",
      "row: 47 label: [2]\n",
      "row: 48 label: [2]\n",
      "row: 49 label: [2]\n",
      "row: 50 label: [2]\n",
      "row: 51 label: [2]\n",
      "row: 52 label: [2]\n",
      "row: 53 label: [2]\n",
      "row: 54 label: [2]\n",
      "row: 55 label: [2]\n",
      "row: 56 label: [2]\n",
      "row: 57 label: [2]\n",
      "row: 58 label: [2]\n",
      "row: 59 label: [2]\n",
      "row: 60 label: [2]\n",
      "row: 61 label: [2]\n",
      "row: 62 label: [2]\n",
      "row: 63 label: [2]\n",
      "row: 64 label: [2]\n",
      "row: 65 label: [2]\n",
      "row: 66 label: [2]\n",
      "row: 67 label: [2]\n",
      "row: 68 label: [2]\n",
      "row: 69 label: [2]\n",
      "row: 70 label: [2]\n",
      "row: 71 label: [2]\n",
      "row: 72 label: [2]\n",
      "row: 73 label: [2]\n",
      "row: 74 label: [2]\n",
      "row: 75 label: [2]\n",
      "row: 76 label: [2]\n",
      "row: 77 label: [2]\n",
      "row: 78 label: [2]\n",
      "row: 79 label: [2]\n",
      "row: 80 label: [2]\n",
      "row: 81 label: [2]\n",
      "row: 82 label: [2]\n",
      "row: 83 label: [2]\n",
      "row: 84 label: [2]\n",
      "row: 85 label: [2]\n",
      "row: 86 label: [3]\n",
      "row: 87 label: [3]\n",
      "row: 88 label: [3]\n",
      "row: 89 label: [3]\n",
      "row: 90 label: [3]\n",
      "row: 91 label: [3]\n",
      "row: 92 label: [3]\n",
      "row: 93 label: [3]\n",
      "row: 94 label: [3]\n",
      "row: 95 label: [3]\n",
      "row: 96 label: [3]\n",
      "row: 97 label: [3]\n",
      "row: 98 label: [3]\n",
      "row: 99 label: [3]\n",
      "row: 100 label: [3]\n",
      "row: 101 label: [3]\n",
      "row: 102 label: [3]\n",
      "row: 103 label: [3]\n",
      "row: 104 label: [3]\n",
      "row: 105 label: [3]\n",
      "row: 106 label: [3]\n",
      "row: 107 label: [3]\n",
      "row: 108 label: [3]\n",
      "row: 109 label: [3]\n",
      "row: 110 label: [3]\n",
      "row: 111 label: [3]\n",
      "row: 112 label: [3]\n",
      "row: 113 label: [3]\n",
      "row: 114 label: [3]\n",
      "row: 115 label: [3]\n",
      "row: 116 label: [3]\n",
      "row: 117 label: [3]\n",
      "row: 118 label: [3]\n",
      "row: 119 label: [4]\n",
      "row: 120 label: [4]\n",
      "row: 121 label: [4]\n",
      "row: 122 label: [4]\n",
      "row: 123 label: [4]\n",
      "row: 124 label: [4]\n",
      "row: 125 label: [4]\n",
      "row: 126 label: [4]\n",
      "row: 127 label: [4]\n",
      "row: 128 label: [4]\n",
      "row: 129 label: [4]\n",
      "row: 130 label: [4]\n",
      "row: 131 label: [4]\n",
      "row: 132 label: [4]\n",
      "row: 133 label: [4]\n",
      "row: 134 label: [4]\n",
      "row: 135 label: [4]\n",
      "row: 136 label: [4]\n",
      "row: 137 label: [4]\n",
      "row: 138 label: [4]\n",
      "row: 139 label: [4]\n",
      "row: 140 label: [4]\n",
      "row: 141 label: [4]\n",
      "row: 142 label: [4]\n",
      "row: 143 label: [4]\n",
      "row: 144 label: [4]\n",
      "row: 145 label: [4]\n",
      "row: 146 label: [4]\n",
      "row: 147 label: [4]\n",
      "row: 148 label: [4]\n",
      "row: 149 label: [4]\n",
      "row: 150 label: [4]\n",
      "row: 151 label: [4]\n",
      "row: 152 label: [4]\n",
      "row: 153 label: [4]\n",
      "row: 154 label: [4]\n",
      "row: 155 label: [4]\n",
      "row: 156 label: [4]\n",
      "row: 157 label: [4]\n",
      "row: 158 label: [4]\n",
      "row: 159 label: [4]\n",
      "row: 160 label: [4]\n",
      "row: 161 label: [4]\n",
      "row: 162 label: [4]\n",
      "row: 163 label: [4]\n",
      "row: 164 label: [4]\n",
      "row: 165 label: [4]\n",
      "row: 166 label: [4]\n",
      "row: 167 label: [4]\n",
      "row: 168 label: [4]\n",
      "row: 169 label: [4]\n",
      "row: 170 label: [4]\n",
      "row: 171 label: [4]\n",
      "row: 172 label: [5]\n",
      "row: 173 label: [5]\n",
      "row: 174 label: [5]\n",
      "row: 175 label: [5]\n",
      "row: 176 label: [5]\n",
      "row: 177 label: [5]\n",
      "row: 178 label: [5]\n",
      "row: 179 label: [5]\n",
      "row: 180 label: [5]\n",
      "row: 181 label: [5]\n",
      "row: 182 label: [5]\n",
      "row: 183 label: [5]\n",
      "row: 184 label: [5]\n",
      "row: 185 label: [5]\n",
      "row: 186 label: [5]\n",
      "row: 187 label: [5]\n",
      "row: 188 label: [5]\n",
      "row: 189 label: [5]\n",
      "row: 190 label: [5]\n",
      "row: 191 label: [5]\n",
      "row: 192 label: [5]\n",
      "row: 193 label: [5]\n",
      "row: 194 label: [5]\n",
      "row: 195 label: [5]\n",
      "row: 196 label: [5]\n",
      "row: 197 label: [5]\n",
      "row: 198 label: [5]\n",
      "row: 199 label: [6]\n",
      "row: 200 label: [6]\n",
      "row: 201 label: [6]\n",
      "row: 202 label: [6]\n",
      "row: 203 label: [6]\n",
      "row: 204 label: [6]\n",
      "row: 205 label: [6]\n",
      "row: 206 label: [6]\n",
      "row: 207 label: [6]\n",
      "row: 208 label: [6]\n",
      "row: 209 label: [6]\n",
      "row: 210 label: [6]\n",
      "row: 211 label: [6]\n",
      "row: 212 label: [6]\n",
      "row: 213 label: [6]\n",
      "row: 214 label: [6]\n",
      "row: 215 label: [6]\n",
      "row: 216 label: [6]\n",
      "row: 217 label: [6]\n",
      "row: 218 label: [6]\n",
      "row: 219 label: [6]\n",
      "row: 220 label: [6]\n",
      "row: 221 label: [6]\n",
      "row: 222 label: [6]\n",
      "row: 223 label: [6]\n",
      "row: 224 label: [6]\n",
      "row: 225 label: [6]\n",
      "row: 226 label: [6]\n",
      "row: 227 label: [6]\n",
      "row: 228 label: [6]\n",
      "row: 229 label: [6]\n",
      "row: 230 label: [6]\n",
      "row: 231 label: [6]\n",
      "row: 232 label: [6]\n",
      "row: 233 label: [6]\n",
      "row: 234 label: [6]\n",
      "row: 235 label: [6]\n",
      "row: 236 label: [6]\n",
      "row: 237 label: [6]\n",
      "row: 238 label: [6]\n",
      "row: 239 label: [6]\n",
      "row: 240 label: [6]\n",
      "row: 241 label: [7]\n",
      "row: 242 label: [7]\n",
      "row: 243 label: [7]\n",
      "row: 244 label: [7]\n",
      "row: 245 label: [7]\n",
      "row: 246 label: [7]\n",
      "row: 247 label: [7]\n",
      "row: 248 label: [7]\n",
      "row: 249 label: [7]\n",
      "row: 250 label: [7]\n",
      "row: 251 label: [7]\n",
      "row: 252 label: [7]\n",
      "row: 253 label: [7]\n",
      "row: 254 label: [7]\n",
      "row: 255 label: [7]\n",
      "row: 256 label: [7]\n",
      "row: 257 label: [7]\n",
      "row: 258 label: [7]\n",
      "row: 259 label: [7]\n",
      "row: 260 label: [7]\n",
      "row: 261 label: [7]\n",
      "row: 262 label: [7]\n",
      "row: 263 label: [7]\n",
      "row: 264 label: [7]\n",
      "row: 265 label: [7]\n",
      "row: 266 label: [7]\n",
      "row: 267 label: [7]\n",
      "row: 268 label: [7]\n",
      "row: 269 label: [7]\n",
      "row: 270 label: [7]\n",
      "row: 271 label: [7]\n",
      "row: 272 label: [7]\n",
      "row: 273 label: [7]\n",
      "row: 274 label: [7]\n",
      "row: 275 label: [7]\n",
      "row: 276 label: [7]\n",
      "row: 277 label: [7]\n",
      "row: 278 label: [7]\n",
      "row: 279 label: [7]\n",
      "row: 280 label: [7]\n",
      "row: 281 label: [7]\n",
      "row: 282 label: [7]\n",
      "row: 283 label: [7]\n",
      "row: 284 label: [7]\n",
      "row: 285 label: [7]\n",
      "row: 286 label: [8]\n",
      "row: 287 label: [8]\n",
      "row: 288 label: [8]\n",
      "row: 289 label: [8]\n",
      "row: 290 label: [8]\n",
      "row: 291 label: [8]\n",
      "row: 292 label: [8]\n",
      "row: 293 label: [8]\n",
      "row: 294 label: [8]\n",
      "row: 295 label: [8]\n",
      "row: 296 label: [8]\n",
      "row: 297 label: [8]\n",
      "row: 298 label: [8]\n",
      "row: 299 label: [8]\n",
      "row: 300 label: [8]\n",
      "row: 301 label: [8]\n",
      "row: 302 label: [8]\n",
      "row: 303 label: [8]\n",
      "row: 304 label: [8]\n",
      "row: 305 label: [8]\n",
      "row: 306 label: [8]\n",
      "row: 307 label: [8]\n",
      "row: 308 label: [8]\n",
      "row: 309 label: [8]\n",
      "row: 310 label: [8]\n",
      "row: 311 label: [8]\n",
      "row: 312 label: [8]\n",
      "row: 313 label: [8]\n",
      "row: 314 label: [8]\n",
      "row: 315 label: [8]\n",
      "row: 316 label: [8]\n",
      "row: 317 label: [8]\n",
      "row: 318 label: [8]\n",
      "row: 319 label: [8]\n",
      "row: 320 label: [8]\n",
      "row: 321 label: [8]\n",
      "row: 322 label: [8]\n",
      "row: 323 label: [8]\n",
      "row: 324 label: [8]\n",
      "row: 325 label: [8]\n",
      "row: 326 label: [8]\n",
      "row: 327 label: [8]\n",
      "row: 328 label: [8]\n",
      "row: 329 label: [8]\n",
      "row: 330 label: [8]\n",
      "row: 331 label: [8]\n",
      "row: 332 label: [8]\n",
      "row: 333 label: [8]\n",
      "row: 334 label: [8]\n",
      "row: 335 label: [8]\n",
      "row: 336 label: [8]\n",
      "row: 337 label: [8]\n",
      "row: 338 label: [8]\n",
      "row: 339 label: [8]\n",
      "row: 340 label: [8]\n",
      "row: 341 label: [8]\n",
      "row: 342 label: [8]\n",
      "row: 343 label: [8]\n",
      "row: 344 label: [8]\n",
      "row: 345 label: [8]\n",
      "row: 346 label: [8]\n",
      "row: 347 label: [8]\n",
      "label: [[0.82222223 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]\n",
      " [0.82222223 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]\n",
      " [0.82222223 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]\n",
      " ...\n",
      " [0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.82222223]\n",
      " [0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.82222223]\n",
      " [0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.82222223]]\n",
      "features: [[12.272698   6.0499754  6.02051   ...  7.7617745  5.09314    6.9558606]\n",
      " [11.729695   5.878152   5.815433  ...  7.0375776  5.4506707  7.070001 ]\n",
      " [12.279739   6.0124116  5.6950674 ...  8.078528   5.3745875  7.2418165]\n",
      " ...\n",
      " [13.481028   6.6048713  5.5499773 ...  7.867697   5.491959   6.9525223]\n",
      " [13.040097   6.158324   5.732391  ...  7.3375125  5.355708   7.116389 ]\n",
      " [13.010653   5.8485284  5.5840793 ...  8.320087   5.3133945  6.934439 ]]\n",
      "label.shape: (348, 9)\n",
      "features.shape: (348, 5510)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from torch import optim, nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = FMData(nfm_config['train_non_em'],nfm_config['label_file'],nfm_config['n_class'])\n",
    "train_loader = data.DataLoader(train_dataset, drop_last=True,batch_size=100,shuffle=True, num_workers=4)#batchsize必须小于测试机总数，否则测试时报错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cef944d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 0, total loss: 6.441996, accuracy: 0.263333\n",
      "Training Epoch: 1, total loss: 6.221971, accuracy: 0.513333\n",
      "Training Epoch: 2, total loss: 6.075954, accuracy: 0.600000\n",
      "Training Epoch: 3, total loss: 5.999389, accuracy: 0.676667\n",
      "Training Epoch: 4, total loss: 5.926018, accuracy: 0.706667\n",
      "Training Epoch: 5, total loss: 5.839252, accuracy: 0.753333\n",
      "Training Epoch: 6, total loss: 5.839435, accuracy: 0.756667\n",
      "Training Epoch: 7, total loss: 5.793652, accuracy: 0.813333\n",
      "Training Epoch: 8, total loss: 5.701597, accuracy: 0.846667\n",
      "Training Epoch: 9, total loss: 5.685310, accuracy: 0.876667\n",
      "Training Epoch: 10, total loss: 5.649554, accuracy: 0.883333\n",
      "Training Epoch: 11, total loss: 5.611215, accuracy: 0.900000\n",
      "Training Epoch: 12, total loss: 5.588803, accuracy: 0.910000\n",
      "Training Epoch: 13, total loss: 5.561292, accuracy: 0.936667\n",
      "Training Epoch: 14, total loss: 5.542735, accuracy: 0.920000\n",
      "Training Epoch: 15, total loss: 5.509409, accuracy: 0.960000\n",
      "Training Epoch: 16, total loss: 5.481897, accuracy: 0.943333\n",
      "Training Epoch: 17, total loss: 5.483464, accuracy: 0.960000\n",
      "Training Epoch: 18, total loss: 5.479198, accuracy: 0.963333\n",
      "Training Epoch: 19, total loss: 5.436112, accuracy: 0.980000\n",
      "Training Epoch: 20, total loss: 5.407413, accuracy: 0.986667\n",
      "Training Epoch: 21, total loss: 5.426551, accuracy: 0.980000\n",
      "Training Epoch: 22, total loss: 5.414892, accuracy: 0.986667\n",
      "Training Epoch: 23, total loss: 5.373723, accuracy: 0.986667\n",
      "Training Epoch: 24, total loss: 5.373112, accuracy: 0.983333\n",
      "Training Epoch: 25, total loss: 5.380009, accuracy: 0.990000\n",
      "Training Epoch: 26, total loss: 5.347982, accuracy: 0.990000\n",
      "Training Epoch: 27, total loss: 5.360510, accuracy: 0.983333\n",
      "Training Epoch: 28, total loss: 5.335511, accuracy: 0.990000\n",
      "Training Epoch: 29, total loss: 5.350775, accuracy: 0.990000\n",
      "Training Epoch: 30, total loss: 5.340281, accuracy: 0.990000\n",
      "Training Epoch: 31, total loss: 5.335027, accuracy: 0.993333\n",
      "Training Epoch: 32, total loss: 5.300993, accuracy: 1.000000\n",
      "Training Epoch: 33, total loss: 5.291731, accuracy: 0.996667\n",
      "Training Epoch: 34, total loss: 5.278868, accuracy: 0.996667\n",
      "Training Epoch: 35, total loss: 5.298007, accuracy: 1.000000\n",
      "Training Epoch: 36, total loss: 5.299426, accuracy: 0.996667\n",
      "Training Epoch: 37, total loss: 5.308121, accuracy: 0.986667\n",
      "Training Epoch: 38, total loss: 5.263869, accuracy: 0.996667\n",
      "Training Epoch: 39, total loss: 5.278332, accuracy: 1.000000\n",
      "Training Epoch: 40, total loss: 5.270028, accuracy: 1.000000\n",
      "Training Epoch: 41, total loss: 5.255538, accuracy: 0.996667\n",
      "Training Epoch: 42, total loss: 5.251361, accuracy: 1.000000\n",
      "Training Epoch: 43, total loss: 5.272611, accuracy: 1.000000\n",
      "Training Epoch: 44, total loss: 5.265106, accuracy: 1.000000\n",
      "Training Epoch: 45, total loss: 5.245729, accuracy: 1.000000\n",
      "Training Epoch: 46, total loss: 5.239741, accuracy: 0.996667\n",
      "Training Epoch: 47, total loss: 5.237436, accuracy: 1.000000\n",
      "Training Epoch: 48, total loss: 5.230260, accuracy: 1.000000\n",
      "Training Epoch: 49, total loss: 5.206667, accuracy: 1.000000\n",
      "Training Epoch: 50, total loss: 5.217966, accuracy: 1.000000\n",
      "Training Epoch: 51, total loss: 5.205156, accuracy: 0.996667\n",
      "Training Epoch: 52, total loss: 5.195331, accuracy: 0.996667\n",
      "Training Epoch: 53, total loss: 5.209030, accuracy: 0.996667\n",
      "Training Epoch: 54, total loss: 5.214345, accuracy: 0.996667\n",
      "Training Epoch: 55, total loss: 5.195283, accuracy: 1.000000\n",
      "Training Epoch: 56, total loss: 5.206015, accuracy: 1.000000\n",
      "Training Epoch: 57, total loss: 5.196332, accuracy: 1.000000\n",
      "Training Epoch: 58, total loss: 5.163936, accuracy: 1.000000\n",
      "Training Epoch: 59, total loss: 5.195273, accuracy: 1.000000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-159b1b6d2d59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mcorrect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0;31m#print(\"x:\",x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;31m#print(\"labels:\",labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_worker_number_rationality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/new_pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/new_pytorch/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/new_pytorch/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/new_pytorch/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_fork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mSpawnProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/new_pytorch/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush_std_streams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/new_pytorch/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mparent_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch\n",
    "#from nfm_network import NFM\n",
    "if __name__ == \"__main__\":\n",
    "    ####################################################################################\n",
    "    # NFM 模型\n",
    "    ####################################################################################\n",
    "    BATCH_SIZE=100\n",
    "   \n",
    "    \"\"\"\n",
    "    training_data, training_label, dense_features_col, sparse_features_col = getTrainData(nfm_config['train_file'], nfm_config['fea_file'])\n",
    "    train_dataset = Data.TensorDataset(torch.tensor(training_data).float(), torch.tensor(training_label).float())\n",
    "\n",
    "    test_data = getTestData(nfm_config['test_file'])\n",
    "    test_dataset = Data.TensorDataset(torch.tensor(test_data).float())\n",
    "    \n",
    "    test_data = getTestData(nfm_config['test_file'])\n",
    "    test_dataset = Data.TensorDataset(torch.tensor(test_data).float())\n",
    "\n",
    "    \"\"\"\n",
    "    #device = torch.device('cuda:0')\n",
    "    #epoch=0\n",
    "    \n",
    "    #model=nn.Linear(10149,16).to(device)\n",
    "    #model=nn.Linear(10149,16)\n",
    "    #model=nn.ReLU(nn.Linear(10149,16))#RuntimeError: all elements of input should be between 0 and 1\n",
    "    #print('model:',model)\n",
    "    #nfm = MLP(nfm_config).cuda()#加了device防止出现GPU CPU两种设备的错误提示\n",
    "    #print(\"nfm:\",nfm)\n",
    "    #print(nfm)\n",
    "    #nfm.train()\n",
    "    #u=nfm.parameters()\n",
    "    #print(u)\n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr=nfm_config['lr'], weight_decay=nfm_config['l2_regularization'])\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=nfm_config['lr'], weight_decay=nfm_config['l2_regularization'])\n",
    "    optimizer.zero_grad()\n",
    "    total = 0\n",
    "    #loss_func = torch.nn.BCELoss()\n",
    "    loss_func=torch.nn.CrossEntropyLoss()\n",
    "    #loss_func=torch.nn.LogSoftmax()\n",
    "    \n",
    "    #model=nn.Softmax(nn.Linear(10149,16)).to(device)\n",
    "    # 从DataLoader中获取小批量的id以及数据\n",
    "    for epoch_id in range(1000):\n",
    "        correct=0\n",
    "        total=0\n",
    "        for batch_idx, (x, labels) in enumerate(train_loader):\n",
    "            #print(\"x:\",x)\n",
    "            #print(\"labels:\",labels)\n",
    "            x = Variable(x)\n",
    "            labels = Variable(labels)\n",
    "            \n",
    "            \n",
    "            #x = torch.tensor(x, dtype=torch.float)\n",
    "            #x=x.clone().detach().requires_grad_(True)\n",
    "            #x=torch.tensor(x,dtype=torch.float)\n",
    "            x=x.clone().detach().requires_grad_(True)\n",
    "            #labels=torch.tensor(labels,dtype=torch.float)\n",
    "            labels=labels.clone().detach().requires_grad_(True)\n",
    "            x, labels = x.cuda(), labels.cuda()\n",
    "            \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_predict = model(x)\n",
    "            #loss = loss_func(y_predict.view(-1), labels)\n",
    "            loss = loss_func(y_predict, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss = loss.item()\n",
    "            #loss, predicted = self._train_single_batch(x, labels)\n",
    "\n",
    "            total += loss\n",
    "            \n",
    "            \n",
    "            \n",
    "            predicted = torch.max(y_predict.data,1)\n",
    "            #print(\"predicted:\",predicted)\n",
    "            predicted = torch.max(y_predict.data,1)[1]\n",
    "            \n",
    "            \n",
    "            labels=torch.max(labels,1)\n",
    "            #print(\"labels:\",labels)\n",
    "            labels=labels[1]\n",
    "            \n",
    "            correct += (predicted == labels).sum()\n",
    "            #print(\"correct:\",correct)\n",
    "            #correct=correct[0]\n",
    "            #print(\"new_correct:\",float(correct))\n",
    "            #correct=float(correct)   \n",
    "            #if batch_idx % 10 == 0:\n",
    "            #print(correct/(BATCH_SIZE*(batch_idx+1)))\n",
    "            accuracy=correct/((BATCH_SIZE)*(batch_idx+1))\n",
    "            \"\"\"\n",
    "            #y_predict.detach().numpy()\n",
    "            pred = y_predict\n",
    "            print(\"pred:\",pred.shape)\n",
    "            y=labels.clone().detach().requires_grad_(True)\n",
    "            print(\"y:\",y.shape)\n",
    "            #y=labels.data.cpu().numpy()\n",
    "            #y = labels.detach().numpy()\n",
    "            roc_auc_score(y, pred)\n",
    "            \"\"\"\n",
    "           \n",
    "            # print('[Training Epoch: {}] Batch: {}, Loss: {}'.format(epoch_id, batch_id, loss))\n",
    "        print(\"Training Epoch: %d, total loss: %f, accuracy: %f\" % (epoch_id, total,accuracy))\n",
    "        #print(\"auc:\",roc_auc_score)\n",
    "path='data/xiaoqiu_gene_5000/model/new_model_param_geng_MLP_non_em_5000.pkl'\n",
    "torch.save(model.state_dict(),path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b76cd3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='data/xiaoqiu_gene_5000/model/new_model_param_geng_MLP_5000_with_smoothing.pkl'\n",
    "torch.save(model.state_dict(),path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bca1854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdfc24f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import Trainer\n",
    "from network import NFM\n",
    "import torch.utils.data as Data\n",
    "from Utils.criteo_loader import getTestData, getTrainData\n",
    "from torch import nn\n",
    "import torch.nn.functional as F  # 激励函数的库\n",
    "nfm_config = \\\n",
    "{\n",
    "    'n_class':9,\n",
    "    'linear_hidden1':1000,\n",
    "    'linear_hidden':100,#线性模型输出层（隐层个数）\n",
    "    'embed_input_dim':1001,#embed输入维度\n",
    "    'embed_dim': 100, # 用于控制稀疏特征经过Embedding层后的稠密特征大小，embed输出维度\n",
    "    #'dnn_hidden_units': [100,11],#MLP隐层和输出层\n",
    "    \n",
    "    'dnn_hidden_units':[100,9],#MLP隐层\n",
    "    'num_sparse_features_cols':5510,#the number of the gene columns\n",
    "    'num_dense_features': 0,#dense features number\n",
    "    'bi_dropout': 0.3,#Bi-Interaction 的dropout\n",
    "    'num_epoch': 500,#训练epoch次数\n",
    "    'batch_size': 100,#batch_size\n",
    "    'lr': 1e-3,\n",
    "    'l2_regularization': 1e-4,\n",
    "    'device_id': 0,\n",
    "    'use_cuda': False,\n",
    "    \n",
    "    #'train_file': '../Data/criteo/processed_data/train_set.csv',\n",
    "    #'fea_file': '../Data/criteo/processed_data/fea_col.npy',\n",
    "    #'validate_file': '../Data/criteo/processed_data/val_set.csv',\n",
    "    #'test_file': '../Data/criteo/processed_data/test_set.csv',\n",
    "    #'model_name': '../TrainedModels/NFM.model'\n",
    "    'train_file':'data/xiaoqiu_gene_5000/train/final_5000_encode_100x.csv',\n",
    "    'label_file':'data/xiaoqiu_gene_5000/train/gene_5000_labels.csv',\n",
    "    'test_file':'data/frappe/gene_4000/test/test_file.csv',\n",
    "    'test_label':'data/frappe/gene_4000/test/test_label.csv',\n",
    "    'title':'data/xiaoqiu_gene_5000/train/gene_5000_gene_name.csv',\n",
    "    'all':'data/xiaoqiu_gene_5000/train/gene_5000_label_name.csv'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8820bac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (fc1): Linear(in_features=5510, out_features=1000, bias=True)\n",
      "  (bn1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=1000, out_features=100, bias=True)\n",
      "  (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=100, out_features=9, bias=True)\n",
      "  (bn3): BatchNorm1d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#model definition\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(5510, 1000)\n",
    "        self.bn1= nn.BatchNorm1d(1000)\n",
    "        self.fc2 = nn.Linear(1000, 100)\n",
    "        self.bn2=nn.BatchNorm1d(100)\n",
    "        self.fc3 = nn.Linear(100, 9)\n",
    "        self.bn3=nn.BatchNorm1d(9)\n",
    "        self.drop=nn.Dropout(0.5)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.drop(self.bn1(self.fc1(x))))\n",
    "        x = F.relu(self.drop(self.bn2(self.fc2(x))))\n",
    "        return F.softmax(self.bn3(self.fc3(x)), dim=1)\n",
    "model = MLP().cuda()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ead812e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e6f9277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (fc1): Linear(in_features=5510, out_features=1000, bias=True)\n",
      "  (bn1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=1000, out_features=100, bias=True)\n",
      "  (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=100, out_features=9, bias=True)\n",
      "  (bn3): BatchNorm1d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "MLP(\n",
      "  (fc1): Linear(in_features=5510, out_features=1000, bias=True)\n",
      "  (bn1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=1000, out_features=100, bias=True)\n",
      "  (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=100, out_features=9, bias=True)\n",
      "  (bn3): BatchNorm1d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "[('fc1.weight', Parameter containing:\n",
      "tensor([[-0.0071,  0.0226,  0.0067,  ...,  0.0061,  0.0008,  0.0083],\n",
      "        [ 0.0112,  0.0033,  0.0086,  ..., -0.0064, -0.0263, -0.0135],\n",
      "        [ 0.0033,  0.0028,  0.0062,  ...,  0.0092,  0.0040,  0.0123],\n",
      "        ...,\n",
      "        [ 0.0158,  0.0027, -0.0077,  ...,  0.0106,  0.0087, -0.0044],\n",
      "        [ 0.0024, -0.0018, -0.0066,  ..., -0.0041, -0.0010,  0.0053],\n",
      "        [-0.0233, -0.0059, -0.0031,  ..., -0.0050, -0.0167,  0.0058]],\n",
      "       device='cuda:0', requires_grad=True)), ('fc1.bias', Parameter containing:\n",
      "tensor([-6.9882e-07, -2.6899e-07,  8.1030e-07,  8.5366e-07,  9.0213e-07,\n",
      "         1.0310e-06, -1.1119e-06,  1.3993e-07,  2.6477e-06, -8.3633e-07,\n",
      "         1.5823e-06,  3.2739e-08, -8.0105e-07,  3.2181e-07,  6.5521e-07,\n",
      "         1.1072e-06, -3.7159e-08, -2.9549e-07,  7.9424e-07, -1.5349e-07,\n",
      "        -1.0809e-07, -2.9793e-07,  4.9605e-08, -5.4768e-07,  2.2512e-07,\n",
      "        -2.6257e-06, -1.3530e-06, -6.3627e-09, -6.0312e-07,  4.0544e-08,\n",
      "         1.4132e-06, -3.2993e-07, -9.9269e-07,  6.0986e-06,  7.8143e-07,\n",
      "         1.0894e-06, -3.2755e-07, -7.3506e-07,  2.6543e-06,  5.8159e-07,\n",
      "         1.0219e-07, -3.3009e-06,  3.7482e-06,  1.7602e-06, -1.5335e-07,\n",
      "        -8.0566e-07,  1.0251e-06, -9.0085e-07, -1.3945e-06, -4.8892e-07,\n",
      "        -9.5772e-07,  9.8043e-07,  3.3174e-07, -3.0186e-06,  1.6301e-06,\n",
      "        -7.2680e-07, -2.1095e-07, -6.8239e-07, -8.1498e-07,  2.1892e-06,\n",
      "        -3.8102e-08,  1.0525e-07,  1.0316e-07,  1.3128e-07, -5.4499e-07,\n",
      "         7.2199e-07, -8.2204e-07, -2.1970e-07,  6.3371e-07, -3.3037e-07,\n",
      "        -2.0432e-07,  6.0342e-07,  9.3581e-07,  4.1966e-07, -9.3675e-07,\n",
      "        -8.2326e-07, -1.0007e-06, -7.9176e-07, -1.6126e-07,  1.0707e-07,\n",
      "        -4.6105e-07,  3.5876e-07,  1.9515e-07,  3.3749e-07, -9.9945e-07,\n",
      "        -2.7297e-07,  4.7039e-07, -4.9075e-07,  7.3759e-07,  2.1739e-06,\n",
      "        -6.2509e-07,  2.3494e-07, -6.5677e-07, -7.5863e-07, -3.2025e-07,\n",
      "        -2.4698e-07,  8.5422e-07, -2.6947e-07,  9.6027e-07, -1.9681e-07,\n",
      "         7.4629e-07,  4.9016e-07, -1.0445e-06,  6.7267e-08,  5.5358e-07,\n",
      "         2.7574e-07, -3.2573e-07,  1.9441e-07,  2.3534e-07, -4.0928e-07,\n",
      "         3.0169e-07, -5.4619e-07,  9.5774e-07,  2.7907e-07,  4.2801e-07,\n",
      "         6.4882e-07,  4.0857e-07,  4.5026e-07, -3.3983e-07, -7.9529e-07,\n",
      "         9.3095e-07,  1.3581e-07, -1.3790e-06, -7.2270e-07,  2.7501e-07,\n",
      "        -4.0162e-06, -7.1983e-08, -6.8132e-06, -1.0983e-08,  2.7297e-07,\n",
      "         7.1050e-07, -3.7723e-07,  2.1195e-07,  1.2059e-07,  4.5751e-08,\n",
      "        -1.7135e-06,  1.2391e-07, -1.3716e-06,  8.8543e-07,  5.5566e-07,\n",
      "        -4.2930e-09,  6.8189e-07,  2.0816e-07,  1.5788e-07, -1.8879e-07,\n",
      "         7.0980e-08,  1.5034e-06,  2.2388e-08,  1.1464e-06,  4.3852e-07,\n",
      "         1.0515e-06,  1.8240e-08, -5.6958e-07,  1.2202e-06, -1.4154e-06,\n",
      "        -2.4044e-07, -5.7624e-07,  1.5692e-06,  6.2085e-07, -1.1025e-06,\n",
      "        -3.5974e-06, -9.5341e-08,  4.3056e-07,  1.5884e-06,  6.8212e-07,\n",
      "         1.4045e-06,  3.9323e-09,  7.7353e-08,  6.9484e-07, -7.5226e-07,\n",
      "         4.1261e-07,  1.0829e-07,  1.3489e-06, -3.6994e-07,  1.7748e-09,\n",
      "         1.5067e-06, -2.7580e-07, -8.3317e-07, -4.4906e-07, -1.0576e-06,\n",
      "        -4.2029e-07, -4.0817e-07, -8.7643e-07,  1.3577e-07,  2.2620e-07,\n",
      "         2.1513e-06,  2.4347e-06, -6.9374e-07,  7.5388e-07,  6.8778e-07,\n",
      "        -5.2929e-07,  2.0805e-07,  9.0107e-07, -3.4202e-07,  7.5848e-07,\n",
      "         9.1864e-07,  2.3803e-07,  3.0997e-06, -7.7156e-08, -2.7664e-06,\n",
      "        -5.3873e-07,  5.1489e-07, -9.7762e-07, -7.3466e-07,  6.7091e-07,\n",
      "         1.7482e-07, -8.5068e-07,  1.0490e-06, -1.0328e-06, -4.2884e-08,\n",
      "        -3.7965e-07,  4.5358e-07, -7.0881e-07, -3.3551e-07,  6.2892e-07,\n",
      "        -2.8708e-07, -3.3992e-08, -2.2546e-07, -7.3460e-07,  4.2720e-07,\n",
      "        -7.7402e-07, -1.0662e-06,  6.3793e-07,  1.0270e-06, -2.9972e-06,\n",
      "         1.9595e-07, -8.6304e-07, -8.1025e-07,  2.2966e-07, -1.6556e-07,\n",
      "        -4.2414e-07, -7.3237e-07, -6.3445e-07,  3.5447e-08, -8.8888e-07,\n",
      "        -2.0940e-07, -6.0885e-07, -7.1649e-08, -2.5346e-07,  1.3332e-06,\n",
      "        -7.2160e-07, -1.6407e-07, -2.9786e-07, -1.4149e-06, -3.1207e-07,\n",
      "         1.2857e-06, -8.5549e-08, -5.8488e-07, -9.4364e-07,  7.6336e-07,\n",
      "        -1.8732e-06,  1.8733e-07, -1.5588e-07,  2.2154e-07,  2.7262e-07,\n",
      "         5.7630e-07, -9.1920e-07,  8.6708e-07,  8.2684e-07, -2.7961e-07,\n",
      "         1.0328e-06,  4.0242e-07,  2.7849e-07,  3.7801e-07,  6.0539e-07,\n",
      "        -9.4969e-07,  1.1718e-06, -6.1939e-07, -2.4652e-06, -4.1460e-07,\n",
      "        -7.3033e-07, -7.0077e-08, -3.0192e-07,  4.4409e-07,  9.9201e-07,\n",
      "        -4.6466e-08,  7.1938e-07, -8.2018e-07, -3.4136e-07, -2.1364e-07,\n",
      "        -1.9295e-07, -2.9756e-07, -5.0265e-08,  8.4939e-07, -1.8397e-06,\n",
      "        -1.5484e-06,  1.8158e-06, -3.6173e-09,  8.4895e-07,  7.8938e-07,\n",
      "         5.7732e-07, -4.5594e-07,  1.2884e-06,  7.1637e-08,  2.2988e-08,\n",
      "         1.2840e-07,  1.6844e-06, -2.2962e-07,  7.5902e-07, -5.7387e-07,\n",
      "        -3.4304e-07,  9.3963e-07, -3.9630e-07, -4.9163e-07, -3.5397e-08,\n",
      "         1.2029e-06, -1.8965e-07, -1.9863e-07,  5.4273e-07,  6.5835e-07,\n",
      "        -1.5649e-07, -9.9806e-07, -1.4695e-08, -7.4624e-08,  6.8524e-08,\n",
      "        -1.8598e-08, -1.9289e-06, -7.3057e-08,  2.0285e-07,  8.3566e-07,\n",
      "         6.6813e-07,  1.9255e-07,  6.0011e-07, -2.3150e-06, -7.8850e-07,\n",
      "        -1.1552e-05, -4.1590e-07,  7.5859e-08, -1.4535e-06, -5.8105e-07,\n",
      "        -8.2751e-07,  8.4310e-08,  1.3154e-07,  1.0055e-07,  3.8739e-07,\n",
      "        -6.4194e-07, -8.2646e-09,  1.5798e-06, -6.2079e-07, -7.6829e-08,\n",
      "         4.5579e-07, -8.8114e-07, -4.3143e-07, -3.6572e-07, -4.9915e-06,\n",
      "        -4.3417e-07, -1.0027e-06, -9.2548e-06, -3.1537e-07, -8.3203e-07,\n",
      "         3.4578e-07,  7.7671e-08, -1.0176e-06,  4.3975e-07,  2.3135e-07,\n",
      "        -4.0779e-07,  8.8287e-07,  3.7118e-06, -7.5253e-07,  3.6635e-07,\n",
      "         2.5499e-07,  2.5784e-07, -2.9376e-07, -1.4026e-08, -6.5250e-06,\n",
      "        -5.0427e-07, -2.3793e-08, -7.4989e-07, -2.5577e-07,  5.5148e-07,\n",
      "         2.1093e-07,  2.6596e-06,  3.0547e-06, -3.6524e-08, -4.7243e-07,\n",
      "         1.3866e-07,  6.4190e-07,  6.7591e-07,  6.9429e-07,  1.0400e-06,\n",
      "        -1.2945e-08, -1.0463e-06,  4.0131e-07, -4.5261e-07,  8.5238e-07,\n",
      "         3.5565e-07, -1.4776e-06, -3.3425e-07,  4.4004e-07, -3.5729e-07,\n",
      "        -2.0426e-07, -4.1705e-07, -9.5760e-07,  7.7201e-08,  4.8814e-08,\n",
      "         2.4671e-06,  6.5296e-07,  3.9409e-07,  3.4171e-07, -1.1931e-06,\n",
      "        -8.5009e-08,  5.6258e-07, -2.5284e-06, -3.3386e-07, -5.0151e-08,\n",
      "        -4.9659e-07,  8.2533e-07, -1.0613e-07,  1.4218e-06, -3.3380e-06,\n",
      "         5.7512e-07,  1.1131e-07, -3.8547e-07, -2.3392e-06,  4.7063e-07,\n",
      "         3.4674e-06,  2.0097e-07,  1.5356e-07, -1.9232e-07,  4.5071e-07,\n",
      "         7.1239e-07,  7.0172e-07,  1.9325e-07,  3.1520e-07, -2.3333e-07,\n",
      "        -4.4505e-06, -1.0240e-06, -7.9791e-07,  1.3002e-07,  4.6089e-07,\n",
      "         1.4741e-07,  3.9799e-08,  1.7972e-08,  1.3455e-06, -5.8873e-07,\n",
      "        -1.5102e-08, -2.7483e-07,  8.2221e-08,  3.8960e-06, -1.4610e-07,\n",
      "         5.9453e-07,  1.1438e-06, -7.5000e-08, -5.2905e-07,  9.8734e-07,\n",
      "        -1.3872e-07,  2.2079e-06,  5.5721e-07, -2.4301e-07,  1.0272e-06,\n",
      "         1.3930e-06,  3.4875e-08,  1.3044e-07, -6.2205e-07, -1.0699e-07,\n",
      "        -9.0052e-07,  5.4247e-07, -1.5665e-07,  5.7487e-07,  8.3730e-07,\n",
      "        -6.2705e-07, -1.1535e-07, -1.8488e-06,  9.8521e-08,  9.0204e-07,\n",
      "        -5.9315e-07, -4.4566e-07,  5.2172e-07,  1.0120e-06,  5.2290e-07,\n",
      "        -1.8143e-06, -1.0690e-06,  5.4521e-06,  5.4493e-07,  6.5848e-07,\n",
      "         1.2399e-06,  5.0599e-07, -2.0124e-06,  1.0059e-06, -1.3326e-06,\n",
      "        -1.9207e-06, -8.2924e-07,  5.2665e-07,  6.6639e-07,  6.6754e-08,\n",
      "        -2.7482e-07,  2.2510e-07,  1.3629e-06,  8.5843e-07,  6.2138e-08,\n",
      "        -3.6030e-06,  5.3702e-07, -1.1014e-07, -1.1277e-06,  1.2520e-05,\n",
      "         3.6143e-07, -8.3451e-07,  3.7911e-07, -7.2078e-07, -6.8006e-07,\n",
      "         6.3652e-07, -7.7211e-07,  1.3363e-07,  2.5632e-07, -1.6601e-07,\n",
      "        -1.1743e-06,  4.7935e-07, -2.6816e-07,  6.7438e-07,  4.8896e-07,\n",
      "        -3.2405e-07, -2.9730e-07,  1.6173e-06, -6.6000e-07,  1.5177e-07,\n",
      "        -1.5662e-06, -7.5632e-07,  4.2078e-07, -2.8281e-07, -3.9261e-07,\n",
      "        -7.8010e-07, -2.3381e-07,  7.2913e-07,  1.4918e-06, -9.0766e-07,\n",
      "        -4.4877e-07,  1.0481e-06, -3.4451e-07,  6.4672e-07,  3.1396e-06,\n",
      "         4.5661e-06, -8.9576e-07,  8.7879e-07,  1.7085e-07, -9.1994e-07,\n",
      "        -4.7057e-07,  3.0186e-07,  1.3732e-08, -2.5951e-07, -1.1283e-07,\n",
      "         2.8453e-07,  6.1074e-07, -2.6302e-07,  2.0798e-06, -5.6086e-07,\n",
      "        -1.3454e-06,  6.3911e-07,  4.5933e-07,  1.6987e-08, -4.0888e-07,\n",
      "         7.3996e-07,  2.8235e-07, -5.1590e-07,  1.0404e-07, -2.6387e-06,\n",
      "        -4.8913e-07, -1.5157e-06, -1.2248e-06, -6.0141e-07,  7.7334e-07,\n",
      "        -8.9556e-07, -2.3853e-08,  1.1272e-06,  2.5636e-07,  6.9936e-07,\n",
      "        -3.4572e-07, -7.6482e-06, -5.5057e-08,  1.5750e-06, -4.3843e-07,\n",
      "         1.7181e-07,  1.7422e-07, -5.8251e-08, -1.9545e-07,  4.8593e-07,\n",
      "         3.7476e-07, -2.7670e-07,  7.4956e-07,  3.0760e-07,  2.6642e-07,\n",
      "         8.9564e-07, -4.2513e-07,  5.6268e-07,  1.8236e-07,  2.8192e-07,\n",
      "        -1.1040e-06,  4.9150e-07, -9.6898e-07,  4.8238e-08,  1.0606e-07,\n",
      "         6.2664e-07,  3.3388e-07,  1.9975e-07,  2.4305e-07, -1.3630e-07,\n",
      "        -3.2160e-07,  8.6300e-07,  2.1586e-07, -3.3278e-06,  6.7008e-07,\n",
      "        -3.5501e-07, -2.5081e-06, -2.6088e-07,  4.2426e-07, -4.3752e-07,\n",
      "        -2.0852e-06, -8.7480e-07,  1.5610e-06,  2.8196e-07,  5.6376e-07,\n",
      "         1.2709e-06,  4.7974e-07, -9.9742e-08, -5.2094e-07,  6.5614e-07,\n",
      "        -4.9677e-07, -5.0873e-07, -4.9499e-07,  1.6267e-07,  1.0077e-07,\n",
      "        -7.9744e-07, -8.3274e-07,  4.7428e-07, -1.6749e-06, -2.1637e-06,\n",
      "        -5.8099e-07,  8.8110e-07, -6.3101e-07,  1.4018e-07, -8.9142e-07,\n",
      "         2.0292e-07, -3.5839e-07,  4.2248e-07,  2.7902e-07,  1.2713e-07,\n",
      "        -9.5295e-07, -3.1296e-07,  4.3396e-07, -1.5450e-07, -1.3918e-06,\n",
      "         1.3619e-07, -4.9259e-07,  4.7428e-07, -5.9998e-08, -4.1297e-07,\n",
      "         2.4890e-07,  2.6178e-07,  5.2925e-07, -1.2296e-06, -1.5017e-06,\n",
      "         3.9982e-07,  5.5813e-07, -4.5904e-07,  3.9556e-08, -2.9175e-07,\n",
      "         7.7351e-07,  8.0566e-08, -6.2524e-07, -1.0226e-06,  5.2641e-07,\n",
      "        -1.9703e-07, -3.6569e-07, -1.7680e-07, -1.6894e-07, -7.6772e-06,\n",
      "         6.0277e-07,  1.3663e-07, -1.2967e-07, -4.3583e-07,  3.9250e-07,\n",
      "        -1.1420e-06, -1.4592e-07,  4.6781e-07, -5.0913e-07,  9.1059e-07,\n",
      "        -9.1414e-07, -2.8451e-08, -2.0719e-07,  5.2671e-07, -2.7457e-07,\n",
      "         3.0603e-08, -7.5894e-07, -5.8078e-07,  2.0384e-07,  9.6611e-07,\n",
      "         5.9529e-07, -1.3024e-06,  1.4675e-08,  2.3875e-07,  2.6797e-07,\n",
      "        -8.6598e-07, -1.0297e-06, -2.0240e-07, -6.3124e-07,  6.3207e-07,\n",
      "         7.9161e-07,  1.3936e-07, -1.4620e-07,  5.7967e-08, -1.3951e-07,\n",
      "         2.0407e-07, -2.7765e-07, -1.1935e-06, -4.8202e-07,  5.0147e-07,\n",
      "        -1.2604e-08,  4.9160e-07,  4.6819e-08,  8.5745e-07,  1.3404e-07,\n",
      "         9.2482e-07, -7.9300e-08,  7.0950e-07,  9.5215e-07, -4.3328e-07,\n",
      "        -4.8412e-07,  2.0908e-07, -5.6180e-07,  4.8449e-07,  1.8087e-08,\n",
      "        -1.6191e-07, -4.3750e-09, -2.4677e-06, -1.1585e-06,  5.3047e-07,\n",
      "        -8.9748e-08, -1.2321e-06,  2.6902e-07,  2.6538e-06,  4.4683e-06,\n",
      "        -7.1192e-07,  2.1028e-06, -6.7616e-07, -7.0786e-07,  6.7668e-07,\n",
      "         9.0781e-07,  8.8531e-07,  6.6150e-08,  5.9673e-07,  1.0273e-06,\n",
      "        -2.3834e-07,  1.1724e-06,  6.8072e-07, -1.0500e-07,  9.9460e-07,\n",
      "        -3.6784e-08, -1.5195e-07, -1.1886e-06,  1.4864e-06, -1.9672e-06,\n",
      "        -4.0365e-07, -4.5415e-07,  1.1200e-06, -4.2898e-07,  8.8392e-07,\n",
      "        -1.8062e-07, -5.3640e-07,  8.1148e-07, -2.6238e-07,  4.5195e-07,\n",
      "         3.9491e-07, -5.4123e-08, -1.1430e-06,  1.8127e-06, -2.6451e-06,\n",
      "        -1.5866e-06, -4.9292e-08,  5.5866e-08, -3.3959e-07, -4.3556e-07,\n",
      "        -1.2535e-06, -6.4011e-08, -7.4341e-07, -1.0648e-06,  4.3167e-07,\n",
      "         8.2849e-07, -7.2115e-07,  4.6192e-07, -7.8579e-08,  6.3024e-09,\n",
      "         1.9304e-07, -8.0123e-07,  1.7564e-07, -1.0539e-06, -4.9572e-09,\n",
      "         7.0139e-07, -1.1477e-06,  2.6564e-07,  5.3125e-07, -2.6794e-07,\n",
      "         3.6768e-07,  5.9484e-07, -7.1409e-07, -1.3739e-06, -7.6663e-07,\n",
      "         8.3918e-07, -1.0035e-06,  4.8876e-07,  9.2643e-07, -1.2366e-06,\n",
      "         9.1920e-07,  2.1778e-07,  4.5145e-07,  1.0382e-07, -1.2926e-06,\n",
      "         7.1020e-07, -4.2538e-07,  4.3956e-06,  5.9537e-07, -1.0868e-07,\n",
      "         7.5168e-08,  1.1072e-07, -6.7505e-07, -6.9882e-07, -2.7511e-07,\n",
      "        -1.1064e-07,  2.4367e-07, -7.5319e-07,  7.8294e-07,  7.2421e-07,\n",
      "        -2.6758e-07, -1.0066e-06,  1.3092e-06, -3.8259e-07, -2.6397e-06,\n",
      "        -5.8505e-07, -1.4077e-07,  3.2280e-07,  3.8678e-07,  8.8808e-08,\n",
      "         4.8825e-07, -5.8759e-07,  3.8361e-07, -1.0037e-07, -6.5787e-07,\n",
      "        -3.3920e-06, -6.4205e-07, -4.4546e-07, -1.3651e-07, -2.8988e-07,\n",
      "        -1.0057e-06,  3.2406e-07, -6.8947e-07, -5.7151e-08, -1.1492e-06,\n",
      "        -4.0399e-06,  5.3071e-07, -1.7006e-07,  5.0435e-07, -3.2335e-07,\n",
      "         2.2411e-07, -7.2779e-07, -2.5487e-06,  2.2149e-07,  7.5234e-07,\n",
      "         2.5827e-07, -1.1025e-06,  2.4484e-07,  2.8458e-07,  4.2671e-07,\n",
      "         1.7085e-06,  1.7240e-06, -1.2417e-08, -2.6412e-07,  9.2026e-07,\n",
      "        -8.6333e-07,  2.3996e-07,  1.3107e-07, -1.5339e-07, -2.0375e-06,\n",
      "        -5.6877e-07,  6.2680e-07, -1.0283e-06, -7.8849e-07,  8.3088e-07,\n",
      "         3.2501e-06,  7.2467e-07, -2.1987e-07, -1.9325e-07,  6.4798e-07,\n",
      "         5.8327e-07, -5.4620e-07,  7.3409e-07, -3.8761e-07, -1.5420e-07,\n",
      "        -1.2546e-06,  1.2197e-08, -3.5691e-06,  5.7521e-07, -1.0167e-06,\n",
      "         7.0410e-07,  1.0199e-06, -2.3905e-07, -1.8404e-06, -1.1155e-06,\n",
      "         7.7076e-07,  8.2505e-07,  3.8942e-08,  3.4549e-06,  9.0236e-07,\n",
      "         6.4369e-07, -5.8416e-08,  7.9347e-07, -1.7089e-06, -1.8365e-06,\n",
      "        -3.4087e-06, -4.5301e-07,  5.3141e-07,  2.1419e-06, -2.6781e-07,\n",
      "        -4.1810e-07,  1.1673e-06,  2.2120e-08,  3.4121e-07, -7.8536e-07,\n",
      "         2.0074e-07,  9.6761e-09, -2.8410e-06,  6.0478e-08,  3.4459e-07,\n",
      "        -3.4529e-07, -3.3738e-08, -1.4026e-06, -3.1317e-07,  7.1642e-07,\n",
      "         5.1565e-07,  2.2953e-07, -3.1826e-07, -8.7938e-07, -2.3615e-07,\n",
      "        -2.0086e-07,  8.9397e-07,  1.5382e-07,  9.2431e-07,  2.7900e-07,\n",
      "        -1.0152e-06, -3.4657e-07,  1.0694e-07,  8.9646e-07,  9.0131e-07,\n",
      "        -1.2000e-06, -2.3919e-07,  2.4982e-07,  1.9540e-07,  7.2294e-08,\n",
      "        -2.4972e-07,  1.3116e-07,  1.2600e-07,  8.2083e-07,  2.7010e-07,\n",
      "         7.3065e-07, -3.3724e-06, -2.1547e-07, -5.2645e-07,  4.5689e-07,\n",
      "        -3.2204e-07, -5.0865e-07,  4.9779e-07, -2.5383e-07, -2.1837e-07,\n",
      "         1.4664e-06, -3.4543e-07,  9.0138e-07, -6.3266e-08, -3.9109e-07,\n",
      "        -6.3495e-07,  6.2433e-07, -3.0699e-07, -4.8055e-07, -8.6628e-07,\n",
      "        -4.5726e-07, -3.1861e-07,  3.7119e-07, -3.2894e-06,  1.9971e-07,\n",
      "        -1.1663e-06, -3.2627e-08,  1.1033e-06,  6.5136e-07, -2.8244e-07,\n",
      "        -2.1066e-07, -6.6990e-08, -5.9632e-07,  3.8631e-08, -1.7100e-07,\n",
      "        -4.3386e-07,  5.6542e-07, -1.4681e-06, -2.3941e-08, -3.3437e-06,\n",
      "        -2.3881e-07,  1.2025e-06, -2.4541e-07,  4.3944e-07,  1.0907e-06,\n",
      "         7.6049e-07,  2.2291e-08, -1.8894e-07, -2.0724e-07, -6.8685e-07],\n",
      "       device='cuda:0', requires_grad=True)), ('bn1.weight', Parameter containing:\n",
      "tensor([0.9329, 0.9655, 0.9082, 0.9033, 0.9253, 0.9564, 0.9167, 0.9429, 0.9431,\n",
      "        0.9918, 0.9233, 0.9038, 0.9037, 0.9419, 0.9142, 0.8875, 0.9568, 0.9591,\n",
      "        0.9445, 0.9019, 0.9010, 0.9239, 0.9168, 0.9170, 0.8916, 0.9181, 0.9220,\n",
      "        0.9048, 0.9545, 0.9000, 0.9076, 0.9563, 0.9122, 0.9416, 0.9599, 0.9703,\n",
      "        0.9315, 0.9147, 0.9564, 0.9044, 0.9153, 0.9130, 0.9152, 0.9105, 0.8966,\n",
      "        0.9411, 0.9668, 0.9221, 0.9430, 0.9113, 0.9278, 0.9236, 0.9091, 0.9234,\n",
      "        0.9180, 0.9354, 0.9115, 0.9056, 0.8935, 0.9176, 0.8838, 0.9236, 0.9152,\n",
      "        0.9154, 0.9002, 0.9423, 0.9019, 0.9557, 0.9048, 0.9275, 0.9090, 0.9522,\n",
      "        0.9138, 0.9039, 0.9085, 0.9104, 0.9778, 0.9780, 0.9000, 0.9287, 0.9056,\n",
      "        0.9022, 0.9092, 0.9176, 0.9184, 0.9108, 0.9767, 0.9016, 0.9001, 0.9213,\n",
      "        0.9206, 0.8913, 0.9492, 0.9107, 0.9396, 0.9737, 0.9038, 0.9114, 0.9395,\n",
      "        0.9168, 0.9611, 0.9052, 0.9045, 0.9052, 0.9047, 0.9489, 0.9662, 0.9125,\n",
      "        0.9220, 0.8746, 0.9202, 0.9166, 0.9250, 0.9049, 0.9372, 0.9327, 0.9429,\n",
      "        0.8979, 0.9633, 0.9338, 0.9252, 0.9198, 0.9616, 0.9139, 0.8992, 0.9075,\n",
      "        0.9081, 0.9590, 0.9197, 0.9453, 0.9043, 0.9130, 0.9108, 0.9340, 0.9037,\n",
      "        0.9248, 0.9465, 0.9924, 0.9450, 0.9356, 0.9219, 0.9065, 0.8951, 0.9788,\n",
      "        0.9270, 0.9521, 0.9291, 0.8920, 0.9098, 0.8999, 0.9278, 0.9091, 0.9282,\n",
      "        0.9102, 0.9218, 0.9214, 0.9011, 0.9053, 0.9077, 0.9009, 0.9133, 0.9033,\n",
      "        0.8909, 0.9282, 0.9325, 0.9388, 0.9101, 0.9014, 0.8955, 0.8993, 0.8928,\n",
      "        0.8888, 0.9500, 0.9528, 0.8865, 0.9193, 0.9309, 0.9010, 0.9020, 0.9497,\n",
      "        0.8948, 0.8928, 0.9227, 0.8929, 0.9222, 0.9203, 0.9362, 0.9167, 0.9056,\n",
      "        0.9228, 0.9171, 0.9253, 0.9195, 0.8996, 0.9012, 0.9149, 0.9187, 0.9561,\n",
      "        0.9204, 0.9686, 0.9063, 0.9160, 0.9287, 0.9110, 0.9278, 0.8925, 0.8958,\n",
      "        0.8893, 0.9307, 0.8979, 0.9224, 0.9021, 0.9312, 0.8987, 0.9446, 0.9052,\n",
      "        0.9034, 0.9435, 0.9244, 0.9053, 0.9569, 0.8936, 0.9175, 0.9121, 0.9179,\n",
      "        0.9185, 0.9187, 0.9427, 0.9452, 0.9572, 0.9058, 0.9098, 0.9244, 0.8943,\n",
      "        0.9102, 0.8916, 0.9070, 0.9102, 0.8963, 0.8971, 0.9033, 0.9070, 0.9060,\n",
      "        0.9269, 0.9221, 0.9257, 0.9009, 0.9029, 0.9902, 0.9087, 0.9136, 0.8953,\n",
      "        0.8859, 0.8911, 0.9587, 0.8831, 0.9246, 0.9326, 0.9084, 0.9104, 0.8905,\n",
      "        0.8850, 0.8863, 0.9309, 0.9083, 0.8995, 0.9178, 0.9227, 0.9156, 0.8967,\n",
      "        0.8936, 0.9199, 0.9237, 0.9253, 0.9340, 0.8871, 0.9043, 0.9054, 0.9252,\n",
      "        0.8935, 0.9336, 0.9028, 0.9339, 0.9145, 0.9204, 0.9047, 0.9478, 0.9217,\n",
      "        0.9383, 0.9116, 0.9222, 0.9036, 0.9197, 0.9151, 0.9028, 0.9121, 0.9256,\n",
      "        0.9440, 0.9440, 0.9170, 0.9143, 0.9105, 0.8937, 0.9075, 0.9182, 0.8928,\n",
      "        0.8981, 0.9040, 0.9021, 0.9002, 0.9353, 0.9179, 0.9115, 0.9460, 0.9525,\n",
      "        0.9201, 0.9211, 0.8997, 0.9036, 0.8979, 0.9725, 0.9698, 0.9083, 0.9499,\n",
      "        0.9236, 0.9561, 0.9104, 0.9099, 0.9724, 0.8964, 0.9177, 0.9023, 0.9246,\n",
      "        0.9159, 0.9406, 0.9000, 0.9581, 0.9264, 0.9203, 0.9104, 0.8897, 0.9457,\n",
      "        0.9209, 0.9039, 0.9678, 0.9737, 0.9094, 0.9433, 0.9168, 0.9161, 0.9014,\n",
      "        0.9128, 0.9063, 0.8970, 0.9073, 0.9728, 0.9176, 0.9495, 0.9472, 0.8993,\n",
      "        0.8878, 0.9183, 0.9418, 0.9138, 0.9526, 0.9200, 0.9066, 0.8937, 0.9240,\n",
      "        0.9288, 0.8885, 0.9268, 0.9310, 0.9400, 0.9479, 0.9063, 0.9233, 0.9597,\n",
      "        0.9205, 0.8980, 0.9019, 0.9173, 0.9223, 0.8983, 0.9041, 0.9138, 0.9095,\n",
      "        0.9037, 0.9293, 0.9657, 0.9094, 0.9162, 0.9154, 0.9034, 0.9053, 0.9621,\n",
      "        0.9110, 0.9154, 0.9299, 0.9214, 0.8992, 0.9023, 0.9440, 0.8839, 0.9187,\n",
      "        0.9383, 0.9208, 0.9078, 0.9000, 0.9390, 0.9116, 0.9046, 0.9229, 0.9186,\n",
      "        0.9068, 0.9314, 0.9026, 0.9219, 0.8894, 0.9171, 0.9161, 0.8904, 0.9233,\n",
      "        0.9274, 0.9296, 0.9338, 0.8962, 0.8975, 0.9287, 0.8917, 0.9400, 0.9176,\n",
      "        0.9163, 0.9284, 0.8997, 0.8964, 0.9559, 0.8785, 0.9520, 0.9304, 0.8882,\n",
      "        0.9252, 0.9267, 0.9051, 0.9089, 0.9289, 0.9290, 0.9168, 0.9029, 0.9253,\n",
      "        0.9081, 0.8914, 0.9102, 0.8985, 0.9129, 0.8871, 0.9120, 0.9654, 0.9273,\n",
      "        0.9175, 0.9095, 0.8850, 0.9222, 0.9281, 0.9075, 0.9124, 0.9016, 0.9157,\n",
      "        0.9369, 0.9133, 0.9833, 0.9180, 0.9194, 0.9276, 0.9526, 0.9268, 0.8898,\n",
      "        0.9187, 0.9611, 0.9566, 0.9506, 0.9165, 0.9192, 0.9219, 0.9239, 0.9163,\n",
      "        0.9202, 0.9420, 0.9245, 0.9157, 0.9122, 0.8928, 0.9202, 0.9033, 0.9319,\n",
      "        0.9064, 0.9230, 0.9001, 0.9389, 0.9280, 0.9137, 0.9007, 0.9031, 0.9645,\n",
      "        0.8920, 0.9187, 0.9329, 0.9037, 0.9164, 0.9277, 0.9030, 0.9180, 0.9118,\n",
      "        0.8970, 0.9164, 0.9157, 0.9395, 0.9076, 0.9481, 0.9067, 0.8955, 0.9126,\n",
      "        0.9243, 0.9584, 0.9081, 0.9026, 0.9419, 0.9130, 0.9282, 0.9372, 0.9162,\n",
      "        0.9008, 0.9685, 0.9108, 0.9169, 0.9367, 0.9271, 0.8841, 0.8932, 0.9091,\n",
      "        0.8972, 0.9312, 0.9362, 0.9219, 0.9129, 0.9182, 0.9330, 0.9201, 0.9071,\n",
      "        0.9141, 0.9027, 0.9123, 0.9010, 0.9047, 0.9332, 0.9468, 0.9058, 0.9125,\n",
      "        0.9152, 0.9317, 0.9297, 0.9457, 0.9133, 0.9081, 0.9157, 0.9320, 0.9626,\n",
      "        0.8976, 0.9274, 0.9210, 0.8942, 0.9158, 0.9230, 0.9109, 0.8815, 0.9344,\n",
      "        0.8904, 0.9101, 0.9171, 0.9199, 0.9090, 0.9270, 0.9175, 0.9203, 0.9095,\n",
      "        0.9477, 0.9384, 0.9319, 0.9130, 0.9212, 0.9237, 0.9134, 0.9377, 0.9477,\n",
      "        0.9033, 0.9151, 0.9194, 0.9177, 0.9445, 0.9048, 0.9014, 1.0092, 0.9251,\n",
      "        0.9340, 0.9264, 0.9271, 0.8958, 0.9078, 0.9199, 0.8979, 0.9718, 0.9674,\n",
      "        0.9076, 0.9091, 0.9481, 0.9170, 0.9275, 0.8998, 0.8900, 0.9152, 0.9165,\n",
      "        0.9284, 0.9202, 0.9447, 0.9025, 0.9023, 0.9260, 0.9164, 0.9120, 0.9210,\n",
      "        0.9021, 0.9218, 0.9238, 0.9312, 0.9126, 0.9571, 0.9220, 0.9483, 0.9567,\n",
      "        0.9085, 0.9283, 0.9046, 0.9058, 0.9079, 0.8912, 0.9149, 0.9053, 0.9099,\n",
      "        0.9736, 0.9043, 0.9105, 0.8942, 0.9063, 0.9145, 0.9041, 0.9085, 0.8954,\n",
      "        0.9438, 0.9499, 0.9039, 0.9278, 0.9172, 0.9269, 0.9492, 0.9448, 0.9055,\n",
      "        0.9073, 0.9436, 0.9014, 0.8927, 0.9163, 0.9056, 0.9158, 0.9101, 0.9031,\n",
      "        0.8929, 0.9279, 0.9112, 0.9455, 0.9043, 0.9619, 0.9349, 0.8981, 0.9043,\n",
      "        0.9510, 0.9099, 0.9075, 0.8907, 0.9132, 0.9051, 0.9074, 0.9285, 0.8928,\n",
      "        0.9384, 0.9551, 0.9087, 0.9227, 0.9072, 0.9158, 0.9055, 0.8922, 0.9170,\n",
      "        0.9421, 0.9008, 0.9222, 0.9370, 0.9355, 0.9384, 0.9134, 0.9106, 0.9437,\n",
      "        0.9174, 0.9061, 0.9770, 0.9179, 0.8872, 0.9362, 0.8919, 0.9150, 0.9223,\n",
      "        0.9065, 0.8951, 0.9288, 0.9071, 0.9146, 0.9049, 0.9037, 0.8969, 0.9560,\n",
      "        0.9147, 0.9213, 0.9516, 0.9480, 0.9203, 0.9328, 0.9455, 0.9170, 0.8978,\n",
      "        0.9263, 0.9120, 0.9086, 0.8856, 0.9155, 0.8967, 0.9415, 0.9173, 0.9084,\n",
      "        0.9413, 0.9429, 0.9822, 0.9230, 0.9221, 0.9285, 0.9104, 0.9117, 0.9163,\n",
      "        0.9002, 0.9022, 0.8928, 0.9190, 0.9348, 0.8875, 0.9491, 0.9244, 0.9259,\n",
      "        0.9063, 0.9148, 0.9218, 0.9130, 0.8945, 0.9132, 0.8995, 0.9244, 0.9209,\n",
      "        0.8926, 0.9363, 0.9326, 0.9350, 0.9019, 0.9563, 0.9560, 0.8857, 0.8883,\n",
      "        0.9062, 0.9379, 0.9165, 0.9205, 0.8944, 0.9032, 0.8952, 0.9412, 0.9070,\n",
      "        0.9517, 0.8957, 0.9005, 0.9229, 0.9077, 0.8989, 0.9124, 0.9443, 0.9108,\n",
      "        0.9159, 0.9036, 0.9080, 0.9050, 0.9110, 0.9275, 0.9345, 0.9135, 0.9234,\n",
      "        0.8953, 0.9308, 0.9290, 0.9305, 0.8976, 0.9164, 0.9118, 0.8927, 0.9194,\n",
      "        0.8891, 0.8994, 0.9324, 0.8944, 0.9104, 0.9364, 0.8904, 0.9553, 0.9256,\n",
      "        0.9312, 0.9243, 0.9062, 0.9877, 0.9031, 0.9263, 0.8968, 0.9606, 0.9292,\n",
      "        0.8990, 0.9284, 0.9013, 0.9149, 0.8974, 0.9186, 0.9098, 0.8978, 0.9137,\n",
      "        0.9025, 0.9138, 0.9141, 0.8972, 0.9133, 0.9049, 0.9266, 0.9740, 0.9164,\n",
      "        0.9289, 0.9201, 0.9558, 0.9336, 0.8946, 0.9155, 0.9385, 0.9005, 0.9318,\n",
      "        0.8717, 0.9369, 0.9206, 0.9028, 0.9510, 0.9359, 0.9075, 0.9036, 0.9063,\n",
      "        0.9147, 0.9102, 0.9167, 0.9760, 0.8900, 0.9155, 0.9589, 0.9091, 0.9039,\n",
      "        0.9360, 0.8966, 0.9597, 0.9930, 0.9314, 0.9422, 0.9270, 0.9236, 0.9173,\n",
      "        0.8999, 0.9086, 0.9034, 0.9577, 0.8979, 0.9425, 0.8965, 0.9082, 0.9222,\n",
      "        0.9120, 0.9352, 0.9296, 0.9352, 0.9096, 0.8997, 0.9455, 0.9120, 0.9250,\n",
      "        0.8943, 0.8787, 0.9494, 0.8995, 0.8988, 0.9138, 0.9067, 0.9015, 0.9300,\n",
      "        0.8987, 0.9286, 0.9225, 0.9240, 0.9242, 0.9127, 0.9023, 0.9586, 0.9132,\n",
      "        0.9494, 0.9542, 0.9089, 0.9227, 0.9525, 0.9307, 0.8900, 0.9619, 0.8985,\n",
      "        0.8971, 0.9419, 0.9414, 0.8995, 0.9283, 0.9040, 0.9363, 0.8971, 0.9033,\n",
      "        0.9466, 0.8877, 0.9094, 0.8896, 0.9169, 0.9442, 0.9273, 0.9090, 0.9283,\n",
      "        0.9021, 0.9380, 0.9688, 0.8994, 0.9082, 0.9108, 0.9555, 0.9140, 0.8932,\n",
      "        0.9222, 0.9122, 0.9130, 0.9137, 0.8985, 0.9010, 0.9138, 0.9411, 0.9176,\n",
      "        0.9170, 0.9704, 0.9425, 0.9233, 0.8972, 0.9493, 0.9222, 0.9465, 0.9459,\n",
      "        0.9012, 0.9467, 0.9031, 0.9094, 0.9327, 0.8822, 0.9331, 0.9369, 0.9417,\n",
      "        0.9119, 0.9320, 0.9216, 0.9551, 0.9671, 0.9005, 0.9201, 0.8743, 0.9055,\n",
      "        0.9194], device='cuda:0', requires_grad=True)), ('bn1.bias', Parameter containing:\n",
      "tensor([ 6.6689e-03, -1.6602e-02, -5.4948e-03, -2.7176e-02, -4.1650e-03,\n",
      "        -3.3254e-02, -3.4726e-02, -2.1131e-02, -2.6706e-02, -3.9183e-03,\n",
      "        -1.9633e-02, -3.4454e-02, -8.2131e-03, -1.1047e-02, -2.1954e-02,\n",
      "        -1.1030e-02, -9.0473e-03, -2.1881e-02, -1.7709e-02, -3.2082e-02,\n",
      "        -2.7922e-02, -1.2686e-02, -2.6884e-02, -4.0399e-03, -2.3933e-02,\n",
      "        -3.9135e-02, -1.4906e-02, -2.8614e-02, -1.4463e-02, -2.8437e-02,\n",
      "        -1.8314e-02, -2.8647e-02, -2.5134e-02, -2.5696e-02, -2.0498e-02,\n",
      "         8.9429e-04, -1.6452e-02, -7.8580e-03, -2.5155e-02, -2.7913e-02,\n",
      "        -1.2588e-02, -3.3665e-02, -1.7672e-02, -3.1109e-02, -1.5901e-02,\n",
      "         3.4038e-04, -2.6998e-02, -2.1650e-02, -1.4829e-02, -2.8088e-02,\n",
      "        -3.3618e-02, -2.1161e-02, -8.0722e-03, -2.8400e-02, -7.0260e-03,\n",
      "        -1.2873e-02, -2.4722e-02, -2.7200e-02, -3.5426e-02, -2.8341e-02,\n",
      "        -5.6587e-03, -1.9965e-02, -1.0036e-02, -3.0685e-02, -3.1290e-02,\n",
      "        -7.5864e-03, -1.8066e-02,  1.2298e-02, -1.9296e-02, -2.3496e-02,\n",
      "        -3.0459e-02, -1.4967e-02, -3.0481e-02, -2.3555e-02, -3.6288e-02,\n",
      "        -2.4955e-02,  5.5625e-04, -2.2177e-02, -6.5034e-03, -9.9328e-03,\n",
      "        -2.0603e-02, -2.2939e-02, -9.3443e-03, -2.6097e-02, -3.0940e-02,\n",
      "        -1.6017e-02, -3.4319e-03, -3.0075e-02, -2.1629e-02, -2.9975e-02,\n",
      "        -2.2618e-02, -3.2552e-02, -6.2137e-03, -1.9331e-03, -4.0843e-03,\n",
      "        -2.5276e-02, -2.3490e-02, -2.6656e-02, -1.7192e-02, -2.6928e-02,\n",
      "        -2.5907e-02, -1.5416e-02, -5.0497e-03,  3.4951e-03, -1.6449e-02,\n",
      "        -1.0254e-02, -1.6949e-02, -2.2906e-02, -2.9139e-02, -3.7332e-02,\n",
      "        -1.0969e-02, -2.6737e-02, -7.2003e-03,  8.1855e-03, -4.4811e-03,\n",
      "        -1.6956e-02, -4.1586e-03, -2.1208e-02, -1.3265e-02, -2.0140e-02,\n",
      "        -1.5241e-02, -3.0337e-02, -1.1982e-02, -1.5729e-02, -3.7351e-02,\n",
      "        -1.4943e-02, -3.8329e-03, -1.8076e-02, -7.7787e-03, -3.1826e-02,\n",
      "        -1.1243e-02,  9.9568e-03, -1.5013e-02, -2.4823e-02, -2.3724e-03,\n",
      "        -2.9500e-02,  5.9835e-03, -2.4640e-02, -1.3072e-02,  6.6044e-03,\n",
      "        -1.2382e-02, -2.0628e-02, -2.4075e-02, -5.6702e-03, -8.3818e-03,\n",
      "        -1.4208e-02, -2.7129e-02, -2.2061e-02, -1.4759e-02, -2.5010e-02,\n",
      "        -8.4857e-03, -2.8834e-02, -1.8515e-02, -1.4737e-02, -2.9439e-02,\n",
      "        -8.5647e-03, -3.5503e-03, -1.5761e-02, -3.3473e-02, -2.4960e-02,\n",
      "        -2.1153e-02, -2.1765e-02, -1.9017e-02, -2.8667e-02, -2.1223e-02,\n",
      "        -1.7195e-03, -2.5831e-02, -2.3141e-02, -1.8350e-02, -4.6480e-03,\n",
      "        -2.0043e-02, -1.2598e-02,  1.0023e-02, -1.8741e-02, -1.5320e-02,\n",
      "        -1.1675e-02, -2.2526e-02, -2.9444e-02, -2.1160e-02, -6.4009e-05,\n",
      "        -1.7707e-02, -1.1482e-02, -5.1061e-03, -1.3667e-02, -3.2531e-02,\n",
      "        -1.1863e-02, -2.7200e-02, -1.4164e-02, -3.6916e-02, -2.7613e-02,\n",
      "        -3.2167e-02, -3.9048e-02, -1.8391e-02, -3.7944e-02, -2.9016e-02,\n",
      "        -3.4725e-03, -6.7732e-03, -9.9441e-03, -3.5434e-02, -1.2550e-02,\n",
      "        -1.3879e-02, -2.3319e-02, -5.3937e-03, -4.5228e-02, -1.5721e-02,\n",
      "        -2.4581e-02, -3.0884e-02, -3.2848e-02, -2.3539e-02, -4.3454e-02,\n",
      "        -1.7565e-02, -2.3445e-02, -2.6411e-02, -8.3594e-03, -2.7031e-02,\n",
      "        -2.1692e-02, -3.4528e-02, -5.0326e-04, -1.0604e-02, -1.4417e-02,\n",
      "        -1.1024e-04, -3.1011e-02, -1.2172e-02,  4.6815e-03, -2.0905e-02,\n",
      "        -1.6512e-02, -3.1500e-02, -1.0314e-02, -1.4430e-02, -9.3748e-03,\n",
      "        -2.1402e-02, -2.4241e-02, -2.0202e-02, -4.1086e-02, -2.3693e-02,\n",
      "        -1.8502e-02, -1.6903e-02, -1.4484e-02, -2.7136e-02, -3.1580e-02,\n",
      "        -1.2229e-02, -1.7948e-02, -1.0916e-02, -2.4045e-02, -1.7929e-02,\n",
      "        -2.1818e-02,  1.6129e-04, -8.4003e-03, -2.9394e-02, -1.7159e-02,\n",
      "        -1.5038e-02, -3.4071e-02, -3.2497e-02, -2.7061e-02,  1.0884e-03,\n",
      "        -3.8592e-02, -2.4116e-02, -2.0955e-02, -3.8378e-02, -3.0427e-02,\n",
      "        -3.1330e-02, -8.6304e-04, -8.6506e-03, -7.0088e-03, -1.7409e-02,\n",
      "        -4.2697e-03, -2.0766e-02, -1.9667e-02, -2.3224e-02, -3.9196e-02,\n",
      "        -1.9547e-02, -1.0209e-02, -2.9545e-02, -1.0050e-02, -9.1487e-03,\n",
      "        -2.3767e-02, -1.5149e-02, -1.6055e-02, -6.4689e-03, -2.7394e-02,\n",
      "        -5.3582e-03, -1.2546e-02, -1.4908e-02, -3.7417e-02, -7.0792e-03,\n",
      "        -3.4251e-02,  1.1989e-03, -7.6584e-03,  1.3465e-02, -5.1634e-03,\n",
      "        -1.5750e-02, -2.6867e-02, -1.3250e-02,  5.6404e-03, -7.7306e-03,\n",
      "        -2.8677e-02, -1.3688e-02,  6.5814e-03, -3.6806e-03, -4.1002e-03,\n",
      "        -1.1846e-02, -2.5442e-02, -8.9737e-03, -1.5342e-02, -2.9284e-02,\n",
      "        -3.5493e-02, -2.9128e-02, -2.6339e-02, -3.0555e-02, -3.4366e-02,\n",
      "        -1.1129e-02, -1.4612e-02, -1.4620e-02, -8.1182e-03, -2.0405e-03,\n",
      "        -2.6859e-02, -2.8044e-02, -3.5649e-02, -1.8150e-02, -1.4067e-02,\n",
      "        -1.2478e-02, -2.7414e-02, -3.5635e-02,  3.7680e-03, -2.2950e-02,\n",
      "        -2.2457e-03, -2.1400e-02, -1.8270e-02, -6.0534e-03, -1.6415e-02,\n",
      "        -1.2159e-02, -1.5589e-02, -1.2873e-02, -1.3676e-02, -1.2694e-02,\n",
      "        -2.7762e-02,  1.5473e-03, -4.7752e-02, -1.9276e-02, -1.4199e-02,\n",
      "        -2.6870e-02, -1.9491e-02, -2.2402e-02, -1.3095e-02, -2.2867e-02,\n",
      "        -3.7295e-02, -1.3044e-02, -2.3576e-02, -1.7238e-02, -1.3608e-02,\n",
      "        -1.5674e-02, -3.6514e-02, -2.6806e-02, -2.5103e-02, -1.3362e-02,\n",
      "         1.3285e-02, -1.6190e-02, -1.4458e-02, -6.6277e-03, -2.0148e-02,\n",
      "        -4.4692e-02, -1.5983e-02, -2.0241e-02, -2.0768e-02, -2.5682e-02,\n",
      "        -1.5754e-02, -9.5891e-03, -2.7954e-02, -2.4222e-02, -3.1791e-02,\n",
      "        -3.0058e-02, -2.7058e-02, -8.5392e-03, -6.3665e-03, -1.4212e-02,\n",
      "        -2.1837e-02, -2.8051e-02, -1.7439e-02, -2.7823e-02, -5.1764e-03,\n",
      "        -2.3024e-02, -7.0565e-03, -1.7973e-02, -3.8185e-02, -2.3087e-02,\n",
      "        -7.8247e-03, -1.9281e-02, -2.7010e-02, -2.0216e-02,  2.3558e-03,\n",
      "         6.8081e-03, -1.2018e-02, -2.2077e-02, -1.4658e-02, -1.6101e-02,\n",
      "        -3.8539e-02, -3.7745e-02, -1.7563e-02, -1.3597e-02,  7.6479e-03,\n",
      "        -3.1193e-02, -2.4618e-02, -8.9296e-03, -3.0342e-02, -1.0976e-02,\n",
      "         6.4770e-03, -2.5097e-02, -1.4673e-02, -3.1932e-02, -7.4124e-03,\n",
      "        -1.0553e-02, -2.4753e-02, -7.9575e-03, -2.8715e-02, -1.1067e-02,\n",
      "        -1.8494e-02, -3.0851e-02, -1.2963e-02, -1.3419e-02, -1.5479e-02,\n",
      "        -2.7760e-02, -3.1963e-02, -3.4722e-02,  8.7358e-03, -1.9884e-02,\n",
      "        -1.5355e-02, -4.2216e-02, -1.6795e-02, -8.1667e-03, -3.2668e-02,\n",
      "        -1.3746e-02, -8.0615e-03, -1.3886e-02, -1.3549e-02, -3.0387e-02,\n",
      "        -2.1738e-02, -1.0208e-02, -3.8481e-02, -4.2258e-03, -3.1850e-03,\n",
      "        -2.9522e-02,  6.7806e-03, -9.5200e-03, -2.2016e-02, -2.1262e-02,\n",
      "        -1.9239e-02, -2.1334e-02, -1.7601e-02, -2.9264e-02, -1.6571e-02,\n",
      "        -2.7733e-02, -2.5302e-02, -3.4282e-02, -1.7458e-02, -1.4096e-02,\n",
      "        -2.0056e-02, -1.9687e-02, -1.7494e-02,  1.2714e-02, -1.3531e-02,\n",
      "        -2.4435e-02, -2.7098e-02, -1.1675e-02, -4.4530e-03,  2.0269e-03,\n",
      "        -1.5639e-02, -2.3160e-02,  8.0088e-03, -3.6027e-02, -3.3438e-02,\n",
      "        -1.1342e-02, -1.8015e-02, -7.0760e-03, -1.7621e-02, -1.5591e-02,\n",
      "        -1.9952e-02, -2.0860e-02, -1.6778e-02, -6.9233e-03, -1.9530e-02,\n",
      "        -1.3606e-02, -1.3818e-02, -2.7180e-02, -1.2487e-02, -1.9940e-03,\n",
      "        -1.4280e-02, -3.1532e-02, -9.9663e-03, -1.3352e-02, -1.6638e-02,\n",
      "        -2.0339e-02, -3.4635e-02, -3.9827e-02, -1.0780e-02, -9.7040e-03,\n",
      "        -7.4129e-03, -2.0130e-02, -3.5097e-02,  8.4145e-03, -1.5006e-02,\n",
      "        -2.5473e-02, -3.0029e-02, -3.1852e-02,  8.6676e-03, -1.2042e-02,\n",
      "        -2.5287e-02, -1.8187e-02, -2.1066e-02, -2.3535e-02, -1.1189e-02,\n",
      "        -3.3072e-02, -1.9629e-02, -1.5118e-02, -2.1045e-02, -7.4598e-03,\n",
      "        -1.5294e-02, -1.8193e-02, -1.2888e-02, -3.8968e-03, -1.8431e-02,\n",
      "        -1.0926e-02, -1.0837e-02, -3.8620e-02, -2.2096e-02, -3.0851e-02,\n",
      "        -2.2216e-02, -1.8068e-02, -2.3308e-02, -2.3766e-02, -1.6535e-02,\n",
      "        -4.2467e-02, -2.9234e-02,  5.3096e-03, -2.8055e-02, -3.0431e-02,\n",
      "        -3.1430e-03, -3.8930e-03, -2.7459e-02, -2.3590e-02, -2.6572e-02,\n",
      "        -1.2219e-02, -1.8861e-02, -3.5857e-02, -1.1828e-02, -2.0860e-02,\n",
      "        -1.7039e-02,  8.9934e-04, -3.0708e-02, -2.3366e-02, -1.9926e-02,\n",
      "        -2.0168e-02, -1.5041e-02, -2.8904e-02, -3.6276e-02, -2.8632e-02,\n",
      "        -6.8978e-03, -1.3270e-02, -1.9585e-02, -2.8024e-02, -2.2885e-02,\n",
      "        -9.7039e-03, -9.7302e-03, -2.3674e-02, -2.1044e-02, -2.6827e-02,\n",
      "        -2.6777e-03, -1.1763e-02, -3.5416e-02, -3.8267e-02,  2.1145e-03,\n",
      "        -2.3996e-02, -8.7334e-03, -1.8839e-02, -4.3848e-03, -2.6013e-02,\n",
      "        -1.8951e-03, -2.1149e-02, -2.5272e-02, -2.1785e-02, -2.9867e-02,\n",
      "        -1.2569e-02, -1.8280e-02, -1.8004e-02, -2.9751e-02, -3.5965e-02,\n",
      "        -1.9987e-02, -1.8003e-02, -3.1164e-03, -3.3721e-02, -6.0584e-03,\n",
      "        -2.3290e-02, -3.0360e-02,  2.4425e-04, -5.7232e-04, -2.2754e-02,\n",
      "        -2.1438e-02, -2.1923e-02, -2.4165e-02, -1.2716e-02, -8.9850e-03,\n",
      "        -1.8537e-02, -1.6636e-02, -1.1399e-02,  5.1063e-03, -1.9816e-02,\n",
      "        -2.4914e-03, -3.9343e-02, -5.7223e-03,  2.0244e-03, -1.3110e-02,\n",
      "        -1.7722e-02,  2.3689e-03, -1.5537e-02, -2.7283e-02,  4.3345e-03,\n",
      "        -1.4367e-02, -1.1404e-02, -9.1338e-03, -2.6574e-02, -3.0915e-02,\n",
      "        -2.9563e-02, -4.1646e-03,  4.8643e-03, -2.7904e-02, -2.6784e-02,\n",
      "        -2.7448e-02, -1.0766e-02,  2.2961e-03, -2.0787e-02, -9.7494e-03,\n",
      "         7.2097e-03, -1.7273e-02, -3.5181e-02, -1.6719e-02, -2.5136e-02,\n",
      "         8.2135e-03, -2.2062e-02, -9.4969e-03, -1.5154e-02, -2.4748e-02,\n",
      "        -3.7816e-02, -3.1089e-02, -2.8984e-02, -2.1439e-02, -3.0152e-02,\n",
      "        -3.6412e-02, -3.6093e-02, -3.9345e-04,  3.5386e-03, -1.1076e-02,\n",
      "        -2.9457e-02, -2.2778e-02, -2.6344e-02, -2.5620e-02, -3.0142e-02,\n",
      "        -2.0506e-02, -3.1833e-02, -2.1814e-03, -1.6061e-02, -1.4018e-02,\n",
      "        -2.1651e-02, -3.1988e-02, -3.7308e-02, -1.4991e-02, -2.1357e-02,\n",
      "        -3.8269e-02, -3.3362e-02, -2.8450e-02, -1.6077e-02, -2.6389e-02,\n",
      "        -1.4772e-02, -1.9755e-02, -1.1746e-02, -1.2715e-02, -6.7349e-03,\n",
      "        -2.2188e-02, -3.5013e-02, -1.4332e-02, -1.2405e-02, -3.8085e-02,\n",
      "        -2.1271e-02, -1.7114e-02, -2.1281e-02, -2.5841e-02, -1.8204e-02,\n",
      "        -1.0253e-02, -1.8490e-02, -2.0006e-02, -2.5682e-02, -2.6811e-02,\n",
      "        -1.7664e-02, -1.0900e-02, -1.5714e-02, -1.3739e-02, -3.1853e-02,\n",
      "        -1.0237e-02, -2.4647e-02, -3.0057e-02, -2.3366e-02, -3.4595e-02,\n",
      "        -2.4618e-02, -1.8586e-02,  4.3313e-03, -2.0254e-02, -2.2167e-02,\n",
      "        -1.6494e-02, -1.0640e-02,  1.5831e-03, -2.2676e-02, -1.8900e-02,\n",
      "        -2.4447e-02, -2.7768e-02, -1.5523e-02, -2.2395e-02, -3.3379e-02,\n",
      "        -1.9952e-02, -1.9059e-03, -1.9226e-02, -2.3398e-02, -4.1123e-03,\n",
      "        -1.8087e-02, -2.5461e-02, -5.1703e-03, -2.0544e-02, -3.0546e-02,\n",
      "        -4.0207e-03, -2.1004e-02, -2.2115e-02, -2.0572e-02, -1.3735e-02,\n",
      "        -2.3375e-02, -1.7542e-02, -2.1041e-02, -2.7554e-02, -1.7592e-02,\n",
      "         3.0514e-02, -1.2318e-02, -3.2040e-02, -1.5056e-02, -2.7216e-02,\n",
      "        -2.1900e-02, -3.4743e-02, -2.4572e-02, -2.3068e-02, -1.6124e-02,\n",
      "        -2.0290e-02, -3.3722e-02,  1.1291e-03, -1.9137e-03, -3.3555e-02,\n",
      "        -2.5843e-02, -1.4247e-02, -1.2882e-02, -2.0797e-02, -2.3135e-02,\n",
      "        -3.0037e-02, -2.9876e-03, -3.1387e-02, -2.8487e-02, -2.2750e-02,\n",
      "        -1.2512e-02, -2.2003e-02, -2.9078e-02, -1.8827e-02, -2.2524e-02,\n",
      "        -3.0109e-02, -2.2870e-02, -1.8230e-02, -4.0002e-02, -1.8736e-02,\n",
      "        -3.1099e-02, -3.3411e-02, -1.1134e-02, -1.1292e-02, -3.8986e-02,\n",
      "        -2.3202e-02, -1.2138e-02, -1.3275e-02, -1.7375e-02, -6.2959e-03,\n",
      "        -2.4027e-02, -2.7974e-02, -2.5737e-02, -2.6216e-02, -1.3867e-02,\n",
      "        -5.5868e-03, -6.5736e-03, -2.6611e-02, -1.6296e-02, -1.9571e-02,\n",
      "        -1.4522e-02,  4.1844e-03, -8.9995e-05, -2.5994e-02, -1.1034e-02,\n",
      "        -1.6063e-02, -5.3315e-03, -1.2937e-02, -2.5945e-02, -3.0150e-03,\n",
      "        -2.3896e-02, -2.2502e-02, -2.7794e-02, -1.4511e-02, -3.8776e-02,\n",
      "        -5.0948e-02, -1.5961e-02, -2.6542e-03, -2.0530e-02, -1.3690e-02,\n",
      "        -3.0797e-02, -8.9503e-03, -1.1385e-03, -2.0923e-02, -3.5672e-02,\n",
      "        -1.2630e-02, -2.0361e-02, -2.0742e-02, -1.4105e-02, -3.2502e-02,\n",
      "        -3.2993e-02, -2.5678e-02, -4.0496e-03, -3.6218e-02,  1.1226e-02,\n",
      "        -1.7576e-02, -3.5193e-03, -2.1033e-02,  1.1550e-03, -3.2862e-02,\n",
      "        -3.0035e-02, -7.5554e-04, -8.8784e-03, -2.6020e-02, -1.9613e-02,\n",
      "        -1.7707e-02, -1.4907e-02, -2.5563e-02, -1.3637e-02, -1.1892e-02,\n",
      "        -2.2138e-02, -1.7417e-02, -1.7940e-02, -9.0349e-03, -1.3232e-02,\n",
      "        -1.2846e-02, -2.0954e-02, -3.5325e-02, -1.9476e-02, -1.8158e-02,\n",
      "        -7.7704e-03, -2.4015e-02, -9.3514e-03, -1.0624e-02, -1.0850e-02,\n",
      "        -1.8470e-02, -5.8531e-03, -1.1997e-02, -1.2237e-02, -2.2076e-02,\n",
      "        -8.9157e-03, -3.9315e-02, -1.6648e-02, -2.4711e-02, -4.0875e-02,\n",
      "        -1.7640e-02, -3.0972e-02, -3.6808e-02,  1.1334e-03, -2.2874e-02,\n",
      "        -2.7616e-02, -3.1445e-02, -2.0760e-02, -7.3662e-03, -4.0263e-03,\n",
      "        -2.5455e-02, -1.9041e-02, -3.7968e-03, -1.7173e-02, -8.6937e-03,\n",
      "        -2.7904e-02, -2.5934e-02, -1.7872e-02, -1.9529e-02, -1.7984e-02,\n",
      "        -1.8608e-02, -2.8306e-02, -1.2169e-02, -1.1455e-02, -1.1330e-02,\n",
      "        -3.0490e-02, -2.2638e-02, -1.6143e-02, -2.6420e-02, -2.9457e-02,\n",
      "        -8.3630e-03, -2.0240e-02, -2.3154e-02, -3.3164e-02, -2.8887e-02,\n",
      "        -3.9826e-02,  5.6108e-03, -9.5582e-03, -1.5741e-02, -1.8869e-02,\n",
      "        -2.5596e-02, -1.9175e-04, -1.9697e-02, -1.5584e-02, -9.7904e-03,\n",
      "        -3.6085e-02, -5.6078e-03, -2.7315e-02, -1.8772e-02, -2.7811e-02,\n",
      "        -3.3716e-02, -2.7105e-02, -1.6207e-02, -2.5339e-02, -2.9530e-02,\n",
      "        -1.7790e-02, -2.6191e-02,  1.2974e-03, -3.5227e-02, -1.3205e-02,\n",
      "        -7.2069e-03, -1.3645e-02, -1.3047e-02,  1.0167e-02, -2.3037e-02,\n",
      "        -1.3751e-02,  1.4637e-02, -7.3257e-03, -1.7573e-02, -2.8702e-02,\n",
      "        -2.2269e-02, -2.0516e-02, -8.3135e-03, -2.0743e-02, -3.4996e-02,\n",
      "        -2.7761e-03, -1.5695e-02, -1.5719e-02, -1.5113e-02, -8.6706e-03,\n",
      "        -1.4988e-02, -1.7899e-02, -7.0590e-03, -3.2114e-02, -3.0118e-02,\n",
      "        -2.4288e-02, -1.6384e-02, -1.5813e-02, -1.3308e-02, -1.7499e-02,\n",
      "        -4.8465e-03,  1.4723e-02, -2.0683e-02, -3.3210e-02, -2.0017e-02,\n",
      "        -1.9138e-02, -1.5645e-02, -2.6456e-02, -2.1913e-02, -2.9984e-02,\n",
      "        -1.5239e-02, -1.9772e-02, -6.7163e-03, -3.6512e-02, -2.7222e-02,\n",
      "        -1.1856e-02, -1.6294e-02, -9.6320e-03,  1.1897e-02, -8.9992e-04,\n",
      "        -3.3295e-02, -4.8651e-02, -2.6984e-02, -1.9478e-02, -3.6765e-02,\n",
      "        -8.5836e-03, -1.7902e-03, -3.8291e-02, -1.8127e-02, -2.2925e-02,\n",
      "        -3.0081e-02, -2.9705e-02, -4.0635e-02, -6.1154e-03, -5.6890e-03,\n",
      "        -1.5573e-02, -3.7570e-03, -8.2688e-03, -1.2307e-02, -2.0046e-03,\n",
      "        -1.8450e-02, -1.2504e-02, -2.8540e-02, -1.6598e-02, -7.1833e-03],\n",
      "       device='cuda:0', requires_grad=True)), ('fc2.weight', Parameter containing:\n",
      "tensor([[ 0.0043,  0.0233,  0.0188,  ..., -0.0037, -0.0334, -0.0261],\n",
      "        [ 0.0140, -0.0010,  0.0354,  ...,  0.0047, -0.0010,  0.0170],\n",
      "        [-0.0002, -0.0425, -0.0161,  ..., -0.0011, -0.0294, -0.0125],\n",
      "        ...,\n",
      "        [-0.0075, -0.0192,  0.0029,  ...,  0.0310, -0.0227,  0.0088],\n",
      "        [-0.0129, -0.0130,  0.0241,  ...,  0.0230, -0.0026,  0.0065],\n",
      "        [-0.0300,  0.0196, -0.0261,  ...,  0.0153, -0.0399, -0.0380]],\n",
      "       device='cuda:0', requires_grad=True)), ('fc2.bias', Parameter containing:\n",
      "tensor([-1.6386e-06,  9.0694e-07,  5.9922e-07, -1.4073e-06,  2.1126e-06,\n",
      "        -1.4930e-07,  8.3749e-07, -2.4989e-07, -7.6836e-07,  1.1764e-06,\n",
      "        -7.5386e-07, -2.4573e-06,  1.4761e-06, -7.7414e-07, -4.6838e-08,\n",
      "        -2.4798e-07,  7.5390e-07, -1.3699e-06,  1.3644e-06,  5.0831e-07,\n",
      "         8.1472e-07, -7.6656e-07,  1.2108e-06,  5.8479e-07,  9.9214e-07,\n",
      "         1.7520e-06, -4.9753e-07, -6.5118e-07, -1.7593e-06,  5.2278e-07,\n",
      "        -2.4436e-06, -2.7859e-06,  5.7476e-07,  2.2525e-06, -1.2921e-06,\n",
      "         9.9092e-08, -1.6788e-06, -1.7669e-08, -1.7426e-07,  4.8097e-07,\n",
      "        -5.1166e-07, -6.4745e-07, -1.0770e-06,  2.0769e-07,  1.6213e-07,\n",
      "        -1.0469e-06,  1.4681e-06,  1.0105e-06,  9.0248e-07, -2.1077e-07,\n",
      "         2.6496e-07, -4.6658e-07, -9.6297e-07,  1.1049e-08,  3.5182e-07,\n",
      "        -1.7166e-07, -1.0556e-06,  7.2073e-07, -1.4950e-06, -2.5440e-07,\n",
      "        -1.2108e-06,  1.5307e-06, -4.3240e-07, -5.5009e-08,  9.5013e-07,\n",
      "        -6.1869e-07, -3.1969e-08, -2.4065e-06,  4.8668e-07, -1.0264e-06,\n",
      "         1.0883e-07, -3.6234e-07,  1.2352e-06,  6.2245e-07,  3.9907e-07,\n",
      "        -2.5061e-07,  9.1149e-07, -5.6317e-07,  1.6432e-08, -1.8304e-06,\n",
      "        -2.3652e-06,  5.1031e-08,  1.3380e-06,  7.0282e-07, -8.2256e-07,\n",
      "        -2.3767e-06,  2.4996e-06,  3.0883e-07, -7.1520e-07, -6.7435e-07,\n",
      "        -1.5481e-07, -1.6368e-06,  3.3116e-07, -7.5087e-07,  7.1340e-07,\n",
      "        -8.8781e-07, -1.4234e-07, -2.1208e-06,  7.3245e-07, -2.1474e-07],\n",
      "       device='cuda:0', requires_grad=True)), ('bn2.weight', Parameter containing:\n",
      "tensor([0.9893, 0.9571, 0.9872, 0.9943, 0.9777, 0.9827, 0.9908, 1.0006, 0.9910,\n",
      "        0.9891, 0.9611, 0.9996, 0.9662, 1.0145, 0.9432, 0.9896, 0.9975, 0.9996,\n",
      "        0.9926, 0.9701, 0.9464, 0.9823, 0.9867, 0.9974, 0.9617, 0.9639, 0.9798,\n",
      "        0.9837, 0.9825, 0.9837, 0.9839, 0.9814, 0.9783, 0.9712, 1.0254, 0.9522,\n",
      "        0.9676, 0.9819, 0.9963, 0.9421, 0.9812, 0.9918, 0.9882, 0.9709, 0.9939,\n",
      "        0.9489, 0.9372, 0.9821, 0.9751, 0.9823, 0.9838, 1.0023, 0.9717, 0.9795,\n",
      "        0.9841, 0.9821, 0.9929, 0.9922, 0.9866, 0.9771, 1.0001, 0.9750, 0.9651,\n",
      "        0.9698, 0.9776, 0.9956, 0.9261, 0.9682, 0.9798, 0.9794, 0.9825, 0.9510,\n",
      "        0.9806, 0.9707, 0.9978, 0.9589, 0.9863, 1.0042, 0.9527, 0.9899, 0.9756,\n",
      "        0.9709, 1.0085, 1.0040, 0.9719, 0.9929, 0.9872, 0.9620, 0.9565, 0.9449,\n",
      "        0.9795, 0.9822, 0.9537, 0.9766, 1.0062, 0.9806, 1.0007, 0.9713, 0.9952,\n",
      "        0.9873], device='cuda:0', requires_grad=True)), ('bn2.bias', Parameter containing:\n",
      "tensor([ 3.5287e-03,  3.6302e-03,  1.9887e-02,  9.4999e-03, -2.3203e-02,\n",
      "        -5.2354e-02, -1.9507e-02, -2.0771e-02,  1.7060e-02,  2.1729e-02,\n",
      "         3.0081e-03,  1.7474e-02, -2.7067e-02,  2.3756e-03,  1.9088e-03,\n",
      "        -1.5983e-02,  3.3332e-02, -3.1769e-02,  4.0721e-02, -6.4843e-04,\n",
      "         2.2722e-03,  5.4029e-03,  3.5864e-02, -3.2298e-02,  1.9859e-02,\n",
      "        -2.5520e-02, -3.8638e-03,  1.5593e-02,  9.8270e-03, -6.4939e-03,\n",
      "         2.0447e-02, -3.3712e-02,  2.8276e-02, -1.0447e-02,  3.1958e-02,\n",
      "         1.1793e-02, -3.5293e-02, -2.8783e-02,  3.7012e-02,  3.9771e-03,\n",
      "        -2.1852e-02,  4.1022e-02,  4.9241e-02,  1.3042e-02, -6.3932e-03,\n",
      "         2.0310e-02, -5.8792e-02, -6.9808e-03,  5.4355e-02,  7.1263e-03,\n",
      "        -1.9407e-02,  3.4361e-02, -3.0729e-03, -2.2622e-02, -3.8076e-04,\n",
      "         5.5585e-02,  4.3477e-02,  8.9244e-03,  1.6949e-03, -1.8357e-02,\n",
      "        -2.4154e-02,  7.2729e-03,  1.3868e-05, -2.1630e-02, -1.6303e-02,\n",
      "         3.9983e-02, -3.7431e-02,  9.9429e-03,  1.3385e-02,  1.1861e-02,\n",
      "         3.3628e-03, -9.9912e-03,  1.6258e-02, -1.3588e-02,  1.6430e-02,\n",
      "         2.8498e-03, -3.7865e-02,  2.3715e-02, -3.2687e-03,  1.5450e-03,\n",
      "        -9.9677e-03,  4.9405e-03,  3.1578e-02, -9.4971e-03,  2.9122e-02,\n",
      "         1.9517e-02,  9.3212e-03, -3.6430e-03, -1.3514e-02, -3.4797e-03,\n",
      "         4.5481e-03, -1.3530e-02, -1.7320e-02,  8.9103e-03,  4.5530e-02,\n",
      "        -2.6644e-02,  1.1318e-02, -4.1349e-04, -3.4385e-02,  2.1213e-02],\n",
      "       device='cuda:0', requires_grad=True)), ('fc3.weight', Parameter containing:\n",
      "tensor([[ 9.6656e-02,  2.4124e-03, -3.6698e-02,  6.6248e-02, -2.4505e-02,\n",
      "         -4.2889e-02,  8.6327e-03, -2.7487e-02, -2.9830e-02,  4.4156e-03,\n",
      "          8.8697e-02,  1.2940e-01, -1.9837e-02, -2.1459e-02, -2.8902e-02,\n",
      "          8.9248e-02,  4.5284e-02,  3.5788e-02,  8.4060e-02,  1.1100e-01,\n",
      "          8.4502e-02, -3.9932e-02, -2.9054e-02,  3.7260e-03, -1.6746e-02,\n",
      "          1.1608e-02, -2.0598e-02,  5.8290e-02, -4.6946e-02, -3.5825e-02,\n",
      "          9.4911e-02, -1.7876e-02,  6.1267e-02, -4.0084e-02, -2.8521e-02,\n",
      "         -3.8602e-02, -3.7791e-02, -7.9391e-03, -4.2755e-03,  2.9838e-02,\n",
      "          3.4664e-02,  9.3484e-02,  4.2888e-03,  1.1505e-02, -3.3857e-02,\n",
      "          8.3979e-02, -3.6304e-02,  9.2507e-02, -2.7712e-02, -3.7329e-02,\n",
      "          1.1683e-01,  6.2955e-02, -2.9646e-02,  8.1578e-02, -2.0538e-02,\n",
      "         -1.8828e-02,  5.9376e-02, -5.0023e-03,  2.6089e-02, -1.7892e-02,\n",
      "          5.2846e-03,  1.1248e-01, -1.6147e-02, -4.6862e-02, -4.0645e-02,\n",
      "         -7.9844e-03, -1.6524e-02, -3.6479e-02,  7.2786e-02,  2.0052e-02,\n",
      "         -1.9853e-02, -5.3418e-02, -3.9053e-02,  8.8658e-02, -2.1752e-02,\n",
      "         -5.8122e-02, -2.5039e-02,  6.8546e-02, -2.8181e-02, -7.1603e-03,\n",
      "          6.8971e-03, -4.3823e-02,  1.1526e-01,  1.0954e-01, -3.0229e-02,\n",
      "         -3.8445e-02,  8.8980e-03, -4.7207e-02, -1.3272e-02, -3.2776e-02,\n",
      "          8.0448e-02, -2.7014e-02, -5.0799e-02, -4.6680e-02, -3.8568e-02,\n",
      "         -3.5357e-02,  6.3313e-02,  9.1957e-02, -2.4526e-02, -2.7438e-02],\n",
      "        [-4.9171e-02,  9.8308e-03, -2.8369e-02, -3.5720e-02, -3.5993e-02,\n",
      "         -3.6056e-03,  2.3517e-02, -3.7695e-02, -4.0724e-02, -3.3062e-02,\n",
      "          2.6789e-03, -4.3465e-02, -3.5613e-02,  6.4168e-02, -3.9069e-02,\n",
      "         -2.2750e-02, -3.3387e-02, -1.0508e-02,  1.5380e-02,  9.3793e-02,\n",
      "         -1.3745e-03,  1.1715e-01,  3.9322e-02,  3.9927e-02, -2.2667e-02,\n",
      "         -9.8826e-03, -5.4961e-02, -3.2593e-02, -3.3484e-02, -5.5576e-02,\n",
      "          6.6096e-02, -4.1172e-02, -4.2655e-02,  1.3350e-01,  8.6179e-02,\n",
      "         -5.8830e-02, -2.4960e-02, -3.1615e-02, -3.8782e-02, -3.7494e-02,\n",
      "          9.6472e-02, -6.4872e-02, -4.2434e-02,  8.7700e-03,  1.1429e-01,\n",
      "          5.7601e-02, -6.3587e-02, -2.5703e-02,  4.4974e-02,  9.8036e-02,\n",
      "          5.2480e-02, -4.7785e-02, -5.6841e-02, -6.1688e-02, -3.2689e-02,\n",
      "          1.0309e-01, -3.5518e-02, -4.8557e-03,  6.0699e-02, -2.3559e-02,\n",
      "          4.4373e-03,  7.2047e-02, -5.3337e-02, -3.9637e-02, -4.1341e-03,\n",
      "         -5.2051e-02, -5.3336e-02, -4.6831e-02, -2.0717e-02,  6.9257e-02,\n",
      "          8.2619e-02, -4.8237e-02, -4.4865e-02, -3.9570e-02,  5.9535e-02,\n",
      "          1.0517e-01, -1.9506e-03, -2.3731e-02, -2.0161e-02,  1.0968e-01,\n",
      "          8.0177e-02, -5.2200e-02, -2.2370e-02,  1.2225e-01, -5.1492e-02,\n",
      "          8.5472e-02,  1.1110e-01,  3.3979e-02, -1.8552e-02,  5.9795e-02,\n",
      "         -5.4765e-02,  2.9157e-02,  6.8104e-02, -4.7514e-02, -3.0182e-03,\n",
      "          4.6096e-02,  8.0537e-02,  3.4089e-02, -3.0373e-02,  1.1128e-01],\n",
      "        [ 8.9535e-02, -6.2238e-02,  1.0430e-01, -5.3717e-02, -2.5332e-02,\n",
      "          3.2343e-02, -3.8947e-02, -1.8814e-02, -8.0867e-03,  1.0989e-01,\n",
      "         -6.8881e-02, -2.6501e-02, -3.2586e-02,  1.3278e-01,  1.6607e-02,\n",
      "          1.7600e-02, -2.9950e-02, -1.8221e-02, -7.3417e-02, -1.7187e-02,\n",
      "          7.9425e-02, -4.0103e-02, -3.9569e-02, -2.4980e-02,  1.0325e-01,\n",
      "          4.6659e-02, -5.5289e-02,  7.2156e-02,  4.2141e-02, -4.3181e-02,\n",
      "          9.7795e-02,  1.2792e-01, -4.0385e-02, -3.7986e-02, -3.2173e-02,\n",
      "         -5.3832e-02, -1.6375e-02, -2.7884e-02,  8.0875e-02, -4.9461e-02,\n",
      "         -3.7945e-02, -3.3653e-02, -5.3658e-02, -4.1784e-02,  6.3827e-02,\n",
      "         -6.0754e-02,  8.8554e-02, -3.6055e-03, -2.7636e-02, -5.1249e-02,\n",
      "         -1.9974e-02,  4.0488e-02, -4.4479e-02, -5.9063e-02, -4.0101e-02,\n",
      "          1.3347e-02, -3.8663e-02,  9.7523e-02,  1.5077e-02,  1.1576e-02,\n",
      "          1.2579e-01,  7.4987e-02,  6.4006e-02, -5.8977e-02,  2.6950e-02,\n",
      "         -4.0190e-02,  7.4734e-02, -3.8185e-02, -1.2712e-02, -4.4136e-02,\n",
      "         -3.8148e-03, -5.8435e-02, -5.0973e-02,  9.3504e-02,  1.0811e-01,\n",
      "          3.1674e-03, -2.2413e-02, -1.3180e-02, -9.8814e-03, -3.2746e-02,\n",
      "         -9.3356e-03,  8.4690e-02,  9.2344e-03, -7.2404e-03,  1.0663e-01,\n",
      "          1.1448e-02, -2.7727e-02, -5.8272e-02,  1.6782e-02,  8.7722e-02,\n",
      "         -6.2220e-02, -3.1268e-02, -3.2097e-02, -4.2872e-02, -2.5800e-02,\n",
      "         -3.7508e-02, -1.7948e-02, -2.3623e-02,  1.1817e-01,  4.1434e-02],\n",
      "        [-3.0109e-02, -2.3194e-02, -1.4844e-02,  6.2278e-02,  5.4662e-02,\n",
      "          1.1725e-01, -9.7955e-04, -1.7830e-02,  6.9718e-02,  7.7853e-02,\n",
      "         -5.8687e-03, -3.8488e-02, -1.7151e-02,  9.5910e-03,  1.0326e-01,\n",
      "         -1.9049e-02, -4.7656e-02, -3.8512e-02,  6.1815e-02, -4.5902e-02,\n",
      "          7.8693e-03,  2.4864e-02, -3.0204e-02,  1.1653e-01, -5.3861e-02,\n",
      "          2.2829e-02, -2.9062e-02,  2.6988e-02,  8.9702e-02, -2.7367e-02,\n",
      "         -1.2133e-02,  1.4058e-02,  5.0146e-02,  4.4113e-03, -3.9087e-02,\n",
      "          5.7068e-02,  2.3406e-02,  9.8628e-02, -3.6047e-02, -3.2072e-02,\n",
      "          1.2733e-02, -1.8857e-02, -3.5653e-02, -1.4606e-02,  9.1049e-02,\n",
      "          3.1646e-02, -5.6241e-02, -5.6699e-02,  7.9483e-02,  4.2211e-02,\n",
      "          4.5680e-02, -4.6945e-02,  6.4917e-02,  6.4433e-02, -4.7199e-02,\n",
      "         -3.6286e-02,  5.4275e-02, -6.6063e-03, -2.2284e-02,  9.8791e-02,\n",
      "         -2.1379e-02, -2.3402e-02, -4.0345e-02,  7.7549e-02, -2.7128e-02,\n",
      "         -1.4582e-02,  9.6932e-02, -3.5168e-02,  1.0107e-01, -4.3665e-02,\n",
      "         -3.4938e-02, -2.5384e-02,  3.9042e-02, -5.4470e-02, -3.4438e-02,\n",
      "         -5.8657e-02,  6.3415e-03,  6.1711e-02, -3.0997e-02, -5.2566e-02,\n",
      "         -7.8209e-03, -4.0665e-02,  2.9282e-02,  2.5053e-02, -3.7116e-02,\n",
      "          4.6297e-02,  9.4303e-02, -4.8556e-02, -1.9193e-02, -2.1068e-02,\n",
      "         -3.1006e-02, -3.8514e-02, -4.9950e-02, -4.7854e-02,  3.9687e-02,\n",
      "         -3.9598e-02, -5.8098e-02, -6.7213e-02, -1.4928e-02, -2.9450e-02],\n",
      "        [-4.9102e-02, -2.5638e-03, -5.4926e-02, -6.3255e-02, -2.9186e-02,\n",
      "         -3.1597e-02, -3.6654e-02,  9.7589e-02, -1.7375e-02,  1.4031e-02,\n",
      "          9.8965e-02,  5.8097e-02,  1.0962e-02, -3.5363e-02, -7.1032e-02,\n",
      "         -1.9052e-02,  1.0290e-01, -4.7264e-02,  5.9756e-02,  2.5463e-02,\n",
      "          3.1142e-03, -3.1123e-02, -4.5678e-02, -3.5242e-02,  3.3342e-02,\n",
      "         -3.1154e-02,  1.1200e-01, -4.8954e-02, -2.0781e-02, -4.8132e-02,\n",
      "         -6.6007e-02, -3.5466e-02,  2.5340e-02,  6.9398e-02, -5.3268e-02,\n",
      "         -9.5702e-03,  6.0375e-03, -6.2724e-02,  8.0193e-02,  4.6133e-02,\n",
      "         -8.6563e-03,  1.2754e-02, -4.2937e-02, -3.8809e-02, -2.0332e-02,\n",
      "         -3.1788e-02, -3.9838e-02, -5.0513e-02,  5.7568e-02,  8.5966e-02,\n",
      "         -3.6777e-02, -4.6480e-02,  1.1766e-03, -4.1298e-02,  9.7829e-02,\n",
      "         -4.9628e-02, -7.0730e-02, -5.2436e-02, -7.3667e-02,  6.2323e-03,\n",
      "         -4.7413e-02,  3.4536e-02,  1.0000e-01, -4.9504e-02, -4.3551e-02,\n",
      "         -4.7958e-02,  3.6631e-02,  4.8963e-02,  8.1131e-02, -4.4738e-02,\n",
      "         -7.0241e-02,  5.3384e-02,  1.0071e-01, -7.1059e-02,  9.7645e-02,\n",
      "          6.2546e-02,  2.2731e-03, -4.6835e-02, -7.8258e-02, -6.0471e-02,\n",
      "         -2.2219e-02,  8.3514e-02,  7.4990e-02, -5.7739e-02, -6.2802e-02,\n",
      "         -5.6506e-02,  1.6843e-02,  2.7465e-02, -5.4879e-02, -1.8836e-02,\n",
      "         -2.6732e-02,  1.1060e-01, -6.0087e-02,  6.4460e-02, -7.4410e-02,\n",
      "          1.1621e-01, -3.8684e-02, -4.2171e-02, -3.5788e-02, -4.4504e-02],\n",
      "        [-4.7951e-02,  8.2426e-02, -4.8634e-02, -2.2688e-02, -5.4653e-02,\n",
      "         -4.1215e-02, -1.7146e-02,  9.9145e-02,  9.7331e-02,  5.6986e-02,\n",
      "          9.2361e-02, -6.1844e-03,  5.5345e-02, -5.0620e-02,  6.0860e-02,\n",
      "         -3.6878e-03, -5.1463e-02, -1.4071e-02,  2.8221e-02, -1.4623e-02,\n",
      "         -6.0237e-02,  6.7837e-02, -3.2292e-02, -2.3296e-02,  4.8313e-02,\n",
      "          1.1220e-02,  6.2777e-02,  9.0174e-02,  3.4215e-02, -2.0400e-02,\n",
      "         -3.9785e-02, -3.8632e-02, -2.1644e-02, -4.7402e-02,  1.0073e-01,\n",
      "         -3.4276e-02, -2.9928e-02, -2.2568e-02, -1.7274e-02,  5.4031e-02,\n",
      "          1.1722e-01, -1.7290e-02,  2.7316e-02, -1.6153e-02, -3.3091e-02,\n",
      "          3.8987e-02,  9.5406e-02,  1.0109e-01,  2.6270e-02, -4.7089e-02,\n",
      "         -4.8664e-02,  1.1340e-01, -3.3251e-02,  5.5932e-02,  8.6452e-03,\n",
      "          8.7606e-02, -3.3764e-02, -1.1196e-02, -3.9240e-02,  6.5484e-02,\n",
      "         -4.6055e-02,  1.7067e-02, -4.3367e-02,  8.8023e-02,  1.0553e-01,\n",
      "         -2.3644e-03, -5.2608e-02, -2.0315e-02, -5.5030e-02,  7.0804e-02,\n",
      "         -3.7427e-03, -4.6195e-02, -3.7255e-02, -5.3323e-02, -2.7728e-02,\n",
      "         -1.0469e-02, -1.0059e-02, -3.5616e-02, -1.1428e-02, -4.8406e-02,\n",
      "          1.0822e-01, -3.5814e-02,  4.1127e-03, -1.6471e-02,  8.6168e-02,\n",
      "          8.9071e-02, -3.4834e-02,  2.9797e-02, -3.0865e-02, -2.9441e-02,\n",
      "          5.9241e-02,  3.5418e-03, -4.5677e-02,  4.4156e-03, -5.9188e-02,\n",
      "         -1.1601e-02, -2.6628e-02,  8.3916e-02,  6.7752e-02, -4.4497e-02],\n",
      "        [-3.1158e-02,  8.1484e-02,  6.7173e-02,  8.1375e-02, -1.6328e-02,\n",
      "         -3.9478e-02, -2.2522e-02, -1.7932e-02,  4.2618e-02, -4.9304e-02,\n",
      "         -4.0824e-02, -3.9025e-02, -3.5561e-02, -4.4828e-02,  3.9857e-02,\n",
      "         -2.6415e-02, -1.9874e-02, -2.6810e-02, -6.0152e-02, -3.9259e-02,\n",
      "          1.0503e-01,  3.6416e-02, -3.0448e-02, -2.5640e-02,  6.4948e-02,\n",
      "          8.9772e-03,  8.7613e-02, -6.0485e-02, -6.6572e-02,  2.4852e-03,\n",
      "          4.5214e-02, -2.9862e-02,  8.2137e-02,  5.3399e-03,  1.0191e-01,\n",
      "         -4.4383e-02,  1.2121e-01,  9.8988e-02,  3.8036e-02, -5.8947e-02,\n",
      "         -1.4906e-02, -4.3474e-02,  1.3122e-02,  4.8534e-02, -4.0515e-02,\n",
      "         -7.1555e-03, -5.4298e-02, -2.6375e-02, -6.5393e-02, -6.5512e-02,\n",
      "         -2.4152e-02, -5.2987e-02, -3.8168e-02, -5.2598e-02,  2.0076e-03,\n",
      "         -1.9127e-02,  3.1763e-02,  9.6590e-02, -4.0643e-02, -4.4730e-02,\n",
      "          1.8786e-02, -3.3577e-02,  1.3798e-02, -8.4138e-03, -5.8798e-02,\n",
      "         -2.4025e-02,  5.9601e-02,  8.2331e-02, -4.3025e-02,  7.8054e-02,\n",
      "          1.4910e-02,  8.2075e-02, -5.4587e-02,  5.7931e-03, -3.2973e-02,\n",
      "          7.3745e-02,  1.1807e-01,  8.5841e-02,  6.6943e-03,  3.7091e-02,\n",
      "         -2.6716e-02, -5.8491e-02, -3.0071e-02, -3.1492e-02, -5.1940e-02,\n",
      "         -2.2044e-02, -5.3202e-02,  1.0057e-01,  1.0892e-01, -5.8783e-02,\n",
      "          1.0355e-01, -2.6293e-02, -5.5148e-02, -4.4831e-02,  8.0551e-02,\n",
      "         -2.0899e-02,  6.3177e-02,  7.7990e-02, -2.8072e-02, -2.6606e-02],\n",
      "        [-2.5290e-02,  2.1104e-02,  8.5250e-02, -2.2316e-02,  1.1024e-01,\n",
      "         -2.9162e-02, -3.4249e-02, -3.7443e-02, -3.0957e-02, -3.8275e-02,\n",
      "         -3.7735e-02, -3.6588e-02,  1.1044e-01,  1.5222e-02,  6.1101e-02,\n",
      "          1.2282e-01,  7.9738e-02,  1.1377e-01, -4.0461e-02, -2.8834e-02,\n",
      "         -1.4069e-02, -2.9071e-02,  7.3595e-02,  2.7640e-05, -2.0293e-02,\n",
      "          1.2506e-01, -2.4846e-02, -1.4643e-02, -7.8480e-03, -4.6056e-02,\n",
      "         -2.4521e-02, -2.6142e-02, -1.5031e-02, -4.9132e-03, -3.5085e-02,\n",
      "          6.3789e-03, -1.3491e-02, -1.8588e-02, -4.7143e-02,  9.4661e-02,\n",
      "          1.0353e-02, -4.9797e-02, -3.7332e-02, -4.6305e-02, -1.2931e-02,\n",
      "         -4.6537e-02, -3.4774e-02,  5.7702e-02,  5.7559e-02, -5.8797e-02,\n",
      "          9.5017e-03,  6.3181e-02, -6.7605e-02, -3.6930e-02,  3.8377e-02,\n",
      "         -3.5439e-02,  7.8017e-02, -2.8303e-02,  6.5703e-02, -3.0276e-02,\n",
      "         -1.2670e-03, -1.3815e-02, -2.2732e-02, -3.9487e-03, -3.2353e-02,\n",
      "          5.3627e-02, -3.8718e-02, -4.2331e-02, -3.5703e-02, -4.4111e-02,\n",
      "          7.4837e-02,  1.6071e-02,  5.3002e-02, -2.7551e-02, -3.4196e-02,\n",
      "         -4.7335e-02, -7.1218e-03, -8.4249e-03,  6.6814e-02,  7.6369e-02,\n",
      "          4.8937e-02, -5.2406e-02, -1.0493e-02, -2.7608e-02, -1.5368e-02,\n",
      "         -1.0115e-02, -1.5185e-02, -2.1005e-02,  1.1852e-02,  6.1582e-02,\n",
      "         -2.9649e-02, -4.6462e-02, -1.5758e-02,  6.4151e-02,  6.1885e-02,\n",
      "         -4.1128e-02, -1.6599e-02, -1.9285e-02, -1.7667e-02, -1.6884e-02],\n",
      "        [ 5.2283e-02, -5.9708e-02, -7.6626e-02, -6.2643e-02, -6.9268e-02,\n",
      "         -4.5367e-03,  1.4387e-01, -3.4417e-02, -6.1704e-03, -6.7160e-02,\n",
      "          2.1782e-02,  4.1960e-02, -6.4054e-02, -7.4519e-02, -1.7701e-02,\n",
      "         -5.7738e-02, -6.3747e-02, -6.1269e-02, -7.3462e-02,  3.4738e-02,\n",
      "         -4.9196e-02, -1.7726e-02,  9.6251e-02, -1.5572e-02, -6.1385e-02,\n",
      "         -2.4852e-02, -6.3841e-02, -3.4702e-02, -6.4240e-02,  1.0657e-01,\n",
      "         -8.0585e-02,  1.7867e-03, -6.8464e-02, -4.2137e-02, -3.0270e-02,\n",
      "          1.2168e-01, -5.3773e-02, -1.9238e-02, -5.9759e-02,  1.2339e-02,\n",
      "         -4.6643e-02,  7.9051e-02,  1.0929e-01,  1.3289e-01, -8.5462e-03,\n",
      "          9.1368e-02, -4.5637e-02, -4.4665e-02, -1.0224e-01, -7.1870e-02,\n",
      "         -2.5024e-02, -6.2700e-02,  1.2299e-01, -5.5188e-02, -5.8544e-02,\n",
      "          8.5334e-02, -6.8130e-02, -5.2878e-02, -5.6362e-02, -1.3193e-03,\n",
      "         -5.1603e-02, -5.2833e-02, -4.9589e-02, -9.5514e-03,  7.1199e-03,\n",
      "          9.3964e-02,  3.0233e-02,  4.0302e-02, -2.3671e-02, -4.7701e-02,\n",
      "         -6.8643e-02, -6.2341e-02, -7.8028e-02, -1.2249e-02, -6.8532e-02,\n",
      "         -4.9874e-02, -4.0154e-02, -1.9477e-02,  1.2237e-01, -5.8033e-02,\n",
      "         -6.8187e-02,  3.6395e-02, -4.7849e-02, -5.4237e-02,  8.5897e-02,\n",
      "         -2.9286e-02, -7.2448e-02, -5.3107e-02,  3.6165e-02,  5.2634e-02,\n",
      "          2.4417e-02, -1.4811e-02,  1.0605e-01, -6.7952e-02, -5.5609e-02,\n",
      "         -5.6459e-02, -2.2689e-02, -1.4492e-02, -5.2638e-02,  8.0418e-02]],\n",
      "       device='cuda:0', requires_grad=True)), ('fc3.bias', Parameter containing:\n",
      "tensor([-5.3513e-06, -4.2028e-05, -5.6393e-07,  3.3012e-06,  5.0986e-06,\n",
      "         4.7881e-07,  4.4494e-07, -2.1326e-07, -1.2301e-06], device='cuda:0',\n",
      "       requires_grad=True)), ('bn3.weight', Parameter containing:\n",
      "tensor([1.1534, 1.1626, 1.1876, 1.1876, 1.1931, 1.1760, 1.1816, 1.1842, 1.1897],\n",
      "       device='cuda:0', requires_grad=True)), ('bn3.bias', Parameter containing:\n",
      "tensor([-0.1673, -0.1416,  0.0070, -0.0944,  0.1374, -0.1419,  0.0564,  0.0720,\n",
      "         0.1581], device='cuda:0', requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "#功能：加载保存到path中的各层参数到神经网络\n",
    "#from new_nfm_network import NFM\n",
    "path='data/xiaoqiu_gene_5000/model/new_model_param_geng_MLP_5000_with_smoothing.pkl'\n",
    "#nfm = NFM(nfm_config).cuda()\n",
    "net=model\n",
    "print(net)\n",
    "#net = nn.DataParallel(net)\n",
    "#net = net.to(device)\n",
    "net.load_state_dict(torch.load(path),strict=False)\n",
    "net.cuda()\n",
    "\n",
    "print(net)\n",
    "\n",
    "params = list(net.named_parameters())\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53a35e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight : torch.Size([1000, 5510])\n",
      "fc1.bias : torch.Size([1000])\n",
      "bn1.weight : torch.Size([1000])\n",
      "bn1.bias : torch.Size([1000])\n",
      "fc2.weight : torch.Size([100, 1000])\n",
      "fc2.bias : torch.Size([100])\n",
      "bn2.weight : torch.Size([100])\n",
      "bn2.bias : torch.Size([100])\n",
      "fc3.weight : torch.Size([9, 100])\n",
      "fc3.bias : torch.Size([9])\n",
      "bn3.weight : torch.Size([9])\n",
      "bn3.bias : torch.Size([9])\n",
      "weight: {'fc1.weight': Parameter containing:\n",
      "tensor([[-0.0071,  0.0226,  0.0067,  ...,  0.0061,  0.0008,  0.0083],\n",
      "        [ 0.0112,  0.0033,  0.0086,  ..., -0.0064, -0.0263, -0.0135],\n",
      "        [ 0.0033,  0.0028,  0.0062,  ...,  0.0092,  0.0040,  0.0123],\n",
      "        ...,\n",
      "        [ 0.0158,  0.0027, -0.0077,  ...,  0.0106,  0.0087, -0.0044],\n",
      "        [ 0.0024, -0.0018, -0.0066,  ..., -0.0041, -0.0010,  0.0053],\n",
      "        [-0.0233, -0.0059, -0.0031,  ..., -0.0050, -0.0167,  0.0058]],\n",
      "       device='cuda:0', requires_grad=True), 'fc1.bias': Parameter containing:\n",
      "tensor([-6.9882e-07, -2.6899e-07,  8.1030e-07,  8.5366e-07,  9.0213e-07,\n",
      "         1.0310e-06, -1.1119e-06,  1.3993e-07,  2.6477e-06, -8.3633e-07,\n",
      "         1.5823e-06,  3.2739e-08, -8.0105e-07,  3.2181e-07,  6.5521e-07,\n",
      "         1.1072e-06, -3.7159e-08, -2.9549e-07,  7.9424e-07, -1.5349e-07,\n",
      "        -1.0809e-07, -2.9793e-07,  4.9605e-08, -5.4768e-07,  2.2512e-07,\n",
      "        -2.6257e-06, -1.3530e-06, -6.3627e-09, -6.0312e-07,  4.0544e-08,\n",
      "         1.4132e-06, -3.2993e-07, -9.9269e-07,  6.0986e-06,  7.8143e-07,\n",
      "         1.0894e-06, -3.2755e-07, -7.3506e-07,  2.6543e-06,  5.8159e-07,\n",
      "         1.0219e-07, -3.3009e-06,  3.7482e-06,  1.7602e-06, -1.5335e-07,\n",
      "        -8.0566e-07,  1.0251e-06, -9.0085e-07, -1.3945e-06, -4.8892e-07,\n",
      "        -9.5772e-07,  9.8043e-07,  3.3174e-07, -3.0186e-06,  1.6301e-06,\n",
      "        -7.2680e-07, -2.1095e-07, -6.8239e-07, -8.1498e-07,  2.1892e-06,\n",
      "        -3.8102e-08,  1.0525e-07,  1.0316e-07,  1.3128e-07, -5.4499e-07,\n",
      "         7.2199e-07, -8.2204e-07, -2.1970e-07,  6.3371e-07, -3.3037e-07,\n",
      "        -2.0432e-07,  6.0342e-07,  9.3581e-07,  4.1966e-07, -9.3675e-07,\n",
      "        -8.2326e-07, -1.0007e-06, -7.9176e-07, -1.6126e-07,  1.0707e-07,\n",
      "        -4.6105e-07,  3.5876e-07,  1.9515e-07,  3.3749e-07, -9.9945e-07,\n",
      "        -2.7297e-07,  4.7039e-07, -4.9075e-07,  7.3759e-07,  2.1739e-06,\n",
      "        -6.2509e-07,  2.3494e-07, -6.5677e-07, -7.5863e-07, -3.2025e-07,\n",
      "        -2.4698e-07,  8.5422e-07, -2.6947e-07,  9.6027e-07, -1.9681e-07,\n",
      "         7.4629e-07,  4.9016e-07, -1.0445e-06,  6.7267e-08,  5.5358e-07,\n",
      "         2.7574e-07, -3.2573e-07,  1.9441e-07,  2.3534e-07, -4.0928e-07,\n",
      "         3.0169e-07, -5.4619e-07,  9.5774e-07,  2.7907e-07,  4.2801e-07,\n",
      "         6.4882e-07,  4.0857e-07,  4.5026e-07, -3.3983e-07, -7.9529e-07,\n",
      "         9.3095e-07,  1.3581e-07, -1.3790e-06, -7.2270e-07,  2.7501e-07,\n",
      "        -4.0162e-06, -7.1983e-08, -6.8132e-06, -1.0983e-08,  2.7297e-07,\n",
      "         7.1050e-07, -3.7723e-07,  2.1195e-07,  1.2059e-07,  4.5751e-08,\n",
      "        -1.7135e-06,  1.2391e-07, -1.3716e-06,  8.8543e-07,  5.5566e-07,\n",
      "        -4.2930e-09,  6.8189e-07,  2.0816e-07,  1.5788e-07, -1.8879e-07,\n",
      "         7.0980e-08,  1.5034e-06,  2.2388e-08,  1.1464e-06,  4.3852e-07,\n",
      "         1.0515e-06,  1.8240e-08, -5.6958e-07,  1.2202e-06, -1.4154e-06,\n",
      "        -2.4044e-07, -5.7624e-07,  1.5692e-06,  6.2085e-07, -1.1025e-06,\n",
      "        -3.5974e-06, -9.5341e-08,  4.3056e-07,  1.5884e-06,  6.8212e-07,\n",
      "         1.4045e-06,  3.9323e-09,  7.7353e-08,  6.9484e-07, -7.5226e-07,\n",
      "         4.1261e-07,  1.0829e-07,  1.3489e-06, -3.6994e-07,  1.7748e-09,\n",
      "         1.5067e-06, -2.7580e-07, -8.3317e-07, -4.4906e-07, -1.0576e-06,\n",
      "        -4.2029e-07, -4.0817e-07, -8.7643e-07,  1.3577e-07,  2.2620e-07,\n",
      "         2.1513e-06,  2.4347e-06, -6.9374e-07,  7.5388e-07,  6.8778e-07,\n",
      "        -5.2929e-07,  2.0805e-07,  9.0107e-07, -3.4202e-07,  7.5848e-07,\n",
      "         9.1864e-07,  2.3803e-07,  3.0997e-06, -7.7156e-08, -2.7664e-06,\n",
      "        -5.3873e-07,  5.1489e-07, -9.7762e-07, -7.3466e-07,  6.7091e-07,\n",
      "         1.7482e-07, -8.5068e-07,  1.0490e-06, -1.0328e-06, -4.2884e-08,\n",
      "        -3.7965e-07,  4.5358e-07, -7.0881e-07, -3.3551e-07,  6.2892e-07,\n",
      "        -2.8708e-07, -3.3992e-08, -2.2546e-07, -7.3460e-07,  4.2720e-07,\n",
      "        -7.7402e-07, -1.0662e-06,  6.3793e-07,  1.0270e-06, -2.9972e-06,\n",
      "         1.9595e-07, -8.6304e-07, -8.1025e-07,  2.2966e-07, -1.6556e-07,\n",
      "        -4.2414e-07, -7.3237e-07, -6.3445e-07,  3.5447e-08, -8.8888e-07,\n",
      "        -2.0940e-07, -6.0885e-07, -7.1649e-08, -2.5346e-07,  1.3332e-06,\n",
      "        -7.2160e-07, -1.6407e-07, -2.9786e-07, -1.4149e-06, -3.1207e-07,\n",
      "         1.2857e-06, -8.5549e-08, -5.8488e-07, -9.4364e-07,  7.6336e-07,\n",
      "        -1.8732e-06,  1.8733e-07, -1.5588e-07,  2.2154e-07,  2.7262e-07,\n",
      "         5.7630e-07, -9.1920e-07,  8.6708e-07,  8.2684e-07, -2.7961e-07,\n",
      "         1.0328e-06,  4.0242e-07,  2.7849e-07,  3.7801e-07,  6.0539e-07,\n",
      "        -9.4969e-07,  1.1718e-06, -6.1939e-07, -2.4652e-06, -4.1460e-07,\n",
      "        -7.3033e-07, -7.0077e-08, -3.0192e-07,  4.4409e-07,  9.9201e-07,\n",
      "        -4.6466e-08,  7.1938e-07, -8.2018e-07, -3.4136e-07, -2.1364e-07,\n",
      "        -1.9295e-07, -2.9756e-07, -5.0265e-08,  8.4939e-07, -1.8397e-06,\n",
      "        -1.5484e-06,  1.8158e-06, -3.6173e-09,  8.4895e-07,  7.8938e-07,\n",
      "         5.7732e-07, -4.5594e-07,  1.2884e-06,  7.1637e-08,  2.2988e-08,\n",
      "         1.2840e-07,  1.6844e-06, -2.2962e-07,  7.5902e-07, -5.7387e-07,\n",
      "        -3.4304e-07,  9.3963e-07, -3.9630e-07, -4.9163e-07, -3.5397e-08,\n",
      "         1.2029e-06, -1.8965e-07, -1.9863e-07,  5.4273e-07,  6.5835e-07,\n",
      "        -1.5649e-07, -9.9806e-07, -1.4695e-08, -7.4624e-08,  6.8524e-08,\n",
      "        -1.8598e-08, -1.9289e-06, -7.3057e-08,  2.0285e-07,  8.3566e-07,\n",
      "         6.6813e-07,  1.9255e-07,  6.0011e-07, -2.3150e-06, -7.8850e-07,\n",
      "        -1.1552e-05, -4.1590e-07,  7.5859e-08, -1.4535e-06, -5.8105e-07,\n",
      "        -8.2751e-07,  8.4310e-08,  1.3154e-07,  1.0055e-07,  3.8739e-07,\n",
      "        -6.4194e-07, -8.2646e-09,  1.5798e-06, -6.2079e-07, -7.6829e-08,\n",
      "         4.5579e-07, -8.8114e-07, -4.3143e-07, -3.6572e-07, -4.9915e-06,\n",
      "        -4.3417e-07, -1.0027e-06, -9.2548e-06, -3.1537e-07, -8.3203e-07,\n",
      "         3.4578e-07,  7.7671e-08, -1.0176e-06,  4.3975e-07,  2.3135e-07,\n",
      "        -4.0779e-07,  8.8287e-07,  3.7118e-06, -7.5253e-07,  3.6635e-07,\n",
      "         2.5499e-07,  2.5784e-07, -2.9376e-07, -1.4026e-08, -6.5250e-06,\n",
      "        -5.0427e-07, -2.3793e-08, -7.4989e-07, -2.5577e-07,  5.5148e-07,\n",
      "         2.1093e-07,  2.6596e-06,  3.0547e-06, -3.6524e-08, -4.7243e-07,\n",
      "         1.3866e-07,  6.4190e-07,  6.7591e-07,  6.9429e-07,  1.0400e-06,\n",
      "        -1.2945e-08, -1.0463e-06,  4.0131e-07, -4.5261e-07,  8.5238e-07,\n",
      "         3.5565e-07, -1.4776e-06, -3.3425e-07,  4.4004e-07, -3.5729e-07,\n",
      "        -2.0426e-07, -4.1705e-07, -9.5760e-07,  7.7201e-08,  4.8814e-08,\n",
      "         2.4671e-06,  6.5296e-07,  3.9409e-07,  3.4171e-07, -1.1931e-06,\n",
      "        -8.5009e-08,  5.6258e-07, -2.5284e-06, -3.3386e-07, -5.0151e-08,\n",
      "        -4.9659e-07,  8.2533e-07, -1.0613e-07,  1.4218e-06, -3.3380e-06,\n",
      "         5.7512e-07,  1.1131e-07, -3.8547e-07, -2.3392e-06,  4.7063e-07,\n",
      "         3.4674e-06,  2.0097e-07,  1.5356e-07, -1.9232e-07,  4.5071e-07,\n",
      "         7.1239e-07,  7.0172e-07,  1.9325e-07,  3.1520e-07, -2.3333e-07,\n",
      "        -4.4505e-06, -1.0240e-06, -7.9791e-07,  1.3002e-07,  4.6089e-07,\n",
      "         1.4741e-07,  3.9799e-08,  1.7972e-08,  1.3455e-06, -5.8873e-07,\n",
      "        -1.5102e-08, -2.7483e-07,  8.2221e-08,  3.8960e-06, -1.4610e-07,\n",
      "         5.9453e-07,  1.1438e-06, -7.5000e-08, -5.2905e-07,  9.8734e-07,\n",
      "        -1.3872e-07,  2.2079e-06,  5.5721e-07, -2.4301e-07,  1.0272e-06,\n",
      "         1.3930e-06,  3.4875e-08,  1.3044e-07, -6.2205e-07, -1.0699e-07,\n",
      "        -9.0052e-07,  5.4247e-07, -1.5665e-07,  5.7487e-07,  8.3730e-07,\n",
      "        -6.2705e-07, -1.1535e-07, -1.8488e-06,  9.8521e-08,  9.0204e-07,\n",
      "        -5.9315e-07, -4.4566e-07,  5.2172e-07,  1.0120e-06,  5.2290e-07,\n",
      "        -1.8143e-06, -1.0690e-06,  5.4521e-06,  5.4493e-07,  6.5848e-07,\n",
      "         1.2399e-06,  5.0599e-07, -2.0124e-06,  1.0059e-06, -1.3326e-06,\n",
      "        -1.9207e-06, -8.2924e-07,  5.2665e-07,  6.6639e-07,  6.6754e-08,\n",
      "        -2.7482e-07,  2.2510e-07,  1.3629e-06,  8.5843e-07,  6.2138e-08,\n",
      "        -3.6030e-06,  5.3702e-07, -1.1014e-07, -1.1277e-06,  1.2520e-05,\n",
      "         3.6143e-07, -8.3451e-07,  3.7911e-07, -7.2078e-07, -6.8006e-07,\n",
      "         6.3652e-07, -7.7211e-07,  1.3363e-07,  2.5632e-07, -1.6601e-07,\n",
      "        -1.1743e-06,  4.7935e-07, -2.6816e-07,  6.7438e-07,  4.8896e-07,\n",
      "        -3.2405e-07, -2.9730e-07,  1.6173e-06, -6.6000e-07,  1.5177e-07,\n",
      "        -1.5662e-06, -7.5632e-07,  4.2078e-07, -2.8281e-07, -3.9261e-07,\n",
      "        -7.8010e-07, -2.3381e-07,  7.2913e-07,  1.4918e-06, -9.0766e-07,\n",
      "        -4.4877e-07,  1.0481e-06, -3.4451e-07,  6.4672e-07,  3.1396e-06,\n",
      "         4.5661e-06, -8.9576e-07,  8.7879e-07,  1.7085e-07, -9.1994e-07,\n",
      "        -4.7057e-07,  3.0186e-07,  1.3732e-08, -2.5951e-07, -1.1283e-07,\n",
      "         2.8453e-07,  6.1074e-07, -2.6302e-07,  2.0798e-06, -5.6086e-07,\n",
      "        -1.3454e-06,  6.3911e-07,  4.5933e-07,  1.6987e-08, -4.0888e-07,\n",
      "         7.3996e-07,  2.8235e-07, -5.1590e-07,  1.0404e-07, -2.6387e-06,\n",
      "        -4.8913e-07, -1.5157e-06, -1.2248e-06, -6.0141e-07,  7.7334e-07,\n",
      "        -8.9556e-07, -2.3853e-08,  1.1272e-06,  2.5636e-07,  6.9936e-07,\n",
      "        -3.4572e-07, -7.6482e-06, -5.5057e-08,  1.5750e-06, -4.3843e-07,\n",
      "         1.7181e-07,  1.7422e-07, -5.8251e-08, -1.9545e-07,  4.8593e-07,\n",
      "         3.7476e-07, -2.7670e-07,  7.4956e-07,  3.0760e-07,  2.6642e-07,\n",
      "         8.9564e-07, -4.2513e-07,  5.6268e-07,  1.8236e-07,  2.8192e-07,\n",
      "        -1.1040e-06,  4.9150e-07, -9.6898e-07,  4.8238e-08,  1.0606e-07,\n",
      "         6.2664e-07,  3.3388e-07,  1.9975e-07,  2.4305e-07, -1.3630e-07,\n",
      "        -3.2160e-07,  8.6300e-07,  2.1586e-07, -3.3278e-06,  6.7008e-07,\n",
      "        -3.5501e-07, -2.5081e-06, -2.6088e-07,  4.2426e-07, -4.3752e-07,\n",
      "        -2.0852e-06, -8.7480e-07,  1.5610e-06,  2.8196e-07,  5.6376e-07,\n",
      "         1.2709e-06,  4.7974e-07, -9.9742e-08, -5.2094e-07,  6.5614e-07,\n",
      "        -4.9677e-07, -5.0873e-07, -4.9499e-07,  1.6267e-07,  1.0077e-07,\n",
      "        -7.9744e-07, -8.3274e-07,  4.7428e-07, -1.6749e-06, -2.1637e-06,\n",
      "        -5.8099e-07,  8.8110e-07, -6.3101e-07,  1.4018e-07, -8.9142e-07,\n",
      "         2.0292e-07, -3.5839e-07,  4.2248e-07,  2.7902e-07,  1.2713e-07,\n",
      "        -9.5295e-07, -3.1296e-07,  4.3396e-07, -1.5450e-07, -1.3918e-06,\n",
      "         1.3619e-07, -4.9259e-07,  4.7428e-07, -5.9998e-08, -4.1297e-07,\n",
      "         2.4890e-07,  2.6178e-07,  5.2925e-07, -1.2296e-06, -1.5017e-06,\n",
      "         3.9982e-07,  5.5813e-07, -4.5904e-07,  3.9556e-08, -2.9175e-07,\n",
      "         7.7351e-07,  8.0566e-08, -6.2524e-07, -1.0226e-06,  5.2641e-07,\n",
      "        -1.9703e-07, -3.6569e-07, -1.7680e-07, -1.6894e-07, -7.6772e-06,\n",
      "         6.0277e-07,  1.3663e-07, -1.2967e-07, -4.3583e-07,  3.9250e-07,\n",
      "        -1.1420e-06, -1.4592e-07,  4.6781e-07, -5.0913e-07,  9.1059e-07,\n",
      "        -9.1414e-07, -2.8451e-08, -2.0719e-07,  5.2671e-07, -2.7457e-07,\n",
      "         3.0603e-08, -7.5894e-07, -5.8078e-07,  2.0384e-07,  9.6611e-07,\n",
      "         5.9529e-07, -1.3024e-06,  1.4675e-08,  2.3875e-07,  2.6797e-07,\n",
      "        -8.6598e-07, -1.0297e-06, -2.0240e-07, -6.3124e-07,  6.3207e-07,\n",
      "         7.9161e-07,  1.3936e-07, -1.4620e-07,  5.7967e-08, -1.3951e-07,\n",
      "         2.0407e-07, -2.7765e-07, -1.1935e-06, -4.8202e-07,  5.0147e-07,\n",
      "        -1.2604e-08,  4.9160e-07,  4.6819e-08,  8.5745e-07,  1.3404e-07,\n",
      "         9.2482e-07, -7.9300e-08,  7.0950e-07,  9.5215e-07, -4.3328e-07,\n",
      "        -4.8412e-07,  2.0908e-07, -5.6180e-07,  4.8449e-07,  1.8087e-08,\n",
      "        -1.6191e-07, -4.3750e-09, -2.4677e-06, -1.1585e-06,  5.3047e-07,\n",
      "        -8.9748e-08, -1.2321e-06,  2.6902e-07,  2.6538e-06,  4.4683e-06,\n",
      "        -7.1192e-07,  2.1028e-06, -6.7616e-07, -7.0786e-07,  6.7668e-07,\n",
      "         9.0781e-07,  8.8531e-07,  6.6150e-08,  5.9673e-07,  1.0273e-06,\n",
      "        -2.3834e-07,  1.1724e-06,  6.8072e-07, -1.0500e-07,  9.9460e-07,\n",
      "        -3.6784e-08, -1.5195e-07, -1.1886e-06,  1.4864e-06, -1.9672e-06,\n",
      "        -4.0365e-07, -4.5415e-07,  1.1200e-06, -4.2898e-07,  8.8392e-07,\n",
      "        -1.8062e-07, -5.3640e-07,  8.1148e-07, -2.6238e-07,  4.5195e-07,\n",
      "         3.9491e-07, -5.4123e-08, -1.1430e-06,  1.8127e-06, -2.6451e-06,\n",
      "        -1.5866e-06, -4.9292e-08,  5.5866e-08, -3.3959e-07, -4.3556e-07,\n",
      "        -1.2535e-06, -6.4011e-08, -7.4341e-07, -1.0648e-06,  4.3167e-07,\n",
      "         8.2849e-07, -7.2115e-07,  4.6192e-07, -7.8579e-08,  6.3024e-09,\n",
      "         1.9304e-07, -8.0123e-07,  1.7564e-07, -1.0539e-06, -4.9572e-09,\n",
      "         7.0139e-07, -1.1477e-06,  2.6564e-07,  5.3125e-07, -2.6794e-07,\n",
      "         3.6768e-07,  5.9484e-07, -7.1409e-07, -1.3739e-06, -7.6663e-07,\n",
      "         8.3918e-07, -1.0035e-06,  4.8876e-07,  9.2643e-07, -1.2366e-06,\n",
      "         9.1920e-07,  2.1778e-07,  4.5145e-07,  1.0382e-07, -1.2926e-06,\n",
      "         7.1020e-07, -4.2538e-07,  4.3956e-06,  5.9537e-07, -1.0868e-07,\n",
      "         7.5168e-08,  1.1072e-07, -6.7505e-07, -6.9882e-07, -2.7511e-07,\n",
      "        -1.1064e-07,  2.4367e-07, -7.5319e-07,  7.8294e-07,  7.2421e-07,\n",
      "        -2.6758e-07, -1.0066e-06,  1.3092e-06, -3.8259e-07, -2.6397e-06,\n",
      "        -5.8505e-07, -1.4077e-07,  3.2280e-07,  3.8678e-07,  8.8808e-08,\n",
      "         4.8825e-07, -5.8759e-07,  3.8361e-07, -1.0037e-07, -6.5787e-07,\n",
      "        -3.3920e-06, -6.4205e-07, -4.4546e-07, -1.3651e-07, -2.8988e-07,\n",
      "        -1.0057e-06,  3.2406e-07, -6.8947e-07, -5.7151e-08, -1.1492e-06,\n",
      "        -4.0399e-06,  5.3071e-07, -1.7006e-07,  5.0435e-07, -3.2335e-07,\n",
      "         2.2411e-07, -7.2779e-07, -2.5487e-06,  2.2149e-07,  7.5234e-07,\n",
      "         2.5827e-07, -1.1025e-06,  2.4484e-07,  2.8458e-07,  4.2671e-07,\n",
      "         1.7085e-06,  1.7240e-06, -1.2417e-08, -2.6412e-07,  9.2026e-07,\n",
      "        -8.6333e-07,  2.3996e-07,  1.3107e-07, -1.5339e-07, -2.0375e-06,\n",
      "        -5.6877e-07,  6.2680e-07, -1.0283e-06, -7.8849e-07,  8.3088e-07,\n",
      "         3.2501e-06,  7.2467e-07, -2.1987e-07, -1.9325e-07,  6.4798e-07,\n",
      "         5.8327e-07, -5.4620e-07,  7.3409e-07, -3.8761e-07, -1.5420e-07,\n",
      "        -1.2546e-06,  1.2197e-08, -3.5691e-06,  5.7521e-07, -1.0167e-06,\n",
      "         7.0410e-07,  1.0199e-06, -2.3905e-07, -1.8404e-06, -1.1155e-06,\n",
      "         7.7076e-07,  8.2505e-07,  3.8942e-08,  3.4549e-06,  9.0236e-07,\n",
      "         6.4369e-07, -5.8416e-08,  7.9347e-07, -1.7089e-06, -1.8365e-06,\n",
      "        -3.4087e-06, -4.5301e-07,  5.3141e-07,  2.1419e-06, -2.6781e-07,\n",
      "        -4.1810e-07,  1.1673e-06,  2.2120e-08,  3.4121e-07, -7.8536e-07,\n",
      "         2.0074e-07,  9.6761e-09, -2.8410e-06,  6.0478e-08,  3.4459e-07,\n",
      "        -3.4529e-07, -3.3738e-08, -1.4026e-06, -3.1317e-07,  7.1642e-07,\n",
      "         5.1565e-07,  2.2953e-07, -3.1826e-07, -8.7938e-07, -2.3615e-07,\n",
      "        -2.0086e-07,  8.9397e-07,  1.5382e-07,  9.2431e-07,  2.7900e-07,\n",
      "        -1.0152e-06, -3.4657e-07,  1.0694e-07,  8.9646e-07,  9.0131e-07,\n",
      "        -1.2000e-06, -2.3919e-07,  2.4982e-07,  1.9540e-07,  7.2294e-08,\n",
      "        -2.4972e-07,  1.3116e-07,  1.2600e-07,  8.2083e-07,  2.7010e-07,\n",
      "         7.3065e-07, -3.3724e-06, -2.1547e-07, -5.2645e-07,  4.5689e-07,\n",
      "        -3.2204e-07, -5.0865e-07,  4.9779e-07, -2.5383e-07, -2.1837e-07,\n",
      "         1.4664e-06, -3.4543e-07,  9.0138e-07, -6.3266e-08, -3.9109e-07,\n",
      "        -6.3495e-07,  6.2433e-07, -3.0699e-07, -4.8055e-07, -8.6628e-07,\n",
      "        -4.5726e-07, -3.1861e-07,  3.7119e-07, -3.2894e-06,  1.9971e-07,\n",
      "        -1.1663e-06, -3.2627e-08,  1.1033e-06,  6.5136e-07, -2.8244e-07,\n",
      "        -2.1066e-07, -6.6990e-08, -5.9632e-07,  3.8631e-08, -1.7100e-07,\n",
      "        -4.3386e-07,  5.6542e-07, -1.4681e-06, -2.3941e-08, -3.3437e-06,\n",
      "        -2.3881e-07,  1.2025e-06, -2.4541e-07,  4.3944e-07,  1.0907e-06,\n",
      "         7.6049e-07,  2.2291e-08, -1.8894e-07, -2.0724e-07, -6.8685e-07],\n",
      "       device='cuda:0', requires_grad=True), 'bn1.weight': Parameter containing:\n",
      "tensor([0.9329, 0.9655, 0.9082, 0.9033, 0.9253, 0.9564, 0.9167, 0.9429, 0.9431,\n",
      "        0.9918, 0.9233, 0.9038, 0.9037, 0.9419, 0.9142, 0.8875, 0.9568, 0.9591,\n",
      "        0.9445, 0.9019, 0.9010, 0.9239, 0.9168, 0.9170, 0.8916, 0.9181, 0.9220,\n",
      "        0.9048, 0.9545, 0.9000, 0.9076, 0.9563, 0.9122, 0.9416, 0.9599, 0.9703,\n",
      "        0.9315, 0.9147, 0.9564, 0.9044, 0.9153, 0.9130, 0.9152, 0.9105, 0.8966,\n",
      "        0.9411, 0.9668, 0.9221, 0.9430, 0.9113, 0.9278, 0.9236, 0.9091, 0.9234,\n",
      "        0.9180, 0.9354, 0.9115, 0.9056, 0.8935, 0.9176, 0.8838, 0.9236, 0.9152,\n",
      "        0.9154, 0.9002, 0.9423, 0.9019, 0.9557, 0.9048, 0.9275, 0.9090, 0.9522,\n",
      "        0.9138, 0.9039, 0.9085, 0.9104, 0.9778, 0.9780, 0.9000, 0.9287, 0.9056,\n",
      "        0.9022, 0.9092, 0.9176, 0.9184, 0.9108, 0.9767, 0.9016, 0.9001, 0.9213,\n",
      "        0.9206, 0.8913, 0.9492, 0.9107, 0.9396, 0.9737, 0.9038, 0.9114, 0.9395,\n",
      "        0.9168, 0.9611, 0.9052, 0.9045, 0.9052, 0.9047, 0.9489, 0.9662, 0.9125,\n",
      "        0.9220, 0.8746, 0.9202, 0.9166, 0.9250, 0.9049, 0.9372, 0.9327, 0.9429,\n",
      "        0.8979, 0.9633, 0.9338, 0.9252, 0.9198, 0.9616, 0.9139, 0.8992, 0.9075,\n",
      "        0.9081, 0.9590, 0.9197, 0.9453, 0.9043, 0.9130, 0.9108, 0.9340, 0.9037,\n",
      "        0.9248, 0.9465, 0.9924, 0.9450, 0.9356, 0.9219, 0.9065, 0.8951, 0.9788,\n",
      "        0.9270, 0.9521, 0.9291, 0.8920, 0.9098, 0.8999, 0.9278, 0.9091, 0.9282,\n",
      "        0.9102, 0.9218, 0.9214, 0.9011, 0.9053, 0.9077, 0.9009, 0.9133, 0.9033,\n",
      "        0.8909, 0.9282, 0.9325, 0.9388, 0.9101, 0.9014, 0.8955, 0.8993, 0.8928,\n",
      "        0.8888, 0.9500, 0.9528, 0.8865, 0.9193, 0.9309, 0.9010, 0.9020, 0.9497,\n",
      "        0.8948, 0.8928, 0.9227, 0.8929, 0.9222, 0.9203, 0.9362, 0.9167, 0.9056,\n",
      "        0.9228, 0.9171, 0.9253, 0.9195, 0.8996, 0.9012, 0.9149, 0.9187, 0.9561,\n",
      "        0.9204, 0.9686, 0.9063, 0.9160, 0.9287, 0.9110, 0.9278, 0.8925, 0.8958,\n",
      "        0.8893, 0.9307, 0.8979, 0.9224, 0.9021, 0.9312, 0.8987, 0.9446, 0.9052,\n",
      "        0.9034, 0.9435, 0.9244, 0.9053, 0.9569, 0.8936, 0.9175, 0.9121, 0.9179,\n",
      "        0.9185, 0.9187, 0.9427, 0.9452, 0.9572, 0.9058, 0.9098, 0.9244, 0.8943,\n",
      "        0.9102, 0.8916, 0.9070, 0.9102, 0.8963, 0.8971, 0.9033, 0.9070, 0.9060,\n",
      "        0.9269, 0.9221, 0.9257, 0.9009, 0.9029, 0.9902, 0.9087, 0.9136, 0.8953,\n",
      "        0.8859, 0.8911, 0.9587, 0.8831, 0.9246, 0.9326, 0.9084, 0.9104, 0.8905,\n",
      "        0.8850, 0.8863, 0.9309, 0.9083, 0.8995, 0.9178, 0.9227, 0.9156, 0.8967,\n",
      "        0.8936, 0.9199, 0.9237, 0.9253, 0.9340, 0.8871, 0.9043, 0.9054, 0.9252,\n",
      "        0.8935, 0.9336, 0.9028, 0.9339, 0.9145, 0.9204, 0.9047, 0.9478, 0.9217,\n",
      "        0.9383, 0.9116, 0.9222, 0.9036, 0.9197, 0.9151, 0.9028, 0.9121, 0.9256,\n",
      "        0.9440, 0.9440, 0.9170, 0.9143, 0.9105, 0.8937, 0.9075, 0.9182, 0.8928,\n",
      "        0.8981, 0.9040, 0.9021, 0.9002, 0.9353, 0.9179, 0.9115, 0.9460, 0.9525,\n",
      "        0.9201, 0.9211, 0.8997, 0.9036, 0.8979, 0.9725, 0.9698, 0.9083, 0.9499,\n",
      "        0.9236, 0.9561, 0.9104, 0.9099, 0.9724, 0.8964, 0.9177, 0.9023, 0.9246,\n",
      "        0.9159, 0.9406, 0.9000, 0.9581, 0.9264, 0.9203, 0.9104, 0.8897, 0.9457,\n",
      "        0.9209, 0.9039, 0.9678, 0.9737, 0.9094, 0.9433, 0.9168, 0.9161, 0.9014,\n",
      "        0.9128, 0.9063, 0.8970, 0.9073, 0.9728, 0.9176, 0.9495, 0.9472, 0.8993,\n",
      "        0.8878, 0.9183, 0.9418, 0.9138, 0.9526, 0.9200, 0.9066, 0.8937, 0.9240,\n",
      "        0.9288, 0.8885, 0.9268, 0.9310, 0.9400, 0.9479, 0.9063, 0.9233, 0.9597,\n",
      "        0.9205, 0.8980, 0.9019, 0.9173, 0.9223, 0.8983, 0.9041, 0.9138, 0.9095,\n",
      "        0.9037, 0.9293, 0.9657, 0.9094, 0.9162, 0.9154, 0.9034, 0.9053, 0.9621,\n",
      "        0.9110, 0.9154, 0.9299, 0.9214, 0.8992, 0.9023, 0.9440, 0.8839, 0.9187,\n",
      "        0.9383, 0.9208, 0.9078, 0.9000, 0.9390, 0.9116, 0.9046, 0.9229, 0.9186,\n",
      "        0.9068, 0.9314, 0.9026, 0.9219, 0.8894, 0.9171, 0.9161, 0.8904, 0.9233,\n",
      "        0.9274, 0.9296, 0.9338, 0.8962, 0.8975, 0.9287, 0.8917, 0.9400, 0.9176,\n",
      "        0.9163, 0.9284, 0.8997, 0.8964, 0.9559, 0.8785, 0.9520, 0.9304, 0.8882,\n",
      "        0.9252, 0.9267, 0.9051, 0.9089, 0.9289, 0.9290, 0.9168, 0.9029, 0.9253,\n",
      "        0.9081, 0.8914, 0.9102, 0.8985, 0.9129, 0.8871, 0.9120, 0.9654, 0.9273,\n",
      "        0.9175, 0.9095, 0.8850, 0.9222, 0.9281, 0.9075, 0.9124, 0.9016, 0.9157,\n",
      "        0.9369, 0.9133, 0.9833, 0.9180, 0.9194, 0.9276, 0.9526, 0.9268, 0.8898,\n",
      "        0.9187, 0.9611, 0.9566, 0.9506, 0.9165, 0.9192, 0.9219, 0.9239, 0.9163,\n",
      "        0.9202, 0.9420, 0.9245, 0.9157, 0.9122, 0.8928, 0.9202, 0.9033, 0.9319,\n",
      "        0.9064, 0.9230, 0.9001, 0.9389, 0.9280, 0.9137, 0.9007, 0.9031, 0.9645,\n",
      "        0.8920, 0.9187, 0.9329, 0.9037, 0.9164, 0.9277, 0.9030, 0.9180, 0.9118,\n",
      "        0.8970, 0.9164, 0.9157, 0.9395, 0.9076, 0.9481, 0.9067, 0.8955, 0.9126,\n",
      "        0.9243, 0.9584, 0.9081, 0.9026, 0.9419, 0.9130, 0.9282, 0.9372, 0.9162,\n",
      "        0.9008, 0.9685, 0.9108, 0.9169, 0.9367, 0.9271, 0.8841, 0.8932, 0.9091,\n",
      "        0.8972, 0.9312, 0.9362, 0.9219, 0.9129, 0.9182, 0.9330, 0.9201, 0.9071,\n",
      "        0.9141, 0.9027, 0.9123, 0.9010, 0.9047, 0.9332, 0.9468, 0.9058, 0.9125,\n",
      "        0.9152, 0.9317, 0.9297, 0.9457, 0.9133, 0.9081, 0.9157, 0.9320, 0.9626,\n",
      "        0.8976, 0.9274, 0.9210, 0.8942, 0.9158, 0.9230, 0.9109, 0.8815, 0.9344,\n",
      "        0.8904, 0.9101, 0.9171, 0.9199, 0.9090, 0.9270, 0.9175, 0.9203, 0.9095,\n",
      "        0.9477, 0.9384, 0.9319, 0.9130, 0.9212, 0.9237, 0.9134, 0.9377, 0.9477,\n",
      "        0.9033, 0.9151, 0.9194, 0.9177, 0.9445, 0.9048, 0.9014, 1.0092, 0.9251,\n",
      "        0.9340, 0.9264, 0.9271, 0.8958, 0.9078, 0.9199, 0.8979, 0.9718, 0.9674,\n",
      "        0.9076, 0.9091, 0.9481, 0.9170, 0.9275, 0.8998, 0.8900, 0.9152, 0.9165,\n",
      "        0.9284, 0.9202, 0.9447, 0.9025, 0.9023, 0.9260, 0.9164, 0.9120, 0.9210,\n",
      "        0.9021, 0.9218, 0.9238, 0.9312, 0.9126, 0.9571, 0.9220, 0.9483, 0.9567,\n",
      "        0.9085, 0.9283, 0.9046, 0.9058, 0.9079, 0.8912, 0.9149, 0.9053, 0.9099,\n",
      "        0.9736, 0.9043, 0.9105, 0.8942, 0.9063, 0.9145, 0.9041, 0.9085, 0.8954,\n",
      "        0.9438, 0.9499, 0.9039, 0.9278, 0.9172, 0.9269, 0.9492, 0.9448, 0.9055,\n",
      "        0.9073, 0.9436, 0.9014, 0.8927, 0.9163, 0.9056, 0.9158, 0.9101, 0.9031,\n",
      "        0.8929, 0.9279, 0.9112, 0.9455, 0.9043, 0.9619, 0.9349, 0.8981, 0.9043,\n",
      "        0.9510, 0.9099, 0.9075, 0.8907, 0.9132, 0.9051, 0.9074, 0.9285, 0.8928,\n",
      "        0.9384, 0.9551, 0.9087, 0.9227, 0.9072, 0.9158, 0.9055, 0.8922, 0.9170,\n",
      "        0.9421, 0.9008, 0.9222, 0.9370, 0.9355, 0.9384, 0.9134, 0.9106, 0.9437,\n",
      "        0.9174, 0.9061, 0.9770, 0.9179, 0.8872, 0.9362, 0.8919, 0.9150, 0.9223,\n",
      "        0.9065, 0.8951, 0.9288, 0.9071, 0.9146, 0.9049, 0.9037, 0.8969, 0.9560,\n",
      "        0.9147, 0.9213, 0.9516, 0.9480, 0.9203, 0.9328, 0.9455, 0.9170, 0.8978,\n",
      "        0.9263, 0.9120, 0.9086, 0.8856, 0.9155, 0.8967, 0.9415, 0.9173, 0.9084,\n",
      "        0.9413, 0.9429, 0.9822, 0.9230, 0.9221, 0.9285, 0.9104, 0.9117, 0.9163,\n",
      "        0.9002, 0.9022, 0.8928, 0.9190, 0.9348, 0.8875, 0.9491, 0.9244, 0.9259,\n",
      "        0.9063, 0.9148, 0.9218, 0.9130, 0.8945, 0.9132, 0.8995, 0.9244, 0.9209,\n",
      "        0.8926, 0.9363, 0.9326, 0.9350, 0.9019, 0.9563, 0.9560, 0.8857, 0.8883,\n",
      "        0.9062, 0.9379, 0.9165, 0.9205, 0.8944, 0.9032, 0.8952, 0.9412, 0.9070,\n",
      "        0.9517, 0.8957, 0.9005, 0.9229, 0.9077, 0.8989, 0.9124, 0.9443, 0.9108,\n",
      "        0.9159, 0.9036, 0.9080, 0.9050, 0.9110, 0.9275, 0.9345, 0.9135, 0.9234,\n",
      "        0.8953, 0.9308, 0.9290, 0.9305, 0.8976, 0.9164, 0.9118, 0.8927, 0.9194,\n",
      "        0.8891, 0.8994, 0.9324, 0.8944, 0.9104, 0.9364, 0.8904, 0.9553, 0.9256,\n",
      "        0.9312, 0.9243, 0.9062, 0.9877, 0.9031, 0.9263, 0.8968, 0.9606, 0.9292,\n",
      "        0.8990, 0.9284, 0.9013, 0.9149, 0.8974, 0.9186, 0.9098, 0.8978, 0.9137,\n",
      "        0.9025, 0.9138, 0.9141, 0.8972, 0.9133, 0.9049, 0.9266, 0.9740, 0.9164,\n",
      "        0.9289, 0.9201, 0.9558, 0.9336, 0.8946, 0.9155, 0.9385, 0.9005, 0.9318,\n",
      "        0.8717, 0.9369, 0.9206, 0.9028, 0.9510, 0.9359, 0.9075, 0.9036, 0.9063,\n",
      "        0.9147, 0.9102, 0.9167, 0.9760, 0.8900, 0.9155, 0.9589, 0.9091, 0.9039,\n",
      "        0.9360, 0.8966, 0.9597, 0.9930, 0.9314, 0.9422, 0.9270, 0.9236, 0.9173,\n",
      "        0.8999, 0.9086, 0.9034, 0.9577, 0.8979, 0.9425, 0.8965, 0.9082, 0.9222,\n",
      "        0.9120, 0.9352, 0.9296, 0.9352, 0.9096, 0.8997, 0.9455, 0.9120, 0.9250,\n",
      "        0.8943, 0.8787, 0.9494, 0.8995, 0.8988, 0.9138, 0.9067, 0.9015, 0.9300,\n",
      "        0.8987, 0.9286, 0.9225, 0.9240, 0.9242, 0.9127, 0.9023, 0.9586, 0.9132,\n",
      "        0.9494, 0.9542, 0.9089, 0.9227, 0.9525, 0.9307, 0.8900, 0.9619, 0.8985,\n",
      "        0.8971, 0.9419, 0.9414, 0.8995, 0.9283, 0.9040, 0.9363, 0.8971, 0.9033,\n",
      "        0.9466, 0.8877, 0.9094, 0.8896, 0.9169, 0.9442, 0.9273, 0.9090, 0.9283,\n",
      "        0.9021, 0.9380, 0.9688, 0.8994, 0.9082, 0.9108, 0.9555, 0.9140, 0.8932,\n",
      "        0.9222, 0.9122, 0.9130, 0.9137, 0.8985, 0.9010, 0.9138, 0.9411, 0.9176,\n",
      "        0.9170, 0.9704, 0.9425, 0.9233, 0.8972, 0.9493, 0.9222, 0.9465, 0.9459,\n",
      "        0.9012, 0.9467, 0.9031, 0.9094, 0.9327, 0.8822, 0.9331, 0.9369, 0.9417,\n",
      "        0.9119, 0.9320, 0.9216, 0.9551, 0.9671, 0.9005, 0.9201, 0.8743, 0.9055,\n",
      "        0.9194], device='cuda:0', requires_grad=True), 'bn1.bias': Parameter containing:\n",
      "tensor([ 6.6689e-03, -1.6602e-02, -5.4948e-03, -2.7176e-02, -4.1650e-03,\n",
      "        -3.3254e-02, -3.4726e-02, -2.1131e-02, -2.6706e-02, -3.9183e-03,\n",
      "        -1.9633e-02, -3.4454e-02, -8.2131e-03, -1.1047e-02, -2.1954e-02,\n",
      "        -1.1030e-02, -9.0473e-03, -2.1881e-02, -1.7709e-02, -3.2082e-02,\n",
      "        -2.7922e-02, -1.2686e-02, -2.6884e-02, -4.0399e-03, -2.3933e-02,\n",
      "        -3.9135e-02, -1.4906e-02, -2.8614e-02, -1.4463e-02, -2.8437e-02,\n",
      "        -1.8314e-02, -2.8647e-02, -2.5134e-02, -2.5696e-02, -2.0498e-02,\n",
      "         8.9429e-04, -1.6452e-02, -7.8580e-03, -2.5155e-02, -2.7913e-02,\n",
      "        -1.2588e-02, -3.3665e-02, -1.7672e-02, -3.1109e-02, -1.5901e-02,\n",
      "         3.4038e-04, -2.6998e-02, -2.1650e-02, -1.4829e-02, -2.8088e-02,\n",
      "        -3.3618e-02, -2.1161e-02, -8.0722e-03, -2.8400e-02, -7.0260e-03,\n",
      "        -1.2873e-02, -2.4722e-02, -2.7200e-02, -3.5426e-02, -2.8341e-02,\n",
      "        -5.6587e-03, -1.9965e-02, -1.0036e-02, -3.0685e-02, -3.1290e-02,\n",
      "        -7.5864e-03, -1.8066e-02,  1.2298e-02, -1.9296e-02, -2.3496e-02,\n",
      "        -3.0459e-02, -1.4967e-02, -3.0481e-02, -2.3555e-02, -3.6288e-02,\n",
      "        -2.4955e-02,  5.5625e-04, -2.2177e-02, -6.5034e-03, -9.9328e-03,\n",
      "        -2.0603e-02, -2.2939e-02, -9.3443e-03, -2.6097e-02, -3.0940e-02,\n",
      "        -1.6017e-02, -3.4319e-03, -3.0075e-02, -2.1629e-02, -2.9975e-02,\n",
      "        -2.2618e-02, -3.2552e-02, -6.2137e-03, -1.9331e-03, -4.0843e-03,\n",
      "        -2.5276e-02, -2.3490e-02, -2.6656e-02, -1.7192e-02, -2.6928e-02,\n",
      "        -2.5907e-02, -1.5416e-02, -5.0497e-03,  3.4951e-03, -1.6449e-02,\n",
      "        -1.0254e-02, -1.6949e-02, -2.2906e-02, -2.9139e-02, -3.7332e-02,\n",
      "        -1.0969e-02, -2.6737e-02, -7.2003e-03,  8.1855e-03, -4.4811e-03,\n",
      "        -1.6956e-02, -4.1586e-03, -2.1208e-02, -1.3265e-02, -2.0140e-02,\n",
      "        -1.5241e-02, -3.0337e-02, -1.1982e-02, -1.5729e-02, -3.7351e-02,\n",
      "        -1.4943e-02, -3.8329e-03, -1.8076e-02, -7.7787e-03, -3.1826e-02,\n",
      "        -1.1243e-02,  9.9568e-03, -1.5013e-02, -2.4823e-02, -2.3724e-03,\n",
      "        -2.9500e-02,  5.9835e-03, -2.4640e-02, -1.3072e-02,  6.6044e-03,\n",
      "        -1.2382e-02, -2.0628e-02, -2.4075e-02, -5.6702e-03, -8.3818e-03,\n",
      "        -1.4208e-02, -2.7129e-02, -2.2061e-02, -1.4759e-02, -2.5010e-02,\n",
      "        -8.4857e-03, -2.8834e-02, -1.8515e-02, -1.4737e-02, -2.9439e-02,\n",
      "        -8.5647e-03, -3.5503e-03, -1.5761e-02, -3.3473e-02, -2.4960e-02,\n",
      "        -2.1153e-02, -2.1765e-02, -1.9017e-02, -2.8667e-02, -2.1223e-02,\n",
      "        -1.7195e-03, -2.5831e-02, -2.3141e-02, -1.8350e-02, -4.6480e-03,\n",
      "        -2.0043e-02, -1.2598e-02,  1.0023e-02, -1.8741e-02, -1.5320e-02,\n",
      "        -1.1675e-02, -2.2526e-02, -2.9444e-02, -2.1160e-02, -6.4009e-05,\n",
      "        -1.7707e-02, -1.1482e-02, -5.1061e-03, -1.3667e-02, -3.2531e-02,\n",
      "        -1.1863e-02, -2.7200e-02, -1.4164e-02, -3.6916e-02, -2.7613e-02,\n",
      "        -3.2167e-02, -3.9048e-02, -1.8391e-02, -3.7944e-02, -2.9016e-02,\n",
      "        -3.4725e-03, -6.7732e-03, -9.9441e-03, -3.5434e-02, -1.2550e-02,\n",
      "        -1.3879e-02, -2.3319e-02, -5.3937e-03, -4.5228e-02, -1.5721e-02,\n",
      "        -2.4581e-02, -3.0884e-02, -3.2848e-02, -2.3539e-02, -4.3454e-02,\n",
      "        -1.7565e-02, -2.3445e-02, -2.6411e-02, -8.3594e-03, -2.7031e-02,\n",
      "        -2.1692e-02, -3.4528e-02, -5.0326e-04, -1.0604e-02, -1.4417e-02,\n",
      "        -1.1024e-04, -3.1011e-02, -1.2172e-02,  4.6815e-03, -2.0905e-02,\n",
      "        -1.6512e-02, -3.1500e-02, -1.0314e-02, -1.4430e-02, -9.3748e-03,\n",
      "        -2.1402e-02, -2.4241e-02, -2.0202e-02, -4.1086e-02, -2.3693e-02,\n",
      "        -1.8502e-02, -1.6903e-02, -1.4484e-02, -2.7136e-02, -3.1580e-02,\n",
      "        -1.2229e-02, -1.7948e-02, -1.0916e-02, -2.4045e-02, -1.7929e-02,\n",
      "        -2.1818e-02,  1.6129e-04, -8.4003e-03, -2.9394e-02, -1.7159e-02,\n",
      "        -1.5038e-02, -3.4071e-02, -3.2497e-02, -2.7061e-02,  1.0884e-03,\n",
      "        -3.8592e-02, -2.4116e-02, -2.0955e-02, -3.8378e-02, -3.0427e-02,\n",
      "        -3.1330e-02, -8.6304e-04, -8.6506e-03, -7.0088e-03, -1.7409e-02,\n",
      "        -4.2697e-03, -2.0766e-02, -1.9667e-02, -2.3224e-02, -3.9196e-02,\n",
      "        -1.9547e-02, -1.0209e-02, -2.9545e-02, -1.0050e-02, -9.1487e-03,\n",
      "        -2.3767e-02, -1.5149e-02, -1.6055e-02, -6.4689e-03, -2.7394e-02,\n",
      "        -5.3582e-03, -1.2546e-02, -1.4908e-02, -3.7417e-02, -7.0792e-03,\n",
      "        -3.4251e-02,  1.1989e-03, -7.6584e-03,  1.3465e-02, -5.1634e-03,\n",
      "        -1.5750e-02, -2.6867e-02, -1.3250e-02,  5.6404e-03, -7.7306e-03,\n",
      "        -2.8677e-02, -1.3688e-02,  6.5814e-03, -3.6806e-03, -4.1002e-03,\n",
      "        -1.1846e-02, -2.5442e-02, -8.9737e-03, -1.5342e-02, -2.9284e-02,\n",
      "        -3.5493e-02, -2.9128e-02, -2.6339e-02, -3.0555e-02, -3.4366e-02,\n",
      "        -1.1129e-02, -1.4612e-02, -1.4620e-02, -8.1182e-03, -2.0405e-03,\n",
      "        -2.6859e-02, -2.8044e-02, -3.5649e-02, -1.8150e-02, -1.4067e-02,\n",
      "        -1.2478e-02, -2.7414e-02, -3.5635e-02,  3.7680e-03, -2.2950e-02,\n",
      "        -2.2457e-03, -2.1400e-02, -1.8270e-02, -6.0534e-03, -1.6415e-02,\n",
      "        -1.2159e-02, -1.5589e-02, -1.2873e-02, -1.3676e-02, -1.2694e-02,\n",
      "        -2.7762e-02,  1.5473e-03, -4.7752e-02, -1.9276e-02, -1.4199e-02,\n",
      "        -2.6870e-02, -1.9491e-02, -2.2402e-02, -1.3095e-02, -2.2867e-02,\n",
      "        -3.7295e-02, -1.3044e-02, -2.3576e-02, -1.7238e-02, -1.3608e-02,\n",
      "        -1.5674e-02, -3.6514e-02, -2.6806e-02, -2.5103e-02, -1.3362e-02,\n",
      "         1.3285e-02, -1.6190e-02, -1.4458e-02, -6.6277e-03, -2.0148e-02,\n",
      "        -4.4692e-02, -1.5983e-02, -2.0241e-02, -2.0768e-02, -2.5682e-02,\n",
      "        -1.5754e-02, -9.5891e-03, -2.7954e-02, -2.4222e-02, -3.1791e-02,\n",
      "        -3.0058e-02, -2.7058e-02, -8.5392e-03, -6.3665e-03, -1.4212e-02,\n",
      "        -2.1837e-02, -2.8051e-02, -1.7439e-02, -2.7823e-02, -5.1764e-03,\n",
      "        -2.3024e-02, -7.0565e-03, -1.7973e-02, -3.8185e-02, -2.3087e-02,\n",
      "        -7.8247e-03, -1.9281e-02, -2.7010e-02, -2.0216e-02,  2.3558e-03,\n",
      "         6.8081e-03, -1.2018e-02, -2.2077e-02, -1.4658e-02, -1.6101e-02,\n",
      "        -3.8539e-02, -3.7745e-02, -1.7563e-02, -1.3597e-02,  7.6479e-03,\n",
      "        -3.1193e-02, -2.4618e-02, -8.9296e-03, -3.0342e-02, -1.0976e-02,\n",
      "         6.4770e-03, -2.5097e-02, -1.4673e-02, -3.1932e-02, -7.4124e-03,\n",
      "        -1.0553e-02, -2.4753e-02, -7.9575e-03, -2.8715e-02, -1.1067e-02,\n",
      "        -1.8494e-02, -3.0851e-02, -1.2963e-02, -1.3419e-02, -1.5479e-02,\n",
      "        -2.7760e-02, -3.1963e-02, -3.4722e-02,  8.7358e-03, -1.9884e-02,\n",
      "        -1.5355e-02, -4.2216e-02, -1.6795e-02, -8.1667e-03, -3.2668e-02,\n",
      "        -1.3746e-02, -8.0615e-03, -1.3886e-02, -1.3549e-02, -3.0387e-02,\n",
      "        -2.1738e-02, -1.0208e-02, -3.8481e-02, -4.2258e-03, -3.1850e-03,\n",
      "        -2.9522e-02,  6.7806e-03, -9.5200e-03, -2.2016e-02, -2.1262e-02,\n",
      "        -1.9239e-02, -2.1334e-02, -1.7601e-02, -2.9264e-02, -1.6571e-02,\n",
      "        -2.7733e-02, -2.5302e-02, -3.4282e-02, -1.7458e-02, -1.4096e-02,\n",
      "        -2.0056e-02, -1.9687e-02, -1.7494e-02,  1.2714e-02, -1.3531e-02,\n",
      "        -2.4435e-02, -2.7098e-02, -1.1675e-02, -4.4530e-03,  2.0269e-03,\n",
      "        -1.5639e-02, -2.3160e-02,  8.0088e-03, -3.6027e-02, -3.3438e-02,\n",
      "        -1.1342e-02, -1.8015e-02, -7.0760e-03, -1.7621e-02, -1.5591e-02,\n",
      "        -1.9952e-02, -2.0860e-02, -1.6778e-02, -6.9233e-03, -1.9530e-02,\n",
      "        -1.3606e-02, -1.3818e-02, -2.7180e-02, -1.2487e-02, -1.9940e-03,\n",
      "        -1.4280e-02, -3.1532e-02, -9.9663e-03, -1.3352e-02, -1.6638e-02,\n",
      "        -2.0339e-02, -3.4635e-02, -3.9827e-02, -1.0780e-02, -9.7040e-03,\n",
      "        -7.4129e-03, -2.0130e-02, -3.5097e-02,  8.4145e-03, -1.5006e-02,\n",
      "        -2.5473e-02, -3.0029e-02, -3.1852e-02,  8.6676e-03, -1.2042e-02,\n",
      "        -2.5287e-02, -1.8187e-02, -2.1066e-02, -2.3535e-02, -1.1189e-02,\n",
      "        -3.3072e-02, -1.9629e-02, -1.5118e-02, -2.1045e-02, -7.4598e-03,\n",
      "        -1.5294e-02, -1.8193e-02, -1.2888e-02, -3.8968e-03, -1.8431e-02,\n",
      "        -1.0926e-02, -1.0837e-02, -3.8620e-02, -2.2096e-02, -3.0851e-02,\n",
      "        -2.2216e-02, -1.8068e-02, -2.3308e-02, -2.3766e-02, -1.6535e-02,\n",
      "        -4.2467e-02, -2.9234e-02,  5.3096e-03, -2.8055e-02, -3.0431e-02,\n",
      "        -3.1430e-03, -3.8930e-03, -2.7459e-02, -2.3590e-02, -2.6572e-02,\n",
      "        -1.2219e-02, -1.8861e-02, -3.5857e-02, -1.1828e-02, -2.0860e-02,\n",
      "        -1.7039e-02,  8.9934e-04, -3.0708e-02, -2.3366e-02, -1.9926e-02,\n",
      "        -2.0168e-02, -1.5041e-02, -2.8904e-02, -3.6276e-02, -2.8632e-02,\n",
      "        -6.8978e-03, -1.3270e-02, -1.9585e-02, -2.8024e-02, -2.2885e-02,\n",
      "        -9.7039e-03, -9.7302e-03, -2.3674e-02, -2.1044e-02, -2.6827e-02,\n",
      "        -2.6777e-03, -1.1763e-02, -3.5416e-02, -3.8267e-02,  2.1145e-03,\n",
      "        -2.3996e-02, -8.7334e-03, -1.8839e-02, -4.3848e-03, -2.6013e-02,\n",
      "        -1.8951e-03, -2.1149e-02, -2.5272e-02, -2.1785e-02, -2.9867e-02,\n",
      "        -1.2569e-02, -1.8280e-02, -1.8004e-02, -2.9751e-02, -3.5965e-02,\n",
      "        -1.9987e-02, -1.8003e-02, -3.1164e-03, -3.3721e-02, -6.0584e-03,\n",
      "        -2.3290e-02, -3.0360e-02,  2.4425e-04, -5.7232e-04, -2.2754e-02,\n",
      "        -2.1438e-02, -2.1923e-02, -2.4165e-02, -1.2716e-02, -8.9850e-03,\n",
      "        -1.8537e-02, -1.6636e-02, -1.1399e-02,  5.1063e-03, -1.9816e-02,\n",
      "        -2.4914e-03, -3.9343e-02, -5.7223e-03,  2.0244e-03, -1.3110e-02,\n",
      "        -1.7722e-02,  2.3689e-03, -1.5537e-02, -2.7283e-02,  4.3345e-03,\n",
      "        -1.4367e-02, -1.1404e-02, -9.1338e-03, -2.6574e-02, -3.0915e-02,\n",
      "        -2.9563e-02, -4.1646e-03,  4.8643e-03, -2.7904e-02, -2.6784e-02,\n",
      "        -2.7448e-02, -1.0766e-02,  2.2961e-03, -2.0787e-02, -9.7494e-03,\n",
      "         7.2097e-03, -1.7273e-02, -3.5181e-02, -1.6719e-02, -2.5136e-02,\n",
      "         8.2135e-03, -2.2062e-02, -9.4969e-03, -1.5154e-02, -2.4748e-02,\n",
      "        -3.7816e-02, -3.1089e-02, -2.8984e-02, -2.1439e-02, -3.0152e-02,\n",
      "        -3.6412e-02, -3.6093e-02, -3.9345e-04,  3.5386e-03, -1.1076e-02,\n",
      "        -2.9457e-02, -2.2778e-02, -2.6344e-02, -2.5620e-02, -3.0142e-02,\n",
      "        -2.0506e-02, -3.1833e-02, -2.1814e-03, -1.6061e-02, -1.4018e-02,\n",
      "        -2.1651e-02, -3.1988e-02, -3.7308e-02, -1.4991e-02, -2.1357e-02,\n",
      "        -3.8269e-02, -3.3362e-02, -2.8450e-02, -1.6077e-02, -2.6389e-02,\n",
      "        -1.4772e-02, -1.9755e-02, -1.1746e-02, -1.2715e-02, -6.7349e-03,\n",
      "        -2.2188e-02, -3.5013e-02, -1.4332e-02, -1.2405e-02, -3.8085e-02,\n",
      "        -2.1271e-02, -1.7114e-02, -2.1281e-02, -2.5841e-02, -1.8204e-02,\n",
      "        -1.0253e-02, -1.8490e-02, -2.0006e-02, -2.5682e-02, -2.6811e-02,\n",
      "        -1.7664e-02, -1.0900e-02, -1.5714e-02, -1.3739e-02, -3.1853e-02,\n",
      "        -1.0237e-02, -2.4647e-02, -3.0057e-02, -2.3366e-02, -3.4595e-02,\n",
      "        -2.4618e-02, -1.8586e-02,  4.3313e-03, -2.0254e-02, -2.2167e-02,\n",
      "        -1.6494e-02, -1.0640e-02,  1.5831e-03, -2.2676e-02, -1.8900e-02,\n",
      "        -2.4447e-02, -2.7768e-02, -1.5523e-02, -2.2395e-02, -3.3379e-02,\n",
      "        -1.9952e-02, -1.9059e-03, -1.9226e-02, -2.3398e-02, -4.1123e-03,\n",
      "        -1.8087e-02, -2.5461e-02, -5.1703e-03, -2.0544e-02, -3.0546e-02,\n",
      "        -4.0207e-03, -2.1004e-02, -2.2115e-02, -2.0572e-02, -1.3735e-02,\n",
      "        -2.3375e-02, -1.7542e-02, -2.1041e-02, -2.7554e-02, -1.7592e-02,\n",
      "         3.0514e-02, -1.2318e-02, -3.2040e-02, -1.5056e-02, -2.7216e-02,\n",
      "        -2.1900e-02, -3.4743e-02, -2.4572e-02, -2.3068e-02, -1.6124e-02,\n",
      "        -2.0290e-02, -3.3722e-02,  1.1291e-03, -1.9137e-03, -3.3555e-02,\n",
      "        -2.5843e-02, -1.4247e-02, -1.2882e-02, -2.0797e-02, -2.3135e-02,\n",
      "        -3.0037e-02, -2.9876e-03, -3.1387e-02, -2.8487e-02, -2.2750e-02,\n",
      "        -1.2512e-02, -2.2003e-02, -2.9078e-02, -1.8827e-02, -2.2524e-02,\n",
      "        -3.0109e-02, -2.2870e-02, -1.8230e-02, -4.0002e-02, -1.8736e-02,\n",
      "        -3.1099e-02, -3.3411e-02, -1.1134e-02, -1.1292e-02, -3.8986e-02,\n",
      "        -2.3202e-02, -1.2138e-02, -1.3275e-02, -1.7375e-02, -6.2959e-03,\n",
      "        -2.4027e-02, -2.7974e-02, -2.5737e-02, -2.6216e-02, -1.3867e-02,\n",
      "        -5.5868e-03, -6.5736e-03, -2.6611e-02, -1.6296e-02, -1.9571e-02,\n",
      "        -1.4522e-02,  4.1844e-03, -8.9995e-05, -2.5994e-02, -1.1034e-02,\n",
      "        -1.6063e-02, -5.3315e-03, -1.2937e-02, -2.5945e-02, -3.0150e-03,\n",
      "        -2.3896e-02, -2.2502e-02, -2.7794e-02, -1.4511e-02, -3.8776e-02,\n",
      "        -5.0948e-02, -1.5961e-02, -2.6542e-03, -2.0530e-02, -1.3690e-02,\n",
      "        -3.0797e-02, -8.9503e-03, -1.1385e-03, -2.0923e-02, -3.5672e-02,\n",
      "        -1.2630e-02, -2.0361e-02, -2.0742e-02, -1.4105e-02, -3.2502e-02,\n",
      "        -3.2993e-02, -2.5678e-02, -4.0496e-03, -3.6218e-02,  1.1226e-02,\n",
      "        -1.7576e-02, -3.5193e-03, -2.1033e-02,  1.1550e-03, -3.2862e-02,\n",
      "        -3.0035e-02, -7.5554e-04, -8.8784e-03, -2.6020e-02, -1.9613e-02,\n",
      "        -1.7707e-02, -1.4907e-02, -2.5563e-02, -1.3637e-02, -1.1892e-02,\n",
      "        -2.2138e-02, -1.7417e-02, -1.7940e-02, -9.0349e-03, -1.3232e-02,\n",
      "        -1.2846e-02, -2.0954e-02, -3.5325e-02, -1.9476e-02, -1.8158e-02,\n",
      "        -7.7704e-03, -2.4015e-02, -9.3514e-03, -1.0624e-02, -1.0850e-02,\n",
      "        -1.8470e-02, -5.8531e-03, -1.1997e-02, -1.2237e-02, -2.2076e-02,\n",
      "        -8.9157e-03, -3.9315e-02, -1.6648e-02, -2.4711e-02, -4.0875e-02,\n",
      "        -1.7640e-02, -3.0972e-02, -3.6808e-02,  1.1334e-03, -2.2874e-02,\n",
      "        -2.7616e-02, -3.1445e-02, -2.0760e-02, -7.3662e-03, -4.0263e-03,\n",
      "        -2.5455e-02, -1.9041e-02, -3.7968e-03, -1.7173e-02, -8.6937e-03,\n",
      "        -2.7904e-02, -2.5934e-02, -1.7872e-02, -1.9529e-02, -1.7984e-02,\n",
      "        -1.8608e-02, -2.8306e-02, -1.2169e-02, -1.1455e-02, -1.1330e-02,\n",
      "        -3.0490e-02, -2.2638e-02, -1.6143e-02, -2.6420e-02, -2.9457e-02,\n",
      "        -8.3630e-03, -2.0240e-02, -2.3154e-02, -3.3164e-02, -2.8887e-02,\n",
      "        -3.9826e-02,  5.6108e-03, -9.5582e-03, -1.5741e-02, -1.8869e-02,\n",
      "        -2.5596e-02, -1.9175e-04, -1.9697e-02, -1.5584e-02, -9.7904e-03,\n",
      "        -3.6085e-02, -5.6078e-03, -2.7315e-02, -1.8772e-02, -2.7811e-02,\n",
      "        -3.3716e-02, -2.7105e-02, -1.6207e-02, -2.5339e-02, -2.9530e-02,\n",
      "        -1.7790e-02, -2.6191e-02,  1.2974e-03, -3.5227e-02, -1.3205e-02,\n",
      "        -7.2069e-03, -1.3645e-02, -1.3047e-02,  1.0167e-02, -2.3037e-02,\n",
      "        -1.3751e-02,  1.4637e-02, -7.3257e-03, -1.7573e-02, -2.8702e-02,\n",
      "        -2.2269e-02, -2.0516e-02, -8.3135e-03, -2.0743e-02, -3.4996e-02,\n",
      "        -2.7761e-03, -1.5695e-02, -1.5719e-02, -1.5113e-02, -8.6706e-03,\n",
      "        -1.4988e-02, -1.7899e-02, -7.0590e-03, -3.2114e-02, -3.0118e-02,\n",
      "        -2.4288e-02, -1.6384e-02, -1.5813e-02, -1.3308e-02, -1.7499e-02,\n",
      "        -4.8465e-03,  1.4723e-02, -2.0683e-02, -3.3210e-02, -2.0017e-02,\n",
      "        -1.9138e-02, -1.5645e-02, -2.6456e-02, -2.1913e-02, -2.9984e-02,\n",
      "        -1.5239e-02, -1.9772e-02, -6.7163e-03, -3.6512e-02, -2.7222e-02,\n",
      "        -1.1856e-02, -1.6294e-02, -9.6320e-03,  1.1897e-02, -8.9992e-04,\n",
      "        -3.3295e-02, -4.8651e-02, -2.6984e-02, -1.9478e-02, -3.6765e-02,\n",
      "        -8.5836e-03, -1.7902e-03, -3.8291e-02, -1.8127e-02, -2.2925e-02,\n",
      "        -3.0081e-02, -2.9705e-02, -4.0635e-02, -6.1154e-03, -5.6890e-03,\n",
      "        -1.5573e-02, -3.7570e-03, -8.2688e-03, -1.2307e-02, -2.0046e-03,\n",
      "        -1.8450e-02, -1.2504e-02, -2.8540e-02, -1.6598e-02, -7.1833e-03],\n",
      "       device='cuda:0', requires_grad=True), 'fc2.weight': Parameter containing:\n",
      "tensor([[ 0.0043,  0.0233,  0.0188,  ..., -0.0037, -0.0334, -0.0261],\n",
      "        [ 0.0140, -0.0010,  0.0354,  ...,  0.0047, -0.0010,  0.0170],\n",
      "        [-0.0002, -0.0425, -0.0161,  ..., -0.0011, -0.0294, -0.0125],\n",
      "        ...,\n",
      "        [-0.0075, -0.0192,  0.0029,  ...,  0.0310, -0.0227,  0.0088],\n",
      "        [-0.0129, -0.0130,  0.0241,  ...,  0.0230, -0.0026,  0.0065],\n",
      "        [-0.0300,  0.0196, -0.0261,  ...,  0.0153, -0.0399, -0.0380]],\n",
      "       device='cuda:0', requires_grad=True), 'fc2.bias': Parameter containing:\n",
      "tensor([-1.6386e-06,  9.0694e-07,  5.9922e-07, -1.4073e-06,  2.1126e-06,\n",
      "        -1.4930e-07,  8.3749e-07, -2.4989e-07, -7.6836e-07,  1.1764e-06,\n",
      "        -7.5386e-07, -2.4573e-06,  1.4761e-06, -7.7414e-07, -4.6838e-08,\n",
      "        -2.4798e-07,  7.5390e-07, -1.3699e-06,  1.3644e-06,  5.0831e-07,\n",
      "         8.1472e-07, -7.6656e-07,  1.2108e-06,  5.8479e-07,  9.9214e-07,\n",
      "         1.7520e-06, -4.9753e-07, -6.5118e-07, -1.7593e-06,  5.2278e-07,\n",
      "        -2.4436e-06, -2.7859e-06,  5.7476e-07,  2.2525e-06, -1.2921e-06,\n",
      "         9.9092e-08, -1.6788e-06, -1.7669e-08, -1.7426e-07,  4.8097e-07,\n",
      "        -5.1166e-07, -6.4745e-07, -1.0770e-06,  2.0769e-07,  1.6213e-07,\n",
      "        -1.0469e-06,  1.4681e-06,  1.0105e-06,  9.0248e-07, -2.1077e-07,\n",
      "         2.6496e-07, -4.6658e-07, -9.6297e-07,  1.1049e-08,  3.5182e-07,\n",
      "        -1.7166e-07, -1.0556e-06,  7.2073e-07, -1.4950e-06, -2.5440e-07,\n",
      "        -1.2108e-06,  1.5307e-06, -4.3240e-07, -5.5009e-08,  9.5013e-07,\n",
      "        -6.1869e-07, -3.1969e-08, -2.4065e-06,  4.8668e-07, -1.0264e-06,\n",
      "         1.0883e-07, -3.6234e-07,  1.2352e-06,  6.2245e-07,  3.9907e-07,\n",
      "        -2.5061e-07,  9.1149e-07, -5.6317e-07,  1.6432e-08, -1.8304e-06,\n",
      "        -2.3652e-06,  5.1031e-08,  1.3380e-06,  7.0282e-07, -8.2256e-07,\n",
      "        -2.3767e-06,  2.4996e-06,  3.0883e-07, -7.1520e-07, -6.7435e-07,\n",
      "        -1.5481e-07, -1.6368e-06,  3.3116e-07, -7.5087e-07,  7.1340e-07,\n",
      "        -8.8781e-07, -1.4234e-07, -2.1208e-06,  7.3245e-07, -2.1474e-07],\n",
      "       device='cuda:0', requires_grad=True), 'bn2.weight': Parameter containing:\n",
      "tensor([0.9893, 0.9571, 0.9872, 0.9943, 0.9777, 0.9827, 0.9908, 1.0006, 0.9910,\n",
      "        0.9891, 0.9611, 0.9996, 0.9662, 1.0145, 0.9432, 0.9896, 0.9975, 0.9996,\n",
      "        0.9926, 0.9701, 0.9464, 0.9823, 0.9867, 0.9974, 0.9617, 0.9639, 0.9798,\n",
      "        0.9837, 0.9825, 0.9837, 0.9839, 0.9814, 0.9783, 0.9712, 1.0254, 0.9522,\n",
      "        0.9676, 0.9819, 0.9963, 0.9421, 0.9812, 0.9918, 0.9882, 0.9709, 0.9939,\n",
      "        0.9489, 0.9372, 0.9821, 0.9751, 0.9823, 0.9838, 1.0023, 0.9717, 0.9795,\n",
      "        0.9841, 0.9821, 0.9929, 0.9922, 0.9866, 0.9771, 1.0001, 0.9750, 0.9651,\n",
      "        0.9698, 0.9776, 0.9956, 0.9261, 0.9682, 0.9798, 0.9794, 0.9825, 0.9510,\n",
      "        0.9806, 0.9707, 0.9978, 0.9589, 0.9863, 1.0042, 0.9527, 0.9899, 0.9756,\n",
      "        0.9709, 1.0085, 1.0040, 0.9719, 0.9929, 0.9872, 0.9620, 0.9565, 0.9449,\n",
      "        0.9795, 0.9822, 0.9537, 0.9766, 1.0062, 0.9806, 1.0007, 0.9713, 0.9952,\n",
      "        0.9873], device='cuda:0', requires_grad=True), 'bn2.bias': Parameter containing:\n",
      "tensor([ 3.5287e-03,  3.6302e-03,  1.9887e-02,  9.4999e-03, -2.3203e-02,\n",
      "        -5.2354e-02, -1.9507e-02, -2.0771e-02,  1.7060e-02,  2.1729e-02,\n",
      "         3.0081e-03,  1.7474e-02, -2.7067e-02,  2.3756e-03,  1.9088e-03,\n",
      "        -1.5983e-02,  3.3332e-02, -3.1769e-02,  4.0721e-02, -6.4843e-04,\n",
      "         2.2722e-03,  5.4029e-03,  3.5864e-02, -3.2298e-02,  1.9859e-02,\n",
      "        -2.5520e-02, -3.8638e-03,  1.5593e-02,  9.8270e-03, -6.4939e-03,\n",
      "         2.0447e-02, -3.3712e-02,  2.8276e-02, -1.0447e-02,  3.1958e-02,\n",
      "         1.1793e-02, -3.5293e-02, -2.8783e-02,  3.7012e-02,  3.9771e-03,\n",
      "        -2.1852e-02,  4.1022e-02,  4.9241e-02,  1.3042e-02, -6.3932e-03,\n",
      "         2.0310e-02, -5.8792e-02, -6.9808e-03,  5.4355e-02,  7.1263e-03,\n",
      "        -1.9407e-02,  3.4361e-02, -3.0729e-03, -2.2622e-02, -3.8076e-04,\n",
      "         5.5585e-02,  4.3477e-02,  8.9244e-03,  1.6949e-03, -1.8357e-02,\n",
      "        -2.4154e-02,  7.2729e-03,  1.3868e-05, -2.1630e-02, -1.6303e-02,\n",
      "         3.9983e-02, -3.7431e-02,  9.9429e-03,  1.3385e-02,  1.1861e-02,\n",
      "         3.3628e-03, -9.9912e-03,  1.6258e-02, -1.3588e-02,  1.6430e-02,\n",
      "         2.8498e-03, -3.7865e-02,  2.3715e-02, -3.2687e-03,  1.5450e-03,\n",
      "        -9.9677e-03,  4.9405e-03,  3.1578e-02, -9.4971e-03,  2.9122e-02,\n",
      "         1.9517e-02,  9.3212e-03, -3.6430e-03, -1.3514e-02, -3.4797e-03,\n",
      "         4.5481e-03, -1.3530e-02, -1.7320e-02,  8.9103e-03,  4.5530e-02,\n",
      "        -2.6644e-02,  1.1318e-02, -4.1349e-04, -3.4385e-02,  2.1213e-02],\n",
      "       device='cuda:0', requires_grad=True), 'fc3.weight': Parameter containing:\n",
      "tensor([[ 9.6656e-02,  2.4124e-03, -3.6698e-02,  6.6248e-02, -2.4505e-02,\n",
      "         -4.2889e-02,  8.6327e-03, -2.7487e-02, -2.9830e-02,  4.4156e-03,\n",
      "          8.8697e-02,  1.2940e-01, -1.9837e-02, -2.1459e-02, -2.8902e-02,\n",
      "          8.9248e-02,  4.5284e-02,  3.5788e-02,  8.4060e-02,  1.1100e-01,\n",
      "          8.4502e-02, -3.9932e-02, -2.9054e-02,  3.7260e-03, -1.6746e-02,\n",
      "          1.1608e-02, -2.0598e-02,  5.8290e-02, -4.6946e-02, -3.5825e-02,\n",
      "          9.4911e-02, -1.7876e-02,  6.1267e-02, -4.0084e-02, -2.8521e-02,\n",
      "         -3.8602e-02, -3.7791e-02, -7.9391e-03, -4.2755e-03,  2.9838e-02,\n",
      "          3.4664e-02,  9.3484e-02,  4.2888e-03,  1.1505e-02, -3.3857e-02,\n",
      "          8.3979e-02, -3.6304e-02,  9.2507e-02, -2.7712e-02, -3.7329e-02,\n",
      "          1.1683e-01,  6.2955e-02, -2.9646e-02,  8.1578e-02, -2.0538e-02,\n",
      "         -1.8828e-02,  5.9376e-02, -5.0023e-03,  2.6089e-02, -1.7892e-02,\n",
      "          5.2846e-03,  1.1248e-01, -1.6147e-02, -4.6862e-02, -4.0645e-02,\n",
      "         -7.9844e-03, -1.6524e-02, -3.6479e-02,  7.2786e-02,  2.0052e-02,\n",
      "         -1.9853e-02, -5.3418e-02, -3.9053e-02,  8.8658e-02, -2.1752e-02,\n",
      "         -5.8122e-02, -2.5039e-02,  6.8546e-02, -2.8181e-02, -7.1603e-03,\n",
      "          6.8971e-03, -4.3823e-02,  1.1526e-01,  1.0954e-01, -3.0229e-02,\n",
      "         -3.8445e-02,  8.8980e-03, -4.7207e-02, -1.3272e-02, -3.2776e-02,\n",
      "          8.0448e-02, -2.7014e-02, -5.0799e-02, -4.6680e-02, -3.8568e-02,\n",
      "         -3.5357e-02,  6.3313e-02,  9.1957e-02, -2.4526e-02, -2.7438e-02],\n",
      "        [-4.9171e-02,  9.8308e-03, -2.8369e-02, -3.5720e-02, -3.5993e-02,\n",
      "         -3.6056e-03,  2.3517e-02, -3.7695e-02, -4.0724e-02, -3.3062e-02,\n",
      "          2.6789e-03, -4.3465e-02, -3.5613e-02,  6.4168e-02, -3.9069e-02,\n",
      "         -2.2750e-02, -3.3387e-02, -1.0508e-02,  1.5380e-02,  9.3793e-02,\n",
      "         -1.3745e-03,  1.1715e-01,  3.9322e-02,  3.9927e-02, -2.2667e-02,\n",
      "         -9.8826e-03, -5.4961e-02, -3.2593e-02, -3.3484e-02, -5.5576e-02,\n",
      "          6.6096e-02, -4.1172e-02, -4.2655e-02,  1.3350e-01,  8.6179e-02,\n",
      "         -5.8830e-02, -2.4960e-02, -3.1615e-02, -3.8782e-02, -3.7494e-02,\n",
      "          9.6472e-02, -6.4872e-02, -4.2434e-02,  8.7700e-03,  1.1429e-01,\n",
      "          5.7601e-02, -6.3587e-02, -2.5703e-02,  4.4974e-02,  9.8036e-02,\n",
      "          5.2480e-02, -4.7785e-02, -5.6841e-02, -6.1688e-02, -3.2689e-02,\n",
      "          1.0309e-01, -3.5518e-02, -4.8557e-03,  6.0699e-02, -2.3559e-02,\n",
      "          4.4373e-03,  7.2047e-02, -5.3337e-02, -3.9637e-02, -4.1341e-03,\n",
      "         -5.2051e-02, -5.3336e-02, -4.6831e-02, -2.0717e-02,  6.9257e-02,\n",
      "          8.2619e-02, -4.8237e-02, -4.4865e-02, -3.9570e-02,  5.9535e-02,\n",
      "          1.0517e-01, -1.9506e-03, -2.3731e-02, -2.0161e-02,  1.0968e-01,\n",
      "          8.0177e-02, -5.2200e-02, -2.2370e-02,  1.2225e-01, -5.1492e-02,\n",
      "          8.5472e-02,  1.1110e-01,  3.3979e-02, -1.8552e-02,  5.9795e-02,\n",
      "         -5.4765e-02,  2.9157e-02,  6.8104e-02, -4.7514e-02, -3.0182e-03,\n",
      "          4.6096e-02,  8.0537e-02,  3.4089e-02, -3.0373e-02,  1.1128e-01],\n",
      "        [ 8.9535e-02, -6.2238e-02,  1.0430e-01, -5.3717e-02, -2.5332e-02,\n",
      "          3.2343e-02, -3.8947e-02, -1.8814e-02, -8.0867e-03,  1.0989e-01,\n",
      "         -6.8881e-02, -2.6501e-02, -3.2586e-02,  1.3278e-01,  1.6607e-02,\n",
      "          1.7600e-02, -2.9950e-02, -1.8221e-02, -7.3417e-02, -1.7187e-02,\n",
      "          7.9425e-02, -4.0103e-02, -3.9569e-02, -2.4980e-02,  1.0325e-01,\n",
      "          4.6659e-02, -5.5289e-02,  7.2156e-02,  4.2141e-02, -4.3181e-02,\n",
      "          9.7795e-02,  1.2792e-01, -4.0385e-02, -3.7986e-02, -3.2173e-02,\n",
      "         -5.3832e-02, -1.6375e-02, -2.7884e-02,  8.0875e-02, -4.9461e-02,\n",
      "         -3.7945e-02, -3.3653e-02, -5.3658e-02, -4.1784e-02,  6.3827e-02,\n",
      "         -6.0754e-02,  8.8554e-02, -3.6055e-03, -2.7636e-02, -5.1249e-02,\n",
      "         -1.9974e-02,  4.0488e-02, -4.4479e-02, -5.9063e-02, -4.0101e-02,\n",
      "          1.3347e-02, -3.8663e-02,  9.7523e-02,  1.5077e-02,  1.1576e-02,\n",
      "          1.2579e-01,  7.4987e-02,  6.4006e-02, -5.8977e-02,  2.6950e-02,\n",
      "         -4.0190e-02,  7.4734e-02, -3.8185e-02, -1.2712e-02, -4.4136e-02,\n",
      "         -3.8148e-03, -5.8435e-02, -5.0973e-02,  9.3504e-02,  1.0811e-01,\n",
      "          3.1674e-03, -2.2413e-02, -1.3180e-02, -9.8814e-03, -3.2746e-02,\n",
      "         -9.3356e-03,  8.4690e-02,  9.2344e-03, -7.2404e-03,  1.0663e-01,\n",
      "          1.1448e-02, -2.7727e-02, -5.8272e-02,  1.6782e-02,  8.7722e-02,\n",
      "         -6.2220e-02, -3.1268e-02, -3.2097e-02, -4.2872e-02, -2.5800e-02,\n",
      "         -3.7508e-02, -1.7948e-02, -2.3623e-02,  1.1817e-01,  4.1434e-02],\n",
      "        [-3.0109e-02, -2.3194e-02, -1.4844e-02,  6.2278e-02,  5.4662e-02,\n",
      "          1.1725e-01, -9.7955e-04, -1.7830e-02,  6.9718e-02,  7.7853e-02,\n",
      "         -5.8687e-03, -3.8488e-02, -1.7151e-02,  9.5910e-03,  1.0326e-01,\n",
      "         -1.9049e-02, -4.7656e-02, -3.8512e-02,  6.1815e-02, -4.5902e-02,\n",
      "          7.8693e-03,  2.4864e-02, -3.0204e-02,  1.1653e-01, -5.3861e-02,\n",
      "          2.2829e-02, -2.9062e-02,  2.6988e-02,  8.9702e-02, -2.7367e-02,\n",
      "         -1.2133e-02,  1.4058e-02,  5.0146e-02,  4.4113e-03, -3.9087e-02,\n",
      "          5.7068e-02,  2.3406e-02,  9.8628e-02, -3.6047e-02, -3.2072e-02,\n",
      "          1.2733e-02, -1.8857e-02, -3.5653e-02, -1.4606e-02,  9.1049e-02,\n",
      "          3.1646e-02, -5.6241e-02, -5.6699e-02,  7.9483e-02,  4.2211e-02,\n",
      "          4.5680e-02, -4.6945e-02,  6.4917e-02,  6.4433e-02, -4.7199e-02,\n",
      "         -3.6286e-02,  5.4275e-02, -6.6063e-03, -2.2284e-02,  9.8791e-02,\n",
      "         -2.1379e-02, -2.3402e-02, -4.0345e-02,  7.7549e-02, -2.7128e-02,\n",
      "         -1.4582e-02,  9.6932e-02, -3.5168e-02,  1.0107e-01, -4.3665e-02,\n",
      "         -3.4938e-02, -2.5384e-02,  3.9042e-02, -5.4470e-02, -3.4438e-02,\n",
      "         -5.8657e-02,  6.3415e-03,  6.1711e-02, -3.0997e-02, -5.2566e-02,\n",
      "         -7.8209e-03, -4.0665e-02,  2.9282e-02,  2.5053e-02, -3.7116e-02,\n",
      "          4.6297e-02,  9.4303e-02, -4.8556e-02, -1.9193e-02, -2.1068e-02,\n",
      "         -3.1006e-02, -3.8514e-02, -4.9950e-02, -4.7854e-02,  3.9687e-02,\n",
      "         -3.9598e-02, -5.8098e-02, -6.7213e-02, -1.4928e-02, -2.9450e-02],\n",
      "        [-4.9102e-02, -2.5638e-03, -5.4926e-02, -6.3255e-02, -2.9186e-02,\n",
      "         -3.1597e-02, -3.6654e-02,  9.7589e-02, -1.7375e-02,  1.4031e-02,\n",
      "          9.8965e-02,  5.8097e-02,  1.0962e-02, -3.5363e-02, -7.1032e-02,\n",
      "         -1.9052e-02,  1.0290e-01, -4.7264e-02,  5.9756e-02,  2.5463e-02,\n",
      "          3.1142e-03, -3.1123e-02, -4.5678e-02, -3.5242e-02,  3.3342e-02,\n",
      "         -3.1154e-02,  1.1200e-01, -4.8954e-02, -2.0781e-02, -4.8132e-02,\n",
      "         -6.6007e-02, -3.5466e-02,  2.5340e-02,  6.9398e-02, -5.3268e-02,\n",
      "         -9.5702e-03,  6.0375e-03, -6.2724e-02,  8.0193e-02,  4.6133e-02,\n",
      "         -8.6563e-03,  1.2754e-02, -4.2937e-02, -3.8809e-02, -2.0332e-02,\n",
      "         -3.1788e-02, -3.9838e-02, -5.0513e-02,  5.7568e-02,  8.5966e-02,\n",
      "         -3.6777e-02, -4.6480e-02,  1.1766e-03, -4.1298e-02,  9.7829e-02,\n",
      "         -4.9628e-02, -7.0730e-02, -5.2436e-02, -7.3667e-02,  6.2323e-03,\n",
      "         -4.7413e-02,  3.4536e-02,  1.0000e-01, -4.9504e-02, -4.3551e-02,\n",
      "         -4.7958e-02,  3.6631e-02,  4.8963e-02,  8.1131e-02, -4.4738e-02,\n",
      "         -7.0241e-02,  5.3384e-02,  1.0071e-01, -7.1059e-02,  9.7645e-02,\n",
      "          6.2546e-02,  2.2731e-03, -4.6835e-02, -7.8258e-02, -6.0471e-02,\n",
      "         -2.2219e-02,  8.3514e-02,  7.4990e-02, -5.7739e-02, -6.2802e-02,\n",
      "         -5.6506e-02,  1.6843e-02,  2.7465e-02, -5.4879e-02, -1.8836e-02,\n",
      "         -2.6732e-02,  1.1060e-01, -6.0087e-02,  6.4460e-02, -7.4410e-02,\n",
      "          1.1621e-01, -3.8684e-02, -4.2171e-02, -3.5788e-02, -4.4504e-02],\n",
      "        [-4.7951e-02,  8.2426e-02, -4.8634e-02, -2.2688e-02, -5.4653e-02,\n",
      "         -4.1215e-02, -1.7146e-02,  9.9145e-02,  9.7331e-02,  5.6986e-02,\n",
      "          9.2361e-02, -6.1844e-03,  5.5345e-02, -5.0620e-02,  6.0860e-02,\n",
      "         -3.6878e-03, -5.1463e-02, -1.4071e-02,  2.8221e-02, -1.4623e-02,\n",
      "         -6.0237e-02,  6.7837e-02, -3.2292e-02, -2.3296e-02,  4.8313e-02,\n",
      "          1.1220e-02,  6.2777e-02,  9.0174e-02,  3.4215e-02, -2.0400e-02,\n",
      "         -3.9785e-02, -3.8632e-02, -2.1644e-02, -4.7402e-02,  1.0073e-01,\n",
      "         -3.4276e-02, -2.9928e-02, -2.2568e-02, -1.7274e-02,  5.4031e-02,\n",
      "          1.1722e-01, -1.7290e-02,  2.7316e-02, -1.6153e-02, -3.3091e-02,\n",
      "          3.8987e-02,  9.5406e-02,  1.0109e-01,  2.6270e-02, -4.7089e-02,\n",
      "         -4.8664e-02,  1.1340e-01, -3.3251e-02,  5.5932e-02,  8.6452e-03,\n",
      "          8.7606e-02, -3.3764e-02, -1.1196e-02, -3.9240e-02,  6.5484e-02,\n",
      "         -4.6055e-02,  1.7067e-02, -4.3367e-02,  8.8023e-02,  1.0553e-01,\n",
      "         -2.3644e-03, -5.2608e-02, -2.0315e-02, -5.5030e-02,  7.0804e-02,\n",
      "         -3.7427e-03, -4.6195e-02, -3.7255e-02, -5.3323e-02, -2.7728e-02,\n",
      "         -1.0469e-02, -1.0059e-02, -3.5616e-02, -1.1428e-02, -4.8406e-02,\n",
      "          1.0822e-01, -3.5814e-02,  4.1127e-03, -1.6471e-02,  8.6168e-02,\n",
      "          8.9071e-02, -3.4834e-02,  2.9797e-02, -3.0865e-02, -2.9441e-02,\n",
      "          5.9241e-02,  3.5418e-03, -4.5677e-02,  4.4156e-03, -5.9188e-02,\n",
      "         -1.1601e-02, -2.6628e-02,  8.3916e-02,  6.7752e-02, -4.4497e-02],\n",
      "        [-3.1158e-02,  8.1484e-02,  6.7173e-02,  8.1375e-02, -1.6328e-02,\n",
      "         -3.9478e-02, -2.2522e-02, -1.7932e-02,  4.2618e-02, -4.9304e-02,\n",
      "         -4.0824e-02, -3.9025e-02, -3.5561e-02, -4.4828e-02,  3.9857e-02,\n",
      "         -2.6415e-02, -1.9874e-02, -2.6810e-02, -6.0152e-02, -3.9259e-02,\n",
      "          1.0503e-01,  3.6416e-02, -3.0448e-02, -2.5640e-02,  6.4948e-02,\n",
      "          8.9772e-03,  8.7613e-02, -6.0485e-02, -6.6572e-02,  2.4852e-03,\n",
      "          4.5214e-02, -2.9862e-02,  8.2137e-02,  5.3399e-03,  1.0191e-01,\n",
      "         -4.4383e-02,  1.2121e-01,  9.8988e-02,  3.8036e-02, -5.8947e-02,\n",
      "         -1.4906e-02, -4.3474e-02,  1.3122e-02,  4.8534e-02, -4.0515e-02,\n",
      "         -7.1555e-03, -5.4298e-02, -2.6375e-02, -6.5393e-02, -6.5512e-02,\n",
      "         -2.4152e-02, -5.2987e-02, -3.8168e-02, -5.2598e-02,  2.0076e-03,\n",
      "         -1.9127e-02,  3.1763e-02,  9.6590e-02, -4.0643e-02, -4.4730e-02,\n",
      "          1.8786e-02, -3.3577e-02,  1.3798e-02, -8.4138e-03, -5.8798e-02,\n",
      "         -2.4025e-02,  5.9601e-02,  8.2331e-02, -4.3025e-02,  7.8054e-02,\n",
      "          1.4910e-02,  8.2075e-02, -5.4587e-02,  5.7931e-03, -3.2973e-02,\n",
      "          7.3745e-02,  1.1807e-01,  8.5841e-02,  6.6943e-03,  3.7091e-02,\n",
      "         -2.6716e-02, -5.8491e-02, -3.0071e-02, -3.1492e-02, -5.1940e-02,\n",
      "         -2.2044e-02, -5.3202e-02,  1.0057e-01,  1.0892e-01, -5.8783e-02,\n",
      "          1.0355e-01, -2.6293e-02, -5.5148e-02, -4.4831e-02,  8.0551e-02,\n",
      "         -2.0899e-02,  6.3177e-02,  7.7990e-02, -2.8072e-02, -2.6606e-02],\n",
      "        [-2.5290e-02,  2.1104e-02,  8.5250e-02, -2.2316e-02,  1.1024e-01,\n",
      "         -2.9162e-02, -3.4249e-02, -3.7443e-02, -3.0957e-02, -3.8275e-02,\n",
      "         -3.7735e-02, -3.6588e-02,  1.1044e-01,  1.5222e-02,  6.1101e-02,\n",
      "          1.2282e-01,  7.9738e-02,  1.1377e-01, -4.0461e-02, -2.8834e-02,\n",
      "         -1.4069e-02, -2.9071e-02,  7.3595e-02,  2.7640e-05, -2.0293e-02,\n",
      "          1.2506e-01, -2.4846e-02, -1.4643e-02, -7.8480e-03, -4.6056e-02,\n",
      "         -2.4521e-02, -2.6142e-02, -1.5031e-02, -4.9132e-03, -3.5085e-02,\n",
      "          6.3789e-03, -1.3491e-02, -1.8588e-02, -4.7143e-02,  9.4661e-02,\n",
      "          1.0353e-02, -4.9797e-02, -3.7332e-02, -4.6305e-02, -1.2931e-02,\n",
      "         -4.6537e-02, -3.4774e-02,  5.7702e-02,  5.7559e-02, -5.8797e-02,\n",
      "          9.5017e-03,  6.3181e-02, -6.7605e-02, -3.6930e-02,  3.8377e-02,\n",
      "         -3.5439e-02,  7.8017e-02, -2.8303e-02,  6.5703e-02, -3.0276e-02,\n",
      "         -1.2670e-03, -1.3815e-02, -2.2732e-02, -3.9487e-03, -3.2353e-02,\n",
      "          5.3627e-02, -3.8718e-02, -4.2331e-02, -3.5703e-02, -4.4111e-02,\n",
      "          7.4837e-02,  1.6071e-02,  5.3002e-02, -2.7551e-02, -3.4196e-02,\n",
      "         -4.7335e-02, -7.1218e-03, -8.4249e-03,  6.6814e-02,  7.6369e-02,\n",
      "          4.8937e-02, -5.2406e-02, -1.0493e-02, -2.7608e-02, -1.5368e-02,\n",
      "         -1.0115e-02, -1.5185e-02, -2.1005e-02,  1.1852e-02,  6.1582e-02,\n",
      "         -2.9649e-02, -4.6462e-02, -1.5758e-02,  6.4151e-02,  6.1885e-02,\n",
      "         -4.1128e-02, -1.6599e-02, -1.9285e-02, -1.7667e-02, -1.6884e-02],\n",
      "        [ 5.2283e-02, -5.9708e-02, -7.6626e-02, -6.2643e-02, -6.9268e-02,\n",
      "         -4.5367e-03,  1.4387e-01, -3.4417e-02, -6.1704e-03, -6.7160e-02,\n",
      "          2.1782e-02,  4.1960e-02, -6.4054e-02, -7.4519e-02, -1.7701e-02,\n",
      "         -5.7738e-02, -6.3747e-02, -6.1269e-02, -7.3462e-02,  3.4738e-02,\n",
      "         -4.9196e-02, -1.7726e-02,  9.6251e-02, -1.5572e-02, -6.1385e-02,\n",
      "         -2.4852e-02, -6.3841e-02, -3.4702e-02, -6.4240e-02,  1.0657e-01,\n",
      "         -8.0585e-02,  1.7867e-03, -6.8464e-02, -4.2137e-02, -3.0270e-02,\n",
      "          1.2168e-01, -5.3773e-02, -1.9238e-02, -5.9759e-02,  1.2339e-02,\n",
      "         -4.6643e-02,  7.9051e-02,  1.0929e-01,  1.3289e-01, -8.5462e-03,\n",
      "          9.1368e-02, -4.5637e-02, -4.4665e-02, -1.0224e-01, -7.1870e-02,\n",
      "         -2.5024e-02, -6.2700e-02,  1.2299e-01, -5.5188e-02, -5.8544e-02,\n",
      "          8.5334e-02, -6.8130e-02, -5.2878e-02, -5.6362e-02, -1.3193e-03,\n",
      "         -5.1603e-02, -5.2833e-02, -4.9589e-02, -9.5514e-03,  7.1199e-03,\n",
      "          9.3964e-02,  3.0233e-02,  4.0302e-02, -2.3671e-02, -4.7701e-02,\n",
      "         -6.8643e-02, -6.2341e-02, -7.8028e-02, -1.2249e-02, -6.8532e-02,\n",
      "         -4.9874e-02, -4.0154e-02, -1.9477e-02,  1.2237e-01, -5.8033e-02,\n",
      "         -6.8187e-02,  3.6395e-02, -4.7849e-02, -5.4237e-02,  8.5897e-02,\n",
      "         -2.9286e-02, -7.2448e-02, -5.3107e-02,  3.6165e-02,  5.2634e-02,\n",
      "          2.4417e-02, -1.4811e-02,  1.0605e-01, -6.7952e-02, -5.5609e-02,\n",
      "         -5.6459e-02, -2.2689e-02, -1.4492e-02, -5.2638e-02,  8.0418e-02]],\n",
      "       device='cuda:0', requires_grad=True), 'fc3.bias': Parameter containing:\n",
      "tensor([-5.3513e-06, -4.2028e-05, -5.6393e-07,  3.3012e-06,  5.0986e-06,\n",
      "         4.7881e-07,  4.4494e-07, -2.1326e-07, -1.2301e-06], device='cuda:0',\n",
      "       requires_grad=True), 'bn3.weight': Parameter containing:\n",
      "tensor([1.1534, 1.1626, 1.1876, 1.1876, 1.1931, 1.1760, 1.1816, 1.1842, 1.1897],\n",
      "       device='cuda:0', requires_grad=True), 'bn3.bias': Parameter containing:\n",
      "tensor([-0.1673, -0.1416,  0.0070, -0.0944,  0.1374, -0.1419,  0.0564,  0.0720,\n",
      "         0.1581], device='cuda:0', requires_grad=True)}\n"
     ]
    }
   ],
   "source": [
    "weight={}\n",
    "for name,parameters in net.named_parameters():\n",
    "    print(name,':',parameters.size())\n",
    "    #names.append(name)\n",
    "    weight[name]=parameters\n",
    "print(\"weight:\",weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39864833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Con', 'DN', 'FSGS', 'HT', 'IgAN', 'MCD', 'MGN', 'RPGN', 'SLE']\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "{'Con': 0, 'DN': 1, 'FSGS': 2, 'HT': 3, 'IgAN': 4, 'MCD': 5, 'MGN': 6, 'RPGN': 7, 'SLE': 8}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "disease=pd.read_csv(nfm_config['all'],sep=',',header=None)\n",
    "disease=np.array(disease)\n",
    "disease=disease[1:,-1]\n",
    "disease=disease.tolist()\n",
    "#print(disease)\n",
    "dis_names=[]\n",
    "#dis_names.append()\n",
    "\n",
    "for id in disease:\n",
    "    if id not in dis_names:\n",
    "        dis_names.append(id)\n",
    "\n",
    "print(dis_names)\n",
    "val=[ i for i in range(nfm_config['n_class'])]\n",
    "print(val)\n",
    "\n",
    "disease_names={}\n",
    "#disease_names.keys=dis_names\n",
    "#disease_names.values=val\n",
    "#disease_names[dis_names]=val\n",
    "#print(disease_names)\n",
    "disease_names=dict(zip(dis_names,val))\n",
    "print(disease_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54b0a0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes=[]\n",
    "gene_res={}\n",
    "title=pd.read_csv(nfm_config['title'],sep=',',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "151e55a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(labels, classes, label_smoothing=0.2):\n",
    "    n = len(labels)\n",
    "    eoff = label_smoothing / classes\n",
    "    output = np.ones((n, classes), dtype=np.float32) * eoff\n",
    "    for row, label in enumerate(labels):\n",
    "        output[row, label] = 1 - label_smoothing + eoff\n",
    "        print(\"row:\",row,\"label:\",label)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cacf678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(labels, classes):\n",
    "    n = len(labels)\n",
    "    #eoff = label_smoothing / classes\n",
    "    output = np.zeros((n, classes), dtype=np.float32)\n",
    "    for row, label in enumerate(labels):\n",
    "        output[row, label] = 1 \n",
    "        print(\"row:\",row,\"label:\",label)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "daeda9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row: 0 label: 0\n",
      "row: 1 label: 1\n",
      "row: 2 label: 2\n",
      "row: 3 label: 3\n",
      "row: 4 label: 4\n",
      "row: 5 label: 5\n",
      "row: 6 label: 6\n",
      "row: 7 label: 7\n",
      "row: 8 label: 8\n",
      "[[0.82222223 0.02222222 0.02222222 0.02222222 0.02222222 0.02222222\n",
      "  0.02222222 0.02222222 0.02222222]\n",
      " [0.02222222 0.82222223 0.02222222 0.02222222 0.02222222 0.02222222\n",
      "  0.02222222 0.02222222 0.02222222]\n",
      " [0.02222222 0.02222222 0.82222223 0.02222222 0.02222222 0.02222222\n",
      "  0.02222222 0.02222222 0.02222222]\n",
      " [0.02222222 0.02222222 0.02222222 0.82222223 0.02222222 0.02222222\n",
      "  0.02222222 0.02222222 0.02222222]\n",
      " [0.02222222 0.02222222 0.02222222 0.02222222 0.82222223 0.02222222\n",
      "  0.02222222 0.02222222 0.02222222]\n",
      " [0.02222222 0.02222222 0.02222222 0.02222222 0.02222222 0.82222223\n",
      "  0.02222222 0.02222222 0.02222222]\n",
      " [0.02222222 0.02222222 0.02222222 0.02222222 0.02222222 0.02222222\n",
      "  0.82222223 0.02222222 0.02222222]\n",
      " [0.02222222 0.02222222 0.02222222 0.02222222 0.02222222 0.02222222\n",
      "  0.02222222 0.82222223 0.02222222]\n",
      " [0.02222222 0.02222222 0.02222222 0.02222222 0.02222222 0.02222222\n",
      "  0.02222222 0.02222222 0.82222223]]\n"
     ]
    }
   ],
   "source": [
    "new_labels=[i for i in range(nfm_config['n_class'])]\n",
    "new_targets=one_hot(new_labels,nfm_config['n_class'])\n",
    "print(new_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4836749d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Con': ['NR4A2', 'FOSB', 'EGR1', 'PDE4B', 'GATA6', 'GDF15', 'NR4A1', 'AVPI1', 'ID4', 'GADD45G'], 'DN': ['TIMM8B', 'ZNF468', 'HSD17B2', 'PRELP', 'NMT2', 'ITIH3', 'TNF', 'PID1', 'P2RY2', 'FOLR2'], 'FSGS': ['EYA1', 'RPS6KA6', 'PCDHB12', 'TRDC', 'MON1B', 'RIC8B', 'AVIL', 'FAM110B', 'STAT4', 'EFNB3'], 'HT': ['MUC16', 'VAMP2', 'CXCL3', 'ARID5B', 'DCT', 'SLC16A6', 'ORC6', 'RHOB', 'PROCR', 'MIA3'], 'IgAN': ['HBE1', 'SOX17', 'C1GALT1', 'GRTP1', 'TDP1', 'DDX25', 'STAC', 'DCT', 'TMEM100', 'WNT5A'], 'MCD': ['HIST1H1C', 'FUBP1', 'CTNNA3', 'ALKBH1', 'MRPS30', 'GMPR2', 'PER3', 'SF3B4', 'BICDL1', 'ASF1A'], 'MGN': ['SRPX2', 'THBS3', 'GRAP', 'LCN2', 'INSL4', 'CSGALNACT1', 'INPP5F', 'WNT5B', 'TGFBI', 'RBFOX1'], 'RPGN': ['FZD8', 'ST8SIA4', 'ZNF239', 'APBB1IP', 'BMP2K', 'SERPINA3', 'F2RL2', 'ITGA10', 'OPCML', 'TTLL7'], 'SLE': ['MX1', 'DDX58', 'HERC6', 'IFIT2', 'IFIT3', 'OAS3', 'RTP4', 'PRKAB2', 'EIF2AK2', 'IFI44']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengfang/.local/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "for i in range(nfm_config['n_class']):\n",
    "    \n",
    "    #new_targets=torch.tensor([0, 0, 0, 0, 0, 0, 0, 1])\n",
    "    new_targets=torch.tensor(new_targets).cuda()\n",
    "    l1=torch.mv(weight['fc3.weight'].T,(new_targets[i]-weight['fc3.bias']))\n",
    "    l2=torch.mv(weight['fc2.weight'].T,(l1-weight['fc2.bias']))\n",
    "    #l2=l2[100:]\n",
    "    l3=torch.mv(weight['fc1.weight'].T,(l2-weight['fc1.bias']))\n",
    "    #l4=torch.mv(weight['linear_model1.weight'].T,(l3-weight['linear_model1.bias']))\n",
    "    top_k=torch.topk(l3,20,largest=True)\n",
    "    index=top_k.indices\n",
    "    index=index.tolist()\n",
    "    d1=pd.DataFrame(title,columns=index)#\n",
    "    gene=d1.iloc[1,:]\n",
    "    gene=gene.tolist()\n",
    "    genes.append(gene)\n",
    "    #print(genes)\n",
    "    \n",
    "    gene_res=dict(zip(dis_names,genes))\n",
    "print(gene_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9529e382",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
