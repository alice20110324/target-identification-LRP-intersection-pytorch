{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bc20df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import Trainer\n",
    "from network import NFM\n",
    "import torch.utils.data as Data\n",
    "from Utils.criteo_loader import getTestData, getTrainData\n",
    "\n",
    "nfm_config = \\\n",
    "{\n",
    "    'xiaoqiu_n_class':9,\n",
    "    'n_class':11,\n",
    "    'linear_hidden1':1000,\n",
    "    'linear_hidden':100,#线性模型输出层（隐层个数）\n",
    "    'embed_input_dim':1001,#embed输入维度\n",
    "    'embed_dim': 100, # 用于控制稀疏特征经过Embedding层后的稠密特征大小，embed输出维度\n",
    "    'dnn_hidden_units': [100,11],#MLP隐层和输出层\n",
    "    'num_sparse_features_cols':4077,#the number of the gene columns\n",
    "    'num_dense_features': 0,#dense features number\n",
    "    'bi_dropout': 0.3,#Bi-Interaction 的dropout\n",
    "    'num_epoch': 500,#训练epoch次数\n",
    "    'batch_size': 100,#batch_size\n",
    "    'lr': 1e-3,\n",
    "    'l2_regularization': 1e-4,\n",
    "    'device_id': 0,\n",
    "    'use_cuda': False,\n",
    "    \n",
    "    #'train_file': '../Data/criteo/processed_data/train_set.csv',\n",
    "    #'fea_file': '../Data/criteo/processed_data/fea_col.npy',\n",
    "    #'validate_file': '../Data/criteo/processed_data/val_set.csv',\n",
    "    #'test_file': '../Data/criteo/processed_data/test_set.csv',\n",
    "    #'model_name': '../TrainedModels/NFM.model'\n",
    "    'train_file':'data/frappe/gene_4000/gene_4000_encode.csv',\n",
    "    'label_file':'data/frappe/gene_4000/label.csv',\n",
    "    'test_file':'data/frappe/gene_4000/test/test_file.csv',\n",
    "    'test_label':'data/frappe/gene_4000/test/test_label.csv',\n",
    "    'train_xiaoqiu_file':'data/frappe/gene_xiaoqiu_5000/train_file.csv',\n",
    "    'train_xiaoqiu_label':'data/frappe/gene_xiaoqiu_5000/train_label.csv'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedd6a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.backends.cudnn as cudnn\n",
    "#3from tensorboardX import SummaryWriter\n",
    "\n",
    "#import network\n",
    "import config\n",
    "import evaluate\n",
    "import data_utils\n",
    "import Trainer\n",
    "#from utils import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443111e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#功能：加载保存到path中的各层参数到神经网络\n",
    "from new_nfm_network import NFM\n",
    "path='data/frappe/model/new_model_param_gene_4000.pkl'\n",
    "#nfm = NFM(nfm_config).cuda()\n",
    "net=NFM(nfm_config)\n",
    "print(net)\n",
    "#net = nn.DataParallel(net)\n",
    "#net = net.to(device)\n",
    "net.load_state_dict(torch.load(path),strict=False)\n",
    "net.cuda()\n",
    "\n",
    "print(net)\n",
    "\n",
    "params = list(net.named_parameters())\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a32b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight={}\n",
    "for name,parameters in net.named_parameters():\n",
    "    print(name,':',parameters.size())\n",
    "    #names.append(name)\n",
    "    weight[name]=parameters\n",
    "print(\"weight:\",weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c52fcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_process import FMData\n",
    "\n",
    "\n",
    "test_dataset = FMData(nfm_config['test_file'],nfm_config['test_label'],nfm_config['n_class'])\n",
    "test_loader = data.DataLoader(test_dataset, drop_last=True,batch_size=100,shuffle=True, num_workers=4)#batchsize必须小于测试机总数，否则测试时报错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b7b0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from new_nfm_network import NFM\n",
    "if __name__ == \"__main__\":\n",
    "    ####################################################################################\n",
    "    # NFM 模型\n",
    "    ####################################################################################\n",
    "    BATCH_SIZE=100\n",
    "    \"\"\"\n",
    "    training_data, training_label, dense_features_col, sparse_features_col = getTrainData(nfm_config['train_file'], nfm_config['fea_file'])\n",
    "    train_dataset = Data.TensorDataset(torch.tensor(training_data).float(), torch.tensor(training_label).float())\n",
    "\n",
    "    test_data = getTestData(nfm_config['test_file'])\n",
    "    test_dataset = Data.TensorDataset(torch.tensor(test_data).float())\n",
    "    \n",
    "    test_data = getTestData(nfm_config['test_file'])\n",
    "    test_dataset = Data.TensorDataset(torch.tensor(test_data).float())\n",
    "\n",
    "    \"\"\"\n",
    "    #device = torch.device('cuda:0')\n",
    "    #epoch=0\n",
    "    \n",
    "    #model=nn.Linear(10149,16).to(device)\n",
    "    #model=nn.Linear(10149,16)\n",
    "    #model=nn.ReLU(nn.Linear(10149,16))#RuntimeError: all elements of input should be between 0 and 1\n",
    "    #print('model:',model)\n",
    "    nfm = NFM(nfm_config).cuda()#加了device防止出现GPU CPU两种设备的错误提示\n",
    "    print(\"nfm:\",nfm)\n",
    "    #print(nfm)\n",
    "    #nfm.train()\n",
    "    #u=nfm.parameters()\n",
    "    #print(u)\n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr=nfm_config['lr'], weight_decay=nfm_config['l2_regularization'])\n",
    "    optimizer = torch.optim.Adam(nfm.parameters(), lr=nfm_config['lr'], weight_decay=nfm_config['l2_regularization'])\n",
    "    total = 0\n",
    "    #loss_func = torch.nn.BCELoss()\n",
    "    loss_func=torch.nn.CrossEntropyLoss()\n",
    "    #loss_func=torch.nn.LogSoftmax()\n",
    "    \n",
    "    #model=nn.Softmax(nn.Linear(10149,16)).to(device)\n",
    "    # 从DataLoader中获取小批量的id以及数据\n",
    "    for epoch_id in range(1000):\n",
    "        correct=0\n",
    "        total=0\n",
    "        for batch_idx, (x, labels) in enumerate(train_loader):\n",
    "            x = Variable(x)\n",
    "            labels = Variable(labels)\n",
    "            \n",
    "            \n",
    "            #x = torch.tensor(x, dtype=torch.float)\n",
    "            #x=x.clone().detach().requires_grad_(True)\n",
    "            x=torch.tensor(x,dtype=torch.float)\n",
    "            labels=torch.tensor(labels,dtype=torch.float)\n",
    "            x, labels = x.cuda(), labels.cuda()\n",
    "            \n",
    "            print(\"labels:\",labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_predict = nfm(x)\n",
    "            print(\"y_predict:\",y_predict)\n",
    "            #loss = loss_func(y_predict.view(-1), labels)\n",
    "            loss = loss_func(y_predict, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss = loss.item()\n",
    "            #loss, predicted = self._train_single_batch(x, labels)\n",
    "\n",
    "            total += loss\n",
    "            \n",
    "            \n",
    "            \n",
    "            predicted = torch.max(y_predict.data,1)\n",
    "            #print(\"predicted:\",predicted)\n",
    "            predicted = torch.max(y_predict.data,1)[1]\n",
    "            \n",
    "            \n",
    "            labels=torch.max(labels,1)\n",
    "            #print(\"labels:\",labels)\n",
    "            labels=labels[1]\n",
    "            \n",
    "            correct += (predicted == labels).sum()\n",
    "            #print(\"correct:\",correct)\n",
    "            #correct=correct[0]\n",
    "            print(\"new_correct:\",float(correct))\n",
    "            correct=float(correct)   \n",
    "            #if batch_idx % 10 == 0:\n",
    "            print(\"batch_idx:\",batch_idx)\n",
    "            print(correct/(BATCH_SIZE*(batch_idx+1)))\n",
    "            \n",
    "            \"\"\"\n",
    "            #y_predict.detach().numpy()\n",
    "            pred = y_predict\n",
    "            print(\"pred:\",pred.shape)\n",
    "            y=labels.clone().detach().requires_grad_(True)\n",
    "            print(\"y:\",y.shape)\n",
    "            #y=labels.data.cpu().numpy()\n",
    "            #y = labels.detach().numpy()\n",
    "            roc_auc_score(y, pred)\n",
    "            \"\"\"\n",
    "           \n",
    "            # print('[Training Epoch: {}] Batch: {}, Loss: {}'.format(epoch_id, batch_id, loss))\n",
    "        print(\"Training Epoch: %d, total loss: %f\" % (epoch_id, total))\n",
    "        #print(\"auc:\",roc_auc_score)\n",
    "#功能：保存训练完的网络的各层参数（即weights和bias)\n",
    "path='data/frappe/model/new_model_param_gene_4000.pkl'\n",
    "torch.save(nfm.state_dict(),path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
